{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(10000, 20, padding_idx=0)\n",
    "# Embedding 계층의 입력은 int64 텐서\n",
    "inp = torch.tensor([1, 2, 5, 2, 10], dtype=torch.int64)\n",
    "# 출력은 float32 텐서\n",
    "out = emb(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDb 리뷰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "remove_marks_regex = re.compile('[,\\.\\(\\)\\[\\]\\*:;]|<.*?>')\n",
    "shift_marks_regex = re.compile('([?!])')\n",
    "\n",
    "def text2ids(text, vocab_dict):\n",
    "    # !? 이외의 기호 삭제\n",
    "    text = remove_marks_regex.sub('', text)\n",
    "    # !? 와 단어 사이에 공백 삽입\n",
    "    text = shift_marks_regex.sub(r' \\1 ', text)\n",
    "    tokens = text.split()\n",
    "    return [vocab_dict.get(token, 0) for token in tokens]\n",
    "\n",
    "def list2tensor(token_idxes, max_len=100, padding=True):\n",
    "    if len(token_idxes) > max_len:\n",
    "        token_idxes = token_idxes[:max_len]\n",
    "    n_tokens = len(token_idxes)\n",
    "    if padding:\n",
    "        token_idxes = token_idxes + [0] * (max_len - len(token_idxes))\n",
    "    return torch.tensor(token_idxes, dtype=torch.int64), n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, dir_path, train=True, max_len=100, padding=True):\n",
    "        self.max_len = max_len\n",
    "        self.padding = padding\n",
    "        \n",
    "        path = pathlib.Path(dir_path)\n",
    "        vocab_path = path.joinpath('imdb.vocab')\n",
    "        \n",
    "        # 용어집 파일을 읽어서 행 단위로 분할\n",
    "        self.vocab_array = vocab_path.open().read().strip().splitlines()\n",
    "        # 단어가 키이고 값이 ID인 dict 만들기\n",
    "        self.vocab_dict = dict((w, i+1) for (i, w) in enumerate(self.vocab_array))\n",
    "        \n",
    "        if train:\n",
    "            target_path = path.joinpath('train')\n",
    "        else:\n",
    "            target_path = path.joinpath('test')\n",
    "        pos_files = sorted(glob.glob(str(target_path.joinpath('pos/*.txt'))))\n",
    "        neg_files = sorted(glob.glob(str(target_path.joinpath('neg/*.txt'))))\n",
    "        \n",
    "        # pos는 1, neg는 0인 label을 붙여서 (file_path, label)의 튜플 리스트 작성\n",
    "        self.labeled_files = \\\n",
    "        list(zip([0]*len(neg_files), neg_files)) + \\\n",
    "        list(zip([1]*len(pos_files), pos_files))\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab_array)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labeled_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label, f = self.labeled_files[idx]\n",
    "        # 파일의 텍스트 데이터를 읽어서 소문자로 변환\n",
    "        data = open(f).read().lower()\n",
    "        # 텍스트 데이터를 ID리스트로 변환\n",
    "        data = text2ids(data, self.vocab_dict)\n",
    "        # ID 리스트를 텐서로 변환\n",
    "        data, n_tokens = list2tensor(data, self.max_len, self.padding)\n",
    "        return data, label, n_tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = IMDBDataset('/home/data/torch_test/aclImdb/')\n",
    "test_data = IMDBDataset('/home/data/torch_test/aclImdb/', train=False)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTaggingNet(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim=50, hidden_size=50,\n",
    "                 num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
    "                           batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x, h0=None, l=None):\n",
    "        # ID를 Embedding으로 다차원 벡터로 변환\n",
    "        # x는 (batch_size, step_size) -> (batch_size, step_size, embedding_dim)\n",
    "        x = self.emb(x)\n",
    "        # 초기 상태 h0와 함께 RNN에 x를 전달\n",
    "        # x는 (batch_size, step_size, embedding_dim) -> (batch_size, step_size, hidden_dim)\n",
    "        x, h = self.lstm(x, h0)\n",
    "        # 마지막 단계만 추출\n",
    "        # x 는 (batch_size, step_size, hidden_dim) -> (batch_size, 1)\n",
    "        if l is not None:\n",
    "            # 입력의 원래 길이가 있으면 그것을 이용\n",
    "            x = x[list(range(len(x))), l-1, :]\n",
    "        else:\n",
    "            # 없으면 단순히 마지막 것을 이용\n",
    "            x = x[:, -1, :]\n",
    "        \n",
    "        # 추출한 마지막 단계를 선형 계측에 넣는다\n",
    "        x = self.linear(x)\n",
    "        # 불필요한 차원을 삭제\n",
    "        # (batch_size, 1) -> (batch_size, )\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, data_loader, device='cpu'):\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y, l in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        l = l.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = net(x, l=l)\n",
    "            y_pred = (y_pred > 0).long()\n",
    "            ys.append(y)\n",
    "            ypreds.append(y_pred)\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.35it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6767864894226688 0.5662400126457214 0.555840015411377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.43it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6522548801225164 0.5757200121879578 0.5660399794578552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.11it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.5719831281382105 0.7931199669837952 0.7401999831199646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:20<00:00, 37.62it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.42440873973281185 0.8547199964523315 0.7656399607658386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.90it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.34354243925808337 0.8928399682044983 0.7820000052452087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.62it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.2762686503179314 0.9264799952507019 0.7899999618530273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.93it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.21811304512717153 0.9481599926948547 0.7868399620056152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.23it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.1728229735241941 0.9644399881362915 0.7864800095558167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.99it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.12979410097593694 0.9735199809074402 0.7814799547195435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 36.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.09691310933817301 0.9850800037384033 0.7844799757003784\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# num_embeddings 에는 0을 포함해서 train_data.vocab_size+1를 넣는다\n",
    "net = SequenceTaggingNet(train_data.vocab_size+1, num_layers=2)\n",
    "net.to('cuda:0')\n",
    "opt = optim.Adam(net.parameters())\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for x, y, l in tqdm.tqdm(train_loader):\n",
    "        x = x.to('cuda:0')\n",
    "        y = y.to('cuda:0')\n",
    "        l = l.to('cuda:0')\n",
    "        y_pred = net(x, l=l)\n",
    "        loss = loss_f(y_pred, y.float())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    train_acc = eval_net(net, train_loader, 'cuda:0')\n",
    "    val_acc = eval_net(net, test_loader, 'cuda:0')\n",
    "    print(epoch, mean(losses), train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN을 사용하지 않는 모델 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.93084, 0.394)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_X, train_y = load_svmlight_file(\n",
    "'/home/data/torch_test/aclImdb/train/labeledBow.feat')\n",
    "test_X, test_y = load_svmlight_file(\n",
    "'/home/data/torch_test/aclImdb/test/labeledBow.feat', n_features=train_X.shape[1])\n",
    "\n",
    "model = LogisticRegression(C=0.1, max_iter=1000)\n",
    "model.fit(train_X, train_y)\n",
    "model.score(train_X, train_y), model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PackedSequence 성질을 이용한 모델 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTaggingNet2(SequenceTaggingNet):\n",
    "    def forward(self, x, h0=None, l=None):\n",
    "        # ID를 Embedding으로 다차원 벡터로 변환\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # 길이가 주어진 경우 PackedSequence 만들기\n",
    "        if l is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, l, batch_first=True)\n",
    "            \n",
    "        # RNN에 입력\n",
    "        x, h = self.lstm(x, h0)\n",
    "        \n",
    "        # 마지막 단계를 추출해서 선형 계층에 넣는다\n",
    "        if l is not None:\n",
    "            # 길이 정보가 있으면 마지막 계층의 내부 상태 벡터를 직접 이용할 수 있다\n",
    "            # LSTM은 보통 내부 상태 외에 블럭 셸 상태도 가지고 있으므로 \n",
    "            # 내부 상태만 사용한다\n",
    "            hidden_state, cell_state = h\n",
    "            x = hidden_state[-1]\n",
    "        else:\n",
    "            x = x[:, -1, :]\n",
    "            \n",
    "        # 선형 계층에 넣는다\n",
    "        x = self.linear(x).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:23<00:00, 33.26it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.07176295295119514 0.9879599809646606 0.7839599847793579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.27it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.05849907097145867 0.9915199875831604 0.7809199690818787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 34.37it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.04427589983066015 0.9931599497795105 0.7757599949836731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.12it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.04070336643345606 0.9946799874305725 0.7714799642562866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 35.89it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.03325577155934632 0.9957999587059021 0.7770400047302246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 34.87it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.026796035615660612 0.9966399669647217 0.7760799527168274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 35.73it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.024858980857328895 0.9967199563980103 0.7716799974441528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:21<00:00, 35.61it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.022525886282869056 0.9975199699401855 0.7676799893379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.45it/s]\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.01671033776799917 0.9955199956893921 0.7620399594306946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:22<00:00, 35.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.017389539363267034 0.9964799880981445 0.7615599632263184\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for x, y, l in tqdm.tqdm(train_loader):\n",
    "        # 길이 배열을 길이 순으로 정렬\n",
    "        l, sort_idx = torch.sort(l, descending=True)\n",
    "        # 얻은 인덱스를 사용해서 x, y도 정렬\n",
    "        x = x[sort_idx]\n",
    "        y = y[sort_idx]\n",
    "        \n",
    "        x = x.to('cuda:0')\n",
    "        y = y.to('cuda:0')\n",
    "        \n",
    "        y_pred = net(x, l=l)\n",
    "        loss = loss_f(y_pred, y.float())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    train_acc = eval_net(net, train_loader, 'cuda:0')\n",
    "    val_acc = eval_net(net, test_loader, 'cuda:0')\n",
    "    print(epoch, mean(losses), train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN을 사용한 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 ascii 문자로 사전 만들기\n",
    "import string\n",
    "all_chars = string.printable\n",
    "vocab_size = len(all_chars)\n",
    "vocab_dict = dict((c, i) for (i, c) in enumerate(all_chars))\n",
    "\n",
    "# 문자열을 수치 리스트로 변환하는 함수\n",
    "def str2ints(s, vocab_dict):\n",
    "    return [vocab_dict[c] for c in s]\n",
    "\n",
    "# 수치 리스트를 문자열로 변환하는 함수\n",
    "def ints2str(x, vocab_array):\n",
    "    return \"\".join([vocab_array[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, path, chunk_size=200):\n",
    "        # 파일을 읽어서 수치 리스트로 변환\n",
    "        data = str2ints(open(path).read().strip(), vocab_dict)\n",
    "        \n",
    "        # 텐서로 변환해서 split 한다\n",
    "        data = torch.tensor(data, dtype=torch.int64).split(chunk_size)\n",
    "        \n",
    "        # 마지막 덩어리(chunk)의 길이를 확인해서 부족한 경우 버린다\n",
    "        if len(data[-1]) < chunk_size:\n",
    "            data = data[:-1]\n",
    "            \n",
    "        self.data = data\n",
    "        self.n_chunks = len(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_chunks\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ShakespeareDataset('/home/data/torch_test/input.txt', chunk_size=200)\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerationNet(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim=50,\n",
    "                hidden_size=50, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=dropout)\n",
    "        # Linear의 output 크기는 첫 Embedding의 input 크기와 같은 num_embeddings\n",
    "        self.linear = nn.Linear(hidden_size, num_embeddings)\n",
    "        \n",
    "    def forward(self, x, h0=None):\n",
    "        x = self.emb(x)\n",
    "        x, h = self.lstm(x, h0)\n",
    "        x = self.linear(x)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 생성 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(net, start_phrase='The King said ', length=200,\n",
    "                temperature=0.8, device='cpu'):\n",
    "    # 모델을 평가 모드로 설정\n",
    "    net.eval()\n",
    "    # 출력 수치를 저장할 리스트\n",
    "    result = []\n",
    "    \n",
    "    # 시작 문자열을 텐서로 변환\n",
    "    start_tensor = torch.tensor(str2ints(start_phrase, vocab_dict),\n",
    "                               dtype=torch.int64).to(device)\n",
    "    # 선두에 batch 차원을 붙인다\n",
    "    x0 = start_tensor.unsqueeze(0)\n",
    "    # RNN을 통해서 출력과 새로운 내부 상태를 얻는다\n",
    "    o, h = net(x0)\n",
    "    # 출력을 정규화 되어 있지 않은 확률로 변환\n",
    "    out_dist = o[:, -1].view(-1).exp()\n",
    "    # 확률로부터 실제 문자의 인덱스를 샘플링\n",
    "    top_i = torch.multinomial(out_dist, 1)[0]\n",
    "    # 결과 저장\n",
    "    result.append(top_i)\n",
    "    \n",
    "    # 생성된 결과를 차례로 RNN에 넣는다\n",
    "    for i in range(length):\n",
    "        inp = torch.tensor([[top_i]], dtype=torch.int64)\n",
    "        inp = inp.to(device)\n",
    "        o, h = net(inp, h)\n",
    "        out_dist = o.view(-1).exp()\n",
    "        top_i = torch.multinomial(out_dist, 1)[0]\n",
    "        result.append(top_i)\n",
    "    \n",
    "    return start_phrase + ints2str(result, all_chars)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.85it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4623844378335136\n",
      "The King said kiw iSle. td\n",
      "uAs uiisfreuhedwilm  hIi mnroimac  necthtdI? afs emieeme\n",
      "  eWray ines iamy .tT. c,.\n",
      "l Wtee\n",
      " Ashg ar\n",
      ":.e, aewOc' ll dineh t mgot\n",
      "Arr eoheue:aase ose. dy rpbeltdoshIl. yii ohm itteglS oyhUe'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.36it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.9100799001966204\n",
      "The King said aroh aor aotyd then\n",
      "\n",
      "EHchooir fehrrset dr ynin,a ere ars fttoau fdd dtatl!Ntmahed'l\n",
      " a yotsle,\n",
      "Whics huhasgB; miiet mn agas wnrdadm sass my uwohis prsmey.\n",
      "\n",
      "CrESLBI:\n",
      "\n",
      "troan ctenh tras a teaif, bn pfupwa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.79it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2.5826023783002583\n",
      "The King said onlt euvHeme bhimd me hois sotese:\n",
      "\n",
      "AICI:\n",
      "Ah lhud hor ander chesrend oy sebatpnrierh.\n",
      "\n",
      "Sor hain than bhey loud sirin sass mord :ind whe Pougece ilt briaf, ffavorlinser hhhe we: erort\n",
      "Fhame sen was dhoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.93it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2.4098302677699497\n",
      "The King said gosy as th segarge soungred messmy.\n",
      "\n",
      "CENTILALN:\n",
      "T walls ot scerre thine heen:-\n",
      "He ondas os, sorilet fol fh.\n",
      "Whererers anusve lnet is,\n",
      "Art, thive arnle mefest houd laten, borghHoi'd ard,\n",
      "Tupame ar loum,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:05<00:00, 29.71it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2.308585090637207\n",
      "The King said mrole, smeil eorr saos whavish, yar iundeng kold safh.\n",
      "\n",
      "KCBIFNRLEO:\n",
      "Henrakog me ant raser, Levenagole tuntus?\n",
      "\n",
      "ORDANPHTAR RIA:\n",
      "Soo'.\n",
      "\n",
      "GAONFNAK:\n",
      "Not tiriuct Sfoht, notes bun deilr?\n",
      "\n",
      "MPMO\n",
      "LRSRL:\n",
      "Haef\n",
      "In \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.36it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2.234750713620867\n",
      "The King said heipcild you you ferun faor ghiyth Poudy ir at ky of pouvle marcouslr I ele mataw Wivteros, the ill hfar: thiy'r. as gor purpeen hard twy foaprer meselollent ingind. I duind as mortn agar orlelm: I afe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.81it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2.1721610559735978\n",
      "The King said beows they gigkast.\n",
      "\n",
      "CIMPEO:\n",
      "Civell, we youlnher.\n",
      "Anged go goqelrnen pore I ho the morh fleed ives sipfintlesbes, overeroun;\n",
      "Add msy, mone wimitingy.\n",
      "\n",
      "LUIVSRIO:\n",
      "Fryistil utter lil my mass if pusant gro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.92it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2.12021331514631\n",
      "The King said not.\n",
      "\n",
      "LHARUB:\n",
      "Hast nocy be Crine ekct\n",
      "tince:\n",
      "And, qrothy;\n",
      "Cibe bees;\n",
      "\n",
      "Go thave wand , tracide at hirgt ongem, youl'd his bint hiy leay than her bict ow'd bnust me is the, nos nouss nod otn remife non i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.83it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2.0740864058903283\n",
      "The King said dome the kputh is thad, monle; loech kere;\n",
      "For dipoeffels hit has hithe ep thiy xoundir he sint me trin bokof all ambares wist\n",
      "Vy,\n",
      "The ant, agele and tave comnak to but when at Oo mesn ouch esketh and \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.15it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 2.035035719871521\n",
      "The King said the occretprshef she, a hath her daik blace.\n",
      "\n",
      "PHORIKA: Yawe!\n",
      "By lats me anster\n",
      "Foar thif the daow,\n",
      "Es nod thest chootfrers; your thut how loanps,\n",
      "Bettent for salcge\n",
      "stonplit,\n",
      "I be if dear'd sharl.\n",
      "\n",
      "DIK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.37it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2.0004616887228828\n",
      "The King said sexefad too that stiped cwartood, Hand be dyof thy ouf farbow: endot to syo foven more nod bortere.\n",
      "\n",
      "BADHF UISE:\n",
      "And intr on of all soneine whace stasiks,\n",
      "And tighelr-toul not\n",
      "For of be you danazed dea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.60it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1.9691716718673706\n",
      "The King said thess thither, the goud; ip quarsy:\n",
      "Brunk, and as 'swer. But, hich\n",
      "tith whow,\n",
      "To joisty, thither\n",
      "The culdiy Bopim therarise upol his the bestany hath tlich, you dinfouary a baytranctiy of swise!\n",
      "\n",
      "Ferse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.68it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 1.9438961696624757\n",
      "The King said we toderen my angen, my wall by thich sang, to Cliy\n",
      "An inly ann yeen juthink and zoth mvorenythid, beice, le's thuke, to sow he\n",
      "Gnod faid.\n",
      "it aged thy lentt.\n",
      "Noudnok a kning.\n",
      "\n",
      "LUCIO:\n",
      "Toterere soo-low.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.71it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 1.9214001199177333\n",
      "The King said comistly. So.\n",
      "\n",
      "MENETENAPE:\n",
      "Would, it dy thou,\n",
      "Hare jy, Biloud the spors de let.\n",
      "Prease hims : Ier have are you, sict\n",
      "The flort eentrereng;Zy I hound nothir, maich to manse told\n",
      "And im and sake,\n",
      "They hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.04it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 1.9006154319218227\n",
      "The King said contongmed\n",
      "To it meat moress lity\n",
      "Deesiin:\n",
      "Casecter\n",
      "To do dwor' dale farlono lugior and hill, sumpand an'ct, fast a mouks so mester, tobash.\n",
      "\n",
      "HATINGES RSLARZ IO:\n",
      "Cornd neon whant'st, not in atseln. I C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.90it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 1.8831139298847743\n",
      "The King said mare,\n",
      "Frient of\n",
      "Nis all you in here,\n",
      "Sibt\n",
      "And came woult it prings with to that I have tets wry a custly maor that you tois whas thow; and Hordory\n",
      "So hit. my thee givel. Low'd\n",
      "wnow lior, on hasmed\n",
      "feat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.16it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 1.866675408908299\n",
      "The King said encentthess trow eclise, so, you heam\n",
      "qois, yound this musingy.\n",
      "\n",
      "SICINETES:\n",
      "I Casite.\n",
      "An. Whisegs hince. Xringer dearl adthere whight comef\n",
      "father deted other she dear.\n",
      "Is lijleng wheroming,\n",
      "The both m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.49it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 1.8523228093555995\n",
      "The King said to sanss to of Lever, aw, Do day the tellone somborcgior thy angear poaight thy can thouroth choses breance to kick strinl chave thor deep prepother, preais canminllen in yither: that now shame hord ha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.54it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 1.8379281786509922\n",
      "The King said the menesten, to my trock treen\n",
      "Comojert o neqped the shourbuljacsantmion wislling undisialo from I shall leat wixchen't: `ores be have to come be mis fore shame\n",
      "Hod shuse azsaon.\n",
      "\n",
      "HARTIO:\n",
      "In me the th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.37it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1.8262477670397077\n",
      "The King said that him. For--\n",
      "\n",
      "WARFARK VI\n",
      "IA:\n",
      "Lerrangy\n",
      "Petpears of vereged you, it your treclalcion.\n",
      "\n",
      "CORIOLHO:\n",
      "Why; mad'd are sing with halt;\n",
      "I prom, sisseld.\n",
      "\n",
      "Cspord:\n",
      "Whuthing with were herad's deaphty; is Ancell:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.77it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1.8153022881916592\n",
      "The King said is car non time then my bike that the whom your chand here the worr lold,\n",
      "Then thengle Bectainth, he painso the kreornk, by fatelt on-tase;\n",
      "I provuld the prince would knohess of as nom.\n",
      "\n",
      "BARSYA:\n",
      "Whow h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.25it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 1.8057716873713903\n",
      "The King said be now then we graccer\n",
      "As nem:\n",
      "If net as a minor o have wan to him it to be welse uplo'd see plink,\n",
      "AGous the anines\n",
      "In he kink mant, \f",
      "raist of but hank anve you and fair let many cales!\n",
      "\n",
      "WRANIA:\n",
      "Filly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 28.95it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 1.797329911504473\n",
      "The King said comanlouse\n",
      "By Painter, and fither; is thy swy, mest she he good, and quite b of sute one of slrit\n",
      "That, your frems, And in then palcienous or for that the dowl.\n",
      "\n",
      "HANDISSSBERY\n",
      "BARCY:\n",
      "By well mare in the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.11it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 1.7881206451143536\n",
      "The King said to eyes, Kities are nor lome\n",
      "Tinge entys.\n",
      "Wy\n",
      "hee home to minks ouf beonou\n",
      "Undied will concusion whan begnfar God your wif love\n",
      "Inughts to splestes bugst;\n",
      "Rearch; veaanince thotiak his it roou's cleich,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.98it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 1.7794508695602418\n",
      "The King said to againt.\n",
      "\n",
      "VOMENERDUS:\n",
      "How qoece that he leth, is in\n",
      "Was be couningers the layte, for Thand uppes of ligur.\n",
      "'Is time,\n",
      "For faw hotry,\n",
      "Hone belon,\n",
      "Thou of wiy bid,\n",
      "The o-fo me has hath light:\n",
      "Friest, ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:03<00:00, 47.07it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 1.7728857571738106\n",
      "The King said and not; anceh hatesty,\n",
      "If the sicitions the eyeroulrant,\n",
      "\n",
      "First Cearfour:\n",
      "Why Grabed, tham his word thou him, I zard:\n",
      "Heoble her\n",
      "My Kear coneuted a'd asdiply.\n",
      "\n",
      "MENENIUS:\n",
      "I seeb.\n",
      "\n",
      "FERMISTAR VIONEMO:\n",
      "Wh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 27.60it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 1.764600088255746\n",
      "The King said upor, that Cately his for one; the seels\n",
      "That your fames hour be.\n",
      "Meqpenged engrents, But your lerce, my doth yet sell,\n",
      "And no rack plam my\n",
      "sepring your swciced you drournes surled to the have dobe wou\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.42it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 1.7579363693509784\n",
      "The King said thy galent great devared.\n",
      "\n",
      "CAMILLO:\n",
      "I wime would no rather,\n",
      "But as for the prose, inloost'l come,\n",
      "Why sooth and dax my from speed thee brothne any denound,\n",
      "Is hame cellought.\n",
      "\n",
      "COMINIUS:\n",
      "Awined the maid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.51it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 1.7507116379056658\n",
      "The King said the weak my I ofly. Breed, my suers cautiles?\n",
      "\n",
      "EJFALDA:\n",
      "See;\n",
      "Let his foot a senct\n",
      "Eve wartient for is intoy\n",
      "And I seares to hear,\n",
      "This bequtse rode yew o your their on it agan my bate, Lord of'm no his\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.17it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 1.7446132619040353\n",
      "The King said doth Elper nour senats\n",
      "The day duch of but for hoam he, as theurthen, Geworn, the dugk, hath the tome?\n",
      "\n",
      "ChARI:\n",
      "Be you, an and ofter, sloud heart, therefut swall frian,\n",
      "The, well and be have promamin,\n",
      "T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.51it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1.7387727546691893\n",
      "The King said as your reafteds ares he kind\n",
      "To-ours it bepore!\n",
      "Yhe seg him yech it and as more noch grese.\n",
      "\n",
      "AUSELO:\n",
      "Now, she me to with they can beir thene:\n",
      "No offent, I belowalt, not nursh.\n",
      "\n",
      "COMINIUS:\n",
      "No\n",
      "To defone:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.39it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 1.7331742715835572\n",
      "The King said or she no merald;\n",
      "And moor womening.\n",
      "The all bake upon mefsihe of mint; fair:\n",
      "Gad valy his again Itless my namily-mowards! dow, dets, rights; let it be have thoughgo did in did,\n",
      "And\n",
      "Edperetne oul vee.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.89it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1.727847798211234\n",
      "The King said sing doind: forkes\n",
      "Comeer that here am our a grined he being\n",
      "To wrughts in the's downy\n",
      "That; whid, Womes in his linmues.\n",
      "\n",
      "SICINIUS:\n",
      "What, a foil him to thou taties lever man so, Vy quear.\n",
      "\n",
      "MARWIA:\n",
      "Shee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.49it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 1.7224365649904523\n",
      "The King said him\n",
      "Af the king, I couse this gut, and brown.'\n",
      "\n",
      "LEONTES:\n",
      "Nometh. Even wonad. That, spend up! Low; ky\n",
      "Sway you hoise ansigoraal and torwsted\n",
      "And day: though haste, thile an offight but mencance,\n",
      "There, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.29it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 1.717652644429888\n",
      "The King said stansck,\n",
      "And he preyosine, truster'd there's swill me past hover\n",
      "In intake yet ton'm fluce theesely,\n",
      "I lays up my hear of chice: I should prove ensur so this to of her, but was grease, there teill I ha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.96it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 1.7132290833336967\n",
      "The King said insteding of Romon for stay vince our compertiunsion me well\n",
      "For but know roys time I his fathem it esblan:\n",
      "Though the power's ney, as here, stellionce stay, doth sgaite.\n",
      "Praed lire's bard,\n",
      "Briing caun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 25.00it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 1.7083851766586304\n",
      "The King said your courvertrown;\n",
      "Are loth, this ke would gives not: to that you how is I lon on in wund,\n",
      "Upon wrught, and frey sop not deemon gave anttprad then you?\n",
      "I solves fordet untingfour of hod acture why mitr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.80it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 1.704455065727234\n",
      "The King said a off deeds, I'll is nother.\n",
      "Churd I so,\n",
      "And him, thou aspera.\n",
      "The glaty, you voument little art who, that God as I'll it mother fay lord still you\n",
      "And is mell wriss stoper's his sback Sor'd knows with\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.98it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 1.700228179522923\n",
      "The King said hand! he pepsaruchen.\n",
      "\n",
      "TONTIGA:\n",
      "When and that the lay you to\n",
      "no vany,\n",
      "To\n",
      "wwere you, by yetings.\n",
      "\n",
      "JULIET:\n",
      "Letio supurt, the bysmwesn\n",
      "to mage to wifh,\n",
      "Or deabfires iffueds; the halr-stear!\n",
      "\n",
      "Second Crivin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.61it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 1.6967252349853517\n",
      "The King said is not thou report an, are their ius is full the promisy\n",
      "Which good\n",
      "Timms, themine, shield Refleat, may\n",
      "allessurn of hess\n",
      "My to currep by the duke it mess. \n",
      "Secwer:\n",
      "My for this could in this\n",
      "Tunsels fi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.16it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 1.6927047164099558\n",
      "The King said and heard vimots wrongs!\n",
      "Gaod lip'sly,\n",
      "Let he death\n",
      "Of not their teme, do carly amed them, the grupss:\n",
      "Let he how your painl:\n",
      "That non there isence,\n",
      "Whow of my come, Pied do;\n",
      "The Eppecusion as thou gap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.30it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 1.6892115470341273\n",
      "The King said surment easpe,\n",
      "We'll have wan as to my fie:\n",
      "To 'twils it Edir:\n",
      "Whos they what you this stand is Vasy sick,\n",
      "That casicy stay her! own: bid, and come.\n",
      "\n",
      "PETRUCIO:\n",
      "Not of hath are. Which that bethent, if n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:04<00:00, 42.37it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 1.6857708644866944\n",
      "The King said to bly Kand to the masbard,\n",
      "Seard in holy shame you will shalr the it murtaouncies?\n",
      "\n",
      "CORIOLANUS:\n",
      "Nay in advest, behorder is that chicians.\n",
      "\n",
      "BRUSSS:\n",
      "CEwar? Wether furm.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Brought is a gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:05<00:00, 34.61it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 1.6829723855427334\n",
      "The King said your goodfh,\n",
      "I tlook you be us his senful kiy of with youl walrow in brother.\n",
      "\n",
      "GLOUCEST:\n",
      "Yajeece?\n",
      "\n",
      "CORIOSAN:\n",
      "I know to than wame upor prothes curslanding so,\n",
      "Twukh preon a wean bees him gross the volea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 24.69it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 1.6795048795427594\n",
      "The King said facch.\n",
      "A handing. how thone stible to your haughiniom lown,\n",
      "I prowell;\n",
      "This combers underth yous't,\n",
      "Lid me come dousp? old, that to you on this now; as to in tear;\n",
      "Let his to treswelt she shebuson herc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.25it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 1.676377966744559\n",
      "The King said a master; inthince, to Andighne id deard,\n",
      "I wisting: sil would deeds, fratters, and fume nothat a incesitle,\n",
      "Thee rifk are resceed.\n",
      "\n",
      "PETUdBUCE:\n",
      "For protance my wasp fauty sweak this not tonces from you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.25it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 1.673661757196699\n",
      "The King said e'er vircupt; cornouss finst, whery vice it shall\n",
      "From which outes aptiused joib.\n",
      "\n",
      "WARCICLAURLENTE:\n",
      "Who, perciuncoury angie. May, therefore womunce-hand very;\n",
      "\n",
      "JULIET:\n",
      "That then you him sun; Igelf act,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:06<00:00, 25.54it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 1.6706090143748693\n",
      "The King said lave sing the ofvath come tenpalough no bellerger,\n",
      "he comdeive it seem?\n",
      "Haved that tale I would extertaints.\n",
      "Ay, and ay tell thine good'd prectiosing songering be mine septated to cread is himstlient!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.99it/s]\n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 1.6682540723255703\n",
      "The King said as kight lodd my trubt counser to from me them-dever is king,\n",
      "Piviel of the then\n",
      "We crurnal and to not, or prods\n",
      "To clo's this\n",
      "some Towerfo that come?\n",
      "\n",
      "LADY CAPULET:\n",
      "Your fair, by yeath's apdive we wil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:07<00:00, 23.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 1.6660753638403756\n",
      "The King said Norcile\n",
      "this would seebil range\n",
      "That ere think the father sunlerss\n",
      "Wills, as him,\n",
      "The mins.\n",
      "\n",
      "SICINIUS:\n",
      "Behsence you usit!\n",
      "Hoors\n",
      "Priqouded it service isself,\n",
      "Be an is have youl the hate feen.\n",
      "\n",
      "LROCHow:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "net = SequenceGenerationNet(vocab_size, 20, 50, num_layers=2, dropout=0.1)\n",
    "net.to('cuda:0')\n",
    "opt = optim.Adam(net.parameters())\n",
    "# 다중 식별 문제이므로 SoftmaxCrossEntropyLoss 가 손실 함수가 된다\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    net.train()\n",
    "    losses = []\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        # x는 처음부터 마지막의 하나 앞 문자까지 \n",
    "        x = data[:, :-1]\n",
    "        # y는 두번째부터 마지막 문자까지\n",
    "        y = data[:, 1:]\n",
    "        \n",
    "        x = x.to('cuda:0')\n",
    "        y = y.to('cuda:0')\n",
    "        \n",
    "        y_pred, _ = net(x)\n",
    "        # batch와 step 축을 통합해서 CrossEntropyLoss에 전달\n",
    "        loss = loss_f(y_pred.view(-1, vocab_size), y.view(-1))\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    # 현재 손실 함수와 생성된 문장 예 표시\n",
    "    print(epoch, mean(losses))\n",
    "    with torch.no_grad():\n",
    "        print(generate_seq(net, device='cuda:0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
