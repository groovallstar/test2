{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning_from_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0osN8yLT3rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials \n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "file_id = '1Nl6SYOBwJT9F1GmtI5U9BSacr6EdsrVc'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('ThoraricSurgery.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-TRrakwS_zg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f139d4fd-54d8-458f-f477-ccb081c40b0c"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "Data_set = np.loadtxt('ThoraricSurgery.csv', delimiter=\",\")\n",
        "\n",
        "X = Data_set[:, 0:17]\n",
        "Y = Data_set[:, 17]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100, batch_size=10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.8447\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f452f4ea748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPPQSml76Y58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '1Oq9LWJuz0ZdL9yiUVDamNC6XWDS_6-6_'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('pima-indians-diabetes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75zw6SWT6z-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('pima-indians-diabetes.csv', names=['pregnant', 'plasma', 'pressure', 'thickness', 'insulin', 'BMI', 'pedigree', 'age', 'class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMNZwts37EBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "d8c4c102-c4e3-4a84-e60b-0242dd080377"
      },
      "source": [
        "print(df.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
            "0         6     148        72         35        0  33.6     0.627   50      1\n",
            "1         1      85        66         29        0  26.6     0.351   31      0\n",
            "2         8     183        64          0        0  23.3     0.672   32      1\n",
            "3         1      89        66         23       94  28.1     0.167   21      0\n",
            "4         0     137        40         35      168  43.1     2.288   33      1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFfmkRrI7OHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "068a9708-21ca-49c3-84fc-f7f44e7fb225"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   pregnant   768 non-null    int64  \n",
            " 1   plasma     768 non-null    int64  \n",
            " 2   pressure   768 non-null    int64  \n",
            " 3   thickness  768 non-null    int64  \n",
            " 4   insulin    768 non-null    int64  \n",
            " 5   BMI        768 non-null    float64\n",
            " 6   pedigree   768 non-null    float64\n",
            " 7   age        768 non-null    int64  \n",
            " 8   class      768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MTJ8kPt7Se1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "a89e284d-5238-4743-ce1f-659e2b83fa54"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnant</th>\n",
              "      <th>plasma</th>\n",
              "      <th>pressure</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         pregnant      plasma    pressure  ...    pedigree         age       class\n",
              "count  768.000000  768.000000  768.000000  ...  768.000000  768.000000  768.000000\n",
              "mean     3.845052  120.894531   69.105469  ...    0.471876   33.240885    0.348958\n",
              "std      3.369578   31.972618   19.355807  ...    0.331329   11.760232    0.476951\n",
              "min      0.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
              "25%      1.000000   99.000000   62.000000  ...    0.243750   24.000000    0.000000\n",
              "50%      3.000000  117.000000   72.000000  ...    0.372500   29.000000    0.000000\n",
              "75%      6.000000  140.250000   80.000000  ...    0.626250   41.000000    1.000000\n",
              "max     17.000000  199.000000  122.000000  ...    2.420000   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLb138k97Vgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a552dc98-6131-4200-996f-da2905ec38b3"
      },
      "source": [
        "df[['pregnant', 'class']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnant</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     pregnant  class\n",
              "0           6      1\n",
              "1           1      0\n",
              "2           8      1\n",
              "3           1      0\n",
              "4           0      1\n",
              "..        ...    ...\n",
              "763        10      0\n",
              "764         2      0\n",
              "765         5      0\n",
              "766         1      1\n",
              "767         1      0\n",
              "\n",
              "[768 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuSCC1WV7kmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "a931cd1c-3a70-416e-9cce-b0790e6a11a3"
      },
      "source": [
        "print(df[['pregnant', 'class']].groupby(['pregnant'], as_index=False).mean().sort_values(by='pregnant', ascending=True))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    pregnant     class\n",
            "0          0  0.342342\n",
            "1          1  0.214815\n",
            "2          2  0.184466\n",
            "3          3  0.360000\n",
            "4          4  0.338235\n",
            "5          5  0.368421\n",
            "6          6  0.320000\n",
            "7          7  0.555556\n",
            "8          8  0.578947\n",
            "9          9  0.642857\n",
            "10        10  0.416667\n",
            "11        11  0.636364\n",
            "12        12  0.444444\n",
            "13        13  0.500000\n",
            "14        14  1.000000\n",
            "15        15  1.000000\n",
            "16        17  1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU3FxAlI74gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "outputId": "3f92ca43-2829-474b-be65-fcfd1f6eb735"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "sns.heatmap(df.corr(), linewidth=0.1, vmax=0.5, cmap=plt.cm.gist_heat, linecolor='white', annot=True)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FdjIN_d9p_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4783e934-5921-47db-fbe1-6a6f392a3f4f"
      },
      "source": [
        "grid = sns.FacetGrid(df, col='class')\n",
        "grid.map(plt.hist, 'plasma', bins=10)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIjtFJmU-Eyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b3784cd-790d-440e-ef41-acdf6bb2802b"
      },
      "source": [
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
        "X = dataset[:, 0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, Y, epochs=200, batch_size=10)\n",
        "\n",
        "print('\\n Accuracy:%.4f' % (model.evaluate(X, Y)[1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 10.5658 - accuracy: 0.6159\n",
            "Epoch 2/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 5.4303 - accuracy: 0.6029\n",
            "Epoch 3/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 2.9250 - accuracy: 0.5208\n",
            "Epoch 4/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 1.5330 - accuracy: 0.5208\n",
            "Epoch 5/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5000\n",
            "Epoch 6/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8068 - accuracy: 0.5234\n",
            "Epoch 7/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7648 - accuracy: 0.6549\n",
            "Epoch 8/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7319 - accuracy: 0.6628\n",
            "Epoch 9/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.6706\n",
            "Epoch 10/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6758\n",
            "Epoch 11/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6797\n",
            "Epoch 12/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6191 - accuracy: 0.6823\n",
            "Epoch 13/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.6979\n",
            "Epoch 14/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6966\n",
            "Epoch 15/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.7005\n",
            "Epoch 16/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6940\n",
            "Epoch 17/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.7057\n",
            "Epoch 18/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7122\n",
            "Epoch 19/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.6992\n",
            "Epoch 20/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7070\n",
            "Epoch 21/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6810\n",
            "Epoch 22/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7109\n",
            "Epoch 23/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.7148\n",
            "Epoch 24/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7070\n",
            "Epoch 25/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7122\n",
            "Epoch 26/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7161\n",
            "Epoch 27/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.7057\n",
            "Epoch 28/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7174\n",
            "Epoch 29/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7161\n",
            "Epoch 30/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7188\n",
            "Epoch 31/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7122\n",
            "Epoch 32/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7109\n",
            "Epoch 33/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7018\n",
            "Epoch 34/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7214\n",
            "Epoch 35/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7305\n",
            "Epoch 36/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7122\n",
            "Epoch 37/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7070\n",
            "Epoch 38/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.7227\n",
            "Epoch 39/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7174\n",
            "Epoch 40/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7292\n",
            "Epoch 41/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7253\n",
            "Epoch 42/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7227\n",
            "Epoch 43/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7201\n",
            "Epoch 44/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7240\n",
            "Epoch 45/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7122\n",
            "Epoch 46/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7161\n",
            "Epoch 47/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7266\n",
            "Epoch 48/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7318\n",
            "Epoch 49/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7253\n",
            "Epoch 50/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7318\n",
            "Epoch 51/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7279\n",
            "Epoch 52/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7383\n",
            "Epoch 53/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7240\n",
            "Epoch 54/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.7188\n",
            "Epoch 55/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.7253\n",
            "Epoch 56/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7174\n",
            "Epoch 57/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.7240\n",
            "Epoch 58/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7331\n",
            "Epoch 59/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7344\n",
            "Epoch 60/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7292\n",
            "Epoch 61/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7292\n",
            "Epoch 62/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7214\n",
            "Epoch 63/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7357\n",
            "Epoch 64/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7396\n",
            "Epoch 65/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7383\n",
            "Epoch 66/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7344\n",
            "Epoch 67/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7396\n",
            "Epoch 68/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7357\n",
            "Epoch 69/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7370\n",
            "Epoch 70/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7383\n",
            "Epoch 71/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7344\n",
            "Epoch 72/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7357\n",
            "Epoch 73/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7292\n",
            "Epoch 74/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7396\n",
            "Epoch 75/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7344\n",
            "Epoch 76/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7370\n",
            "Epoch 77/200\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7331\n",
            "Epoch 78/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7370\n",
            "Epoch 79/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7318\n",
            "Epoch 80/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7435\n",
            "Epoch 81/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7422\n",
            "Epoch 82/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7461\n",
            "Epoch 83/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7344\n",
            "Epoch 84/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7305\n",
            "Epoch 85/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7461\n",
            "Epoch 86/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7513\n",
            "Epoch 87/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7474\n",
            "Epoch 90/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7357\n",
            "Epoch 91/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7305\n",
            "Epoch 92/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7513\n",
            "Epoch 93/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7513\n",
            "Epoch 94/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7461\n",
            "Epoch 95/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7448\n",
            "Epoch 96/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7318\n",
            "Epoch 97/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7344\n",
            "Epoch 99/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7513\n",
            "Epoch 101/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7448\n",
            "Epoch 102/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7526\n",
            "Epoch 103/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7409\n",
            "Epoch 104/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7552\n",
            "Epoch 105/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7487\n",
            "Epoch 106/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7526\n",
            "Epoch 107/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7539\n",
            "Epoch 108/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7526\n",
            "Epoch 109/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7487\n",
            "Epoch 110/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7578\n",
            "Epoch 111/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7617\n",
            "Epoch 112/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7500\n",
            "Epoch 113/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7539\n",
            "Epoch 114/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7578\n",
            "Epoch 115/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7565\n",
            "Epoch 116/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7474\n",
            "Epoch 117/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7539\n",
            "Epoch 118/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7474\n",
            "Epoch 119/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7552\n",
            "Epoch 120/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7461\n",
            "Epoch 121/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7526\n",
            "Epoch 122/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7461\n",
            "Epoch 123/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7461\n",
            "Epoch 124/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7487\n",
            "Epoch 125/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7539\n",
            "Epoch 126/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7630\n",
            "Epoch 127/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7578\n",
            "Epoch 128/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7591\n",
            "Epoch 129/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7331\n",
            "Epoch 130/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7565\n",
            "Epoch 131/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7695\n",
            "Epoch 132/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7552\n",
            "Epoch 133/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7643\n",
            "Epoch 134/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7513\n",
            "Epoch 135/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7500\n",
            "Epoch 136/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7435\n",
            "Epoch 137/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7539\n",
            "Epoch 138/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7539\n",
            "Epoch 139/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7578\n",
            "Epoch 140/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7695\n",
            "Epoch 141/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7539\n",
            "Epoch 142/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7591\n",
            "Epoch 143/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7604\n",
            "Epoch 144/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7578\n",
            "Epoch 145/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7526\n",
            "Epoch 146/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7604\n",
            "Epoch 147/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7513\n",
            "Epoch 148/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7513\n",
            "Epoch 149/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7578\n",
            "Epoch 150/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7591\n",
            "Epoch 151/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7630\n",
            "Epoch 152/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7513\n",
            "Epoch 153/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7604\n",
            "Epoch 154/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7656\n",
            "Epoch 155/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7591\n",
            "Epoch 156/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7734\n",
            "Epoch 157/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7539\n",
            "Epoch 158/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7695\n",
            "Epoch 159/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7656\n",
            "Epoch 160/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7513\n",
            "Epoch 161/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7630\n",
            "Epoch 162/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7565\n",
            "Epoch 163/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7643\n",
            "Epoch 164/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7643\n",
            "Epoch 165/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7526\n",
            "Epoch 166/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7734\n",
            "Epoch 167/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7695\n",
            "Epoch 168/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7643\n",
            "Epoch 169/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7643\n",
            "Epoch 170/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7656\n",
            "Epoch 171/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7630\n",
            "Epoch 172/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7656\n",
            "Epoch 173/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7734\n",
            "Epoch 174/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7630\n",
            "Epoch 175/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7786\n",
            "Epoch 176/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7591\n",
            "Epoch 177/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7695\n",
            "Epoch 178/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7643\n",
            "Epoch 179/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7695\n",
            "Epoch 180/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7552\n",
            "Epoch 181/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7708\n",
            "Epoch 182/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7682\n",
            "Epoch 183/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7539\n",
            "Epoch 184/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7734\n",
            "Epoch 185/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7682\n",
            "Epoch 186/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7721\n",
            "Epoch 187/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7643\n",
            "Epoch 188/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7721\n",
            "Epoch 189/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7760\n",
            "Epoch 190/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7760\n",
            "Epoch 191/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7669\n",
            "Epoch 192/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7565\n",
            "Epoch 193/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7799\n",
            "Epoch 194/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7695\n",
            "Epoch 195/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7682\n",
            "Epoch 196/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7669\n",
            "Epoch 197/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7747\n",
            "Epoch 198/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7578\n",
            "Epoch 199/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7760\n",
            "Epoch 200/200\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7721\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7708\n",
            "\n",
            " Accuracy:0.7708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcNFXFYJCCi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials \n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1sxjj3p8_9g41_uxd1O9KHYv191_E8h7e'\n",
        "downloaded1 = drive.CreateFile({'id': file_id})\n",
        "downloaded1.GetContentFile('iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN3uDroyCnHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "cc203198-f012-486d-dd22-89f6f6c7fd66"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('iris.csv', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
        "print(df.head())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtYWBC1bC0AA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "bf6b9daf-8eb6-4729-deb1-171bc6f2ea44"
      },
      "source": [
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.pairplot(df, hue='species')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 823.25x720 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8YX2WNVDE8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = df.values\n",
        "X = dataset[:, 0:4].astype(float)\n",
        "Y_obj = dataset[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr3D6c-iDMAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LZcfO_DTSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d4eaa97-be53-4b65-b936-c1659f1d8d71"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "Y_encoded = tf.keras.utils.to_categorical(Y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8qJAeEBD1nk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e45b5d2e-9a04-4fbb-808b-4442e0f778e7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, Y_encoded, epochs=50, batch_size=1)\n",
        "print('\\n Accuracy:%.4f' % (model.evaluate(X, Y_encoded)[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 1.1056 - accuracy: 0.3867\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - 0s 891us/step - loss: 0.7203 - accuracy: 0.7333\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - 0s 887us/step - loss: 0.5782 - accuracy: 0.8467\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - 0s 903us/step - loss: 0.5086 - accuracy: 0.8533\n",
            "Epoch 5/50\n",
            "150/150 [==============================] - 0s 941us/step - loss: 0.4637 - accuracy: 0.8933\n",
            "Epoch 6/50\n",
            "150/150 [==============================] - 0s 932us/step - loss: 0.4287 - accuracy: 0.9333\n",
            "Epoch 7/50\n",
            "150/150 [==============================] - 0s 894us/step - loss: 0.4032 - accuracy: 0.9400\n",
            "Epoch 8/50\n",
            "150/150 [==============================] - 0s 937us/step - loss: 0.3873 - accuracy: 0.9267\n",
            "Epoch 9/50\n",
            "150/150 [==============================] - 0s 913us/step - loss: 0.3702 - accuracy: 0.9267\n",
            "Epoch 10/50\n",
            "150/150 [==============================] - 0s 914us/step - loss: 0.3560 - accuracy: 0.9733\n",
            "Epoch 11/50\n",
            "150/150 [==============================] - 0s 992us/step - loss: 0.3428 - accuracy: 0.9333\n",
            "Epoch 12/50\n",
            "150/150 [==============================] - 0s 924us/step - loss: 0.3301 - accuracy: 0.9400\n",
            "Epoch 13/50\n",
            "150/150 [==============================] - 0s 940us/step - loss: 0.3239 - accuracy: 0.9600\n",
            "Epoch 14/50\n",
            "150/150 [==============================] - 0s 997us/step - loss: 0.3075 - accuracy: 0.9667\n",
            "Epoch 15/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.9667\n",
            "Epoch 16/50\n",
            "150/150 [==============================] - 0s 944us/step - loss: 0.2878 - accuracy: 0.9600\n",
            "Epoch 17/50\n",
            "150/150 [==============================] - 0s 914us/step - loss: 0.2819 - accuracy: 0.9600\n",
            "Epoch 18/50\n",
            "150/150 [==============================] - 0s 963us/step - loss: 0.2775 - accuracy: 0.9533\n",
            "Epoch 19/50\n",
            "150/150 [==============================] - 0s 987us/step - loss: 0.2638 - accuracy: 0.9733\n",
            "Epoch 20/50\n",
            "150/150 [==============================] - 0s 942us/step - loss: 0.2542 - accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "150/150 [==============================] - 0s 919us/step - loss: 0.2468 - accuracy: 0.9733\n",
            "Epoch 22/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9667\n",
            "Epoch 23/50\n",
            "150/150 [==============================] - 0s 914us/step - loss: 0.2322 - accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9667\n",
            "Epoch 25/50\n",
            "150/150 [==============================] - 0s 969us/step - loss: 0.2166 - accuracy: 0.9800\n",
            "Epoch 26/50\n",
            "150/150 [==============================] - 0s 963us/step - loss: 0.2145 - accuracy: 0.9733\n",
            "Epoch 27/50\n",
            "150/150 [==============================] - 0s 897us/step - loss: 0.2071 - accuracy: 0.9667\n",
            "Epoch 28/50\n",
            "150/150 [==============================] - 0s 975us/step - loss: 0.1939 - accuracy: 0.9733\n",
            "Epoch 29/50\n",
            "150/150 [==============================] - 0s 968us/step - loss: 0.1961 - accuracy: 0.9533\n",
            "Epoch 30/50\n",
            "150/150 [==============================] - 0s 936us/step - loss: 0.1938 - accuracy: 0.9600\n",
            "Epoch 31/50\n",
            "150/150 [==============================] - 0s 910us/step - loss: 0.1866 - accuracy: 0.9667\n",
            "Epoch 32/50\n",
            "150/150 [==============================] - 0s 939us/step - loss: 0.1803 - accuracy: 0.9733\n",
            "Epoch 33/50\n",
            "150/150 [==============================] - 0s 943us/step - loss: 0.1769 - accuracy: 0.9800\n",
            "Epoch 34/50\n",
            "150/150 [==============================] - 0s 922us/step - loss: 0.1707 - accuracy: 0.9667\n",
            "Epoch 35/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9733\n",
            "Epoch 36/50\n",
            "150/150 [==============================] - 0s 986us/step - loss: 0.1674 - accuracy: 0.9667\n",
            "Epoch 37/50\n",
            "150/150 [==============================] - 0s 901us/step - loss: 0.1570 - accuracy: 0.9600\n",
            "Epoch 38/50\n",
            "150/150 [==============================] - 0s 983us/step - loss: 0.1581 - accuracy: 0.9667\n",
            "Epoch 39/50\n",
            "150/150 [==============================] - 0s 1000us/step - loss: 0.1506 - accuracy: 0.9733\n",
            "Epoch 40/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9600\n",
            "Epoch 41/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9667\n",
            "Epoch 42/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9800\n",
            "Epoch 43/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9800\n",
            "Epoch 44/50\n",
            "150/150 [==============================] - 0s 999us/step - loss: 0.1375 - accuracy: 0.9667\n",
            "Epoch 45/50\n",
            "150/150 [==============================] - 0s 959us/step - loss: 0.1388 - accuracy: 0.9600\n",
            "Epoch 46/50\n",
            "150/150 [==============================] - 0s 922us/step - loss: 0.1336 - accuracy: 0.9667\n",
            "Epoch 47/50\n",
            "150/150 [==============================] - 0s 901us/step - loss: 0.1344 - accuracy: 0.9600\n",
            "Epoch 48/50\n",
            "150/150 [==============================] - 0s 912us/step - loss: 0.1294 - accuracy: 0.9667\n",
            "Epoch 49/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9667\n",
            "Epoch 50/50\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9600\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9733\n",
            "\n",
            " Accuracy:0.9733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjHaNtsDExYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '1fB7IcP3uIG0L-hLzm65UyrPnvx4MnifP'\n",
        "downloaded2 = drive.CreateFile({'id': file_id})\n",
        "downloaded2.GetContentFile('sonar.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koCjJnRrE34c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af683729-7dae-45b4-ac86-01892c485b56"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('sonar.csv', header=None)\n",
        "print(df.info())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       208 non-null    float64\n",
            " 1   1       208 non-null    float64\n",
            " 2   2       208 non-null    float64\n",
            " 3   3       208 non-null    float64\n",
            " 4   4       208 non-null    float64\n",
            " 5   5       208 non-null    float64\n",
            " 6   6       208 non-null    float64\n",
            " 7   7       208 non-null    float64\n",
            " 8   8       208 non-null    float64\n",
            " 9   9       208 non-null    float64\n",
            " 10  10      208 non-null    float64\n",
            " 11  11      208 non-null    float64\n",
            " 12  12      208 non-null    float64\n",
            " 13  13      208 non-null    float64\n",
            " 14  14      208 non-null    float64\n",
            " 15  15      208 non-null    float64\n",
            " 16  16      208 non-null    float64\n",
            " 17  17      208 non-null    float64\n",
            " 18  18      208 non-null    float64\n",
            " 19  19      208 non-null    float64\n",
            " 20  20      208 non-null    float64\n",
            " 21  21      208 non-null    float64\n",
            " 22  22      208 non-null    float64\n",
            " 23  23      208 non-null    float64\n",
            " 24  24      208 non-null    float64\n",
            " 25  25      208 non-null    float64\n",
            " 26  26      208 non-null    float64\n",
            " 27  27      208 non-null    float64\n",
            " 28  28      208 non-null    float64\n",
            " 29  29      208 non-null    float64\n",
            " 30  30      208 non-null    float64\n",
            " 31  31      208 non-null    float64\n",
            " 32  32      208 non-null    float64\n",
            " 33  33      208 non-null    float64\n",
            " 34  34      208 non-null    float64\n",
            " 35  35      208 non-null    float64\n",
            " 36  36      208 non-null    float64\n",
            " 37  37      208 non-null    float64\n",
            " 38  38      208 non-null    float64\n",
            " 39  39      208 non-null    float64\n",
            " 40  40      208 non-null    float64\n",
            " 41  41      208 non-null    float64\n",
            " 42  42      208 non-null    float64\n",
            " 43  43      208 non-null    float64\n",
            " 44  44      208 non-null    float64\n",
            " 45  45      208 non-null    float64\n",
            " 46  46      208 non-null    float64\n",
            " 47  47      208 non-null    float64\n",
            " 48  48      208 non-null    float64\n",
            " 49  49      208 non-null    float64\n",
            " 50  50      208 non-null    float64\n",
            " 51  51      208 non-null    float64\n",
            " 52  52      208 non-null    float64\n",
            " 53  53      208 non-null    float64\n",
            " 54  54      208 non-null    float64\n",
            " 55  55      208 non-null    float64\n",
            " 56  56      208 non-null    float64\n",
            " 57  57      208 non-null    float64\n",
            " 58  58      208 non-null    float64\n",
            " 59  59      208 non-null    float64\n",
            " 60  60      208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIgssICnFAqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "cf8843ca-d208-4a17-bb18-0bf70c4dcf02"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0       1       2       3       4   ...      56      57      58      59  60\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXBBmUN0FDUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf9f14d5-d261-4012-ee36-f8696d930e2f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "df = pd.read_csv('sonar.csv', header=None)\n",
        "\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:60]\n",
        "Y_obj = dataset[:, 60]\n",
        "\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, Y, epochs=200, batch_size=5)\n",
        "\n",
        "print('\\n Accuracy:%.4f'%(model.evaluate(X, Y)[1]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "208/208 [==============================] - 0s 592us/step - loss: 0.2469 - accuracy: 0.5625\n",
            "Epoch 2/200\n",
            "208/208 [==============================] - 0s 213us/step - loss: 0.2408 - accuracy: 0.5433\n",
            "Epoch 3/200\n",
            "208/208 [==============================] - 0s 235us/step - loss: 0.2272 - accuracy: 0.6106\n",
            "Epoch 4/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.2185 - accuracy: 0.6346\n",
            "Epoch 5/200\n",
            "208/208 [==============================] - 0s 218us/step - loss: 0.2099 - accuracy: 0.6971\n",
            "Epoch 6/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.2024 - accuracy: 0.7212\n",
            "Epoch 7/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.1938 - accuracy: 0.7404\n",
            "Epoch 8/200\n",
            "208/208 [==============================] - 0s 220us/step - loss: 0.1852 - accuracy: 0.7740\n",
            "Epoch 9/200\n",
            "208/208 [==============================] - 0s 215us/step - loss: 0.1753 - accuracy: 0.7981\n",
            "Epoch 10/200\n",
            "208/208 [==============================] - 0s 241us/step - loss: 0.1633 - accuracy: 0.8029\n",
            "Epoch 11/200\n",
            "208/208 [==============================] - 0s 247us/step - loss: 0.1556 - accuracy: 0.7933\n",
            "Epoch 12/200\n",
            "208/208 [==============================] - 0s 230us/step - loss: 0.1504 - accuracy: 0.8029\n",
            "Epoch 13/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.1466 - accuracy: 0.7981\n",
            "Epoch 14/200\n",
            "208/208 [==============================] - 0s 216us/step - loss: 0.1428 - accuracy: 0.8173\n",
            "Epoch 15/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.1403 - accuracy: 0.8029\n",
            "Epoch 16/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.1342 - accuracy: 0.8125\n",
            "Epoch 17/200\n",
            "208/208 [==============================] - 0s 238us/step - loss: 0.1326 - accuracy: 0.8125\n",
            "Epoch 18/200\n",
            "208/208 [==============================] - 0s 249us/step - loss: 0.1271 - accuracy: 0.8269\n",
            "Epoch 19/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.1198 - accuracy: 0.8365\n",
            "Epoch 20/200\n",
            "208/208 [==============================] - 0s 237us/step - loss: 0.1174 - accuracy: 0.8510\n",
            "Epoch 21/200\n",
            "208/208 [==============================] - 0s 227us/step - loss: 0.1149 - accuracy: 0.8606\n",
            "Epoch 22/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.1070 - accuracy: 0.8606\n",
            "Epoch 23/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.1193 - accuracy: 0.8221\n",
            "Epoch 24/200\n",
            "208/208 [==============================] - 0s 236us/step - loss: 0.1058 - accuracy: 0.8606\n",
            "Epoch 25/200\n",
            "208/208 [==============================] - 0s 230us/step - loss: 0.1061 - accuracy: 0.8510\n",
            "Epoch 26/200\n",
            "208/208 [==============================] - 0s 231us/step - loss: 0.1012 - accuracy: 0.8702\n",
            "Epoch 27/200\n",
            "208/208 [==============================] - 0s 236us/step - loss: 0.0979 - accuracy: 0.8846\n",
            "Epoch 28/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0999 - accuracy: 0.8798\n",
            "Epoch 29/200\n",
            "208/208 [==============================] - 0s 234us/step - loss: 0.0959 - accuracy: 0.8798\n",
            "Epoch 30/200\n",
            "208/208 [==============================] - 0s 233us/step - loss: 0.0908 - accuracy: 0.8894\n",
            "Epoch 31/200\n",
            "208/208 [==============================] - 0s 261us/step - loss: 0.0863 - accuracy: 0.8942\n",
            "Epoch 32/200\n",
            "208/208 [==============================] - 0s 238us/step - loss: 0.0940 - accuracy: 0.8606\n",
            "Epoch 33/200\n",
            "208/208 [==============================] - 0s 215us/step - loss: 0.0919 - accuracy: 0.8942\n",
            "Epoch 34/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0863 - accuracy: 0.8990\n",
            "Epoch 35/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0852 - accuracy: 0.8942\n",
            "Epoch 36/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0805 - accuracy: 0.8942\n",
            "Epoch 37/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0803 - accuracy: 0.9087\n",
            "Epoch 38/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.0782 - accuracy: 0.9087\n",
            "Epoch 39/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0778 - accuracy: 0.9183\n",
            "Epoch 40/200\n",
            "208/208 [==============================] - 0s 240us/step - loss: 0.0736 - accuracy: 0.9231\n",
            "Epoch 41/200\n",
            "208/208 [==============================] - 0s 246us/step - loss: 0.0746 - accuracy: 0.9038\n",
            "Epoch 42/200\n",
            "208/208 [==============================] - 0s 227us/step - loss: 0.0704 - accuracy: 0.9135\n",
            "Epoch 43/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0672 - accuracy: 0.9423\n",
            "Epoch 44/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0706 - accuracy: 0.9135\n",
            "Epoch 45/200\n",
            "208/208 [==============================] - 0s 230us/step - loss: 0.0632 - accuracy: 0.9327\n",
            "Epoch 46/200\n",
            "208/208 [==============================] - 0s 208us/step - loss: 0.0634 - accuracy: 0.9375\n",
            "Epoch 47/200\n",
            "208/208 [==============================] - 0s 245us/step - loss: 0.0591 - accuracy: 0.9519\n",
            "Epoch 48/200\n",
            "208/208 [==============================] - 0s 230us/step - loss: 0.0612 - accuracy: 0.9375\n",
            "Epoch 49/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0573 - accuracy: 0.9423\n",
            "Epoch 50/200\n",
            "208/208 [==============================] - 0s 230us/step - loss: 0.0566 - accuracy: 0.9519\n",
            "Epoch 51/200\n",
            "208/208 [==============================] - 0s 219us/step - loss: 0.0564 - accuracy: 0.9423\n",
            "Epoch 52/200\n",
            "208/208 [==============================] - 0s 239us/step - loss: 0.0516 - accuracy: 0.9519\n",
            "Epoch 53/200\n",
            "208/208 [==============================] - 0s 215us/step - loss: 0.0573 - accuracy: 0.9423\n",
            "Epoch 54/200\n",
            "208/208 [==============================] - 0s 220us/step - loss: 0.0528 - accuracy: 0.9471\n",
            "Epoch 55/200\n",
            "208/208 [==============================] - 0s 219us/step - loss: 0.0524 - accuracy: 0.9423\n",
            "Epoch 56/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0474 - accuracy: 0.9712\n",
            "Epoch 57/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0467 - accuracy: 0.9663\n",
            "Epoch 58/200\n",
            "208/208 [==============================] - 0s 238us/step - loss: 0.0452 - accuracy: 0.9712\n",
            "Epoch 59/200\n",
            "208/208 [==============================] - 0s 247us/step - loss: 0.0473 - accuracy: 0.9663\n",
            "Epoch 60/200\n",
            "208/208 [==============================] - 0s 243us/step - loss: 0.0429 - accuracy: 0.9712\n",
            "Epoch 61/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0423 - accuracy: 0.9760\n",
            "Epoch 62/200\n",
            "208/208 [==============================] - 0s 219us/step - loss: 0.0405 - accuracy: 0.9760\n",
            "Epoch 63/200\n",
            "208/208 [==============================] - 0s 222us/step - loss: 0.0401 - accuracy: 0.9712\n",
            "Epoch 64/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0379 - accuracy: 0.9808\n",
            "Epoch 65/200\n",
            "208/208 [==============================] - 0s 222us/step - loss: 0.0367 - accuracy: 0.9808\n",
            "Epoch 66/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0397 - accuracy: 0.9663\n",
            "Epoch 67/200\n",
            "208/208 [==============================] - 0s 243us/step - loss: 0.0377 - accuracy: 0.9712\n",
            "Epoch 68/200\n",
            "208/208 [==============================] - 0s 217us/step - loss: 0.0352 - accuracy: 0.9615\n",
            "Epoch 69/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0325 - accuracy: 0.9856\n",
            "Epoch 70/200\n",
            "208/208 [==============================] - 0s 217us/step - loss: 0.0339 - accuracy: 0.9712\n",
            "Epoch 71/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0330 - accuracy: 0.9760\n",
            "Epoch 72/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0306 - accuracy: 0.9808\n",
            "Epoch 73/200\n",
            "208/208 [==============================] - 0s 246us/step - loss: 0.0371 - accuracy: 0.9663\n",
            "Epoch 74/200\n",
            "208/208 [==============================] - 0s 222us/step - loss: 0.0318 - accuracy: 0.9808\n",
            "Epoch 75/200\n",
            "208/208 [==============================] - 0s 220us/step - loss: 0.0325 - accuracy: 0.9808\n",
            "Epoch 76/200\n",
            "208/208 [==============================] - 0s 215us/step - loss: 0.0291 - accuracy: 0.9808\n",
            "Epoch 77/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0284 - accuracy: 0.9808\n",
            "Epoch 78/200\n",
            "208/208 [==============================] - 0s 222us/step - loss: 0.0273 - accuracy: 0.9856\n",
            "Epoch 79/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0261 - accuracy: 0.9808\n",
            "Epoch 80/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.0266 - accuracy: 0.9760\n",
            "Epoch 81/200\n",
            "208/208 [==============================] - 0s 241us/step - loss: 0.0254 - accuracy: 0.9808\n",
            "Epoch 82/200\n",
            "208/208 [==============================] - 0s 249us/step - loss: 0.0263 - accuracy: 0.9808\n",
            "Epoch 83/200\n",
            "208/208 [==============================] - 0s 233us/step - loss: 0.0253 - accuracy: 0.9808\n",
            "Epoch 84/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.0234 - accuracy: 0.9808\n",
            "Epoch 85/200\n",
            "208/208 [==============================] - 0s 218us/step - loss: 0.0238 - accuracy: 0.9856\n",
            "Epoch 86/200\n",
            "208/208 [==============================] - 0s 273us/step - loss: 0.0219 - accuracy: 0.9856\n",
            "Epoch 87/200\n",
            "208/208 [==============================] - 0s 255us/step - loss: 0.0214 - accuracy: 0.9856\n",
            "Epoch 88/200\n",
            "208/208 [==============================] - 0s 253us/step - loss: 0.0237 - accuracy: 0.9856\n",
            "Epoch 89/200\n",
            "208/208 [==============================] - 0s 256us/step - loss: 0.0229 - accuracy: 0.9808\n",
            "Epoch 90/200\n",
            "208/208 [==============================] - 0s 256us/step - loss: 0.0201 - accuracy: 0.9856\n",
            "Epoch 91/200\n",
            "208/208 [==============================] - 0s 298us/step - loss: 0.0191 - accuracy: 0.9856\n",
            "Epoch 92/200\n",
            "208/208 [==============================] - 0s 282us/step - loss: 0.0182 - accuracy: 0.9904\n",
            "Epoch 93/200\n",
            "208/208 [==============================] - 0s 248us/step - loss: 0.0199 - accuracy: 0.9808\n",
            "Epoch 94/200\n",
            "208/208 [==============================] - 0s 245us/step - loss: 0.0183 - accuracy: 0.9904\n",
            "Epoch 95/200\n",
            "208/208 [==============================] - 0s 251us/step - loss: 0.0186 - accuracy: 0.9904\n",
            "Epoch 96/200\n",
            "208/208 [==============================] - 0s 246us/step - loss: 0.0169 - accuracy: 0.9856\n",
            "Epoch 97/200\n",
            "208/208 [==============================] - 0s 250us/step - loss: 0.0150 - accuracy: 0.9952\n",
            "Epoch 98/200\n",
            "208/208 [==============================] - 0s 240us/step - loss: 0.0174 - accuracy: 0.9952\n",
            "Epoch 99/200\n",
            "208/208 [==============================] - 0s 248us/step - loss: 0.0161 - accuracy: 0.9952\n",
            "Epoch 100/200\n",
            "208/208 [==============================] - 0s 263us/step - loss: 0.0164 - accuracy: 0.9856\n",
            "Epoch 101/200\n",
            "208/208 [==============================] - 0s 250us/step - loss: 0.0147 - accuracy: 0.9952\n",
            "Epoch 102/200\n",
            "208/208 [==============================] - 0s 232us/step - loss: 0.0158 - accuracy: 0.9856\n",
            "Epoch 103/200\n",
            "208/208 [==============================] - 0s 247us/step - loss: 0.0142 - accuracy: 0.9952\n",
            "Epoch 104/200\n",
            "208/208 [==============================] - 0s 253us/step - loss: 0.0148 - accuracy: 0.9952\n",
            "Epoch 105/200\n",
            "208/208 [==============================] - 0s 281us/step - loss: 0.0130 - accuracy: 0.9952\n",
            "Epoch 106/200\n",
            "208/208 [==============================] - 0s 257us/step - loss: 0.0138 - accuracy: 0.9952\n",
            "Epoch 107/200\n",
            "208/208 [==============================] - 0s 255us/step - loss: 0.0125 - accuracy: 0.9952\n",
            "Epoch 108/200\n",
            "208/208 [==============================] - 0s 256us/step - loss: 0.0114 - accuracy: 0.9952\n",
            "Epoch 109/200\n",
            "208/208 [==============================] - 0s 254us/step - loss: 0.0125 - accuracy: 0.9952\n",
            "Epoch 110/200\n",
            "208/208 [==============================] - 0s 254us/step - loss: 0.0139 - accuracy: 0.9904\n",
            "Epoch 111/200\n",
            "208/208 [==============================] - 0s 300us/step - loss: 0.0123 - accuracy: 0.9952\n",
            "Epoch 112/200\n",
            "208/208 [==============================] - 0s 236us/step - loss: 0.0125 - accuracy: 0.9952\n",
            "Epoch 113/200\n",
            "208/208 [==============================] - 0s 260us/step - loss: 0.0113 - accuracy: 0.9952\n",
            "Epoch 114/200\n",
            "208/208 [==============================] - 0s 253us/step - loss: 0.0102 - accuracy: 0.9952\n",
            "Epoch 115/200\n",
            "208/208 [==============================] - 0s 254us/step - loss: 0.0108 - accuracy: 0.9952\n",
            "Epoch 116/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0125 - accuracy: 0.9952\n",
            "Epoch 117/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0105 - accuracy: 0.9952\n",
            "Epoch 118/200\n",
            "208/208 [==============================] - 0s 215us/step - loss: 0.0093 - accuracy: 0.9952\n",
            "Epoch 119/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.0094 - accuracy: 0.9952\n",
            "Epoch 120/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0103 - accuracy: 0.9952\n",
            "Epoch 121/200\n",
            "208/208 [==============================] - 0s 212us/step - loss: 0.0090 - accuracy: 0.9952\n",
            "Epoch 122/200\n",
            "208/208 [==============================] - 0s 213us/step - loss: 0.0092 - accuracy: 0.9952\n",
            "Epoch 123/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0089 - accuracy: 0.9952\n",
            "Epoch 124/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0091 - accuracy: 0.9952\n",
            "Epoch 125/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0084 - accuracy: 0.9952\n",
            "Epoch 126/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0086 - accuracy: 0.9952\n",
            "Epoch 127/200\n",
            "208/208 [==============================] - 0s 232us/step - loss: 0.0083 - accuracy: 0.9952\n",
            "Epoch 128/200\n",
            "208/208 [==============================] - 0s 220us/step - loss: 0.0081 - accuracy: 0.9952\n",
            "Epoch 129/200\n",
            "208/208 [==============================] - 0s 235us/step - loss: 0.0077 - accuracy: 0.9952\n",
            "Epoch 130/200\n",
            "208/208 [==============================] - 0s 249us/step - loss: 0.0081 - accuracy: 0.9952\n",
            "Epoch 131/200\n",
            "208/208 [==============================] - 0s 253us/step - loss: 0.0076 - accuracy: 0.9952\n",
            "Epoch 132/200\n",
            "208/208 [==============================] - 0s 222us/step - loss: 0.0074 - accuracy: 0.9952\n",
            "Epoch 133/200\n",
            "208/208 [==============================] - 0s 231us/step - loss: 0.0078 - accuracy: 0.9952\n",
            "Epoch 134/200\n",
            "208/208 [==============================] - 0s 236us/step - loss: 0.0072 - accuracy: 0.9952\n",
            "Epoch 135/200\n",
            "208/208 [==============================] - 0s 249us/step - loss: 0.0072 - accuracy: 0.9952\n",
            "Epoch 136/200\n",
            "208/208 [==============================] - 0s 222us/step - loss: 0.0110 - accuracy: 0.9904\n",
            "Epoch 137/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.0093 - accuracy: 0.9952\n",
            "Epoch 138/200\n",
            "208/208 [==============================] - 0s 251us/step - loss: 0.0070 - accuracy: 0.9952\n",
            "Epoch 139/200\n",
            "208/208 [==============================] - 0s 249us/step - loss: 0.0083 - accuracy: 0.9952\n",
            "Epoch 140/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0073 - accuracy: 0.9952\n",
            "Epoch 141/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0064 - accuracy: 0.9952\n",
            "Epoch 142/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.0065 - accuracy: 0.9952\n",
            "Epoch 143/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0067 - accuracy: 0.9952\n",
            "Epoch 144/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0063 - accuracy: 0.9952\n",
            "Epoch 145/200\n",
            "208/208 [==============================] - 0s 213us/step - loss: 0.0063 - accuracy: 0.9952\n",
            "Epoch 146/200\n",
            "208/208 [==============================] - 0s 218us/step - loss: 0.0063 - accuracy: 0.9952\n",
            "Epoch 147/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0062 - accuracy: 0.9952\n",
            "Epoch 148/200\n",
            "208/208 [==============================] - 0s 231us/step - loss: 0.0061 - accuracy: 0.9952\n",
            "Epoch 149/200\n",
            "208/208 [==============================] - 0s 232us/step - loss: 0.0062 - accuracy: 0.9952\n",
            "Epoch 150/200\n",
            "208/208 [==============================] - 0s 219us/step - loss: 0.0061 - accuracy: 0.9952\n",
            "Epoch 151/200\n",
            "208/208 [==============================] - 0s 218us/step - loss: 0.0061 - accuracy: 0.9952\n",
            "Epoch 152/200\n",
            "208/208 [==============================] - 0s 248us/step - loss: 0.0060 - accuracy: 0.9952\n",
            "Epoch 153/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0060 - accuracy: 0.9952\n",
            "Epoch 154/200\n",
            "208/208 [==============================] - 0s 220us/step - loss: 0.0059 - accuracy: 0.9952\n",
            "Epoch 155/200\n",
            "208/208 [==============================] - 0s 220us/step - loss: 0.0060 - accuracy: 0.9952\n",
            "Epoch 156/200\n",
            "208/208 [==============================] - 0s 223us/step - loss: 0.0058 - accuracy: 0.9952\n",
            "Epoch 157/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0057 - accuracy: 0.9952\n",
            "Epoch 158/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0057 - accuracy: 0.9952\n",
            "Epoch 159/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.0057 - accuracy: 0.9952\n",
            "Epoch 160/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0056 - accuracy: 0.9952\n",
            "Epoch 161/200\n",
            "208/208 [==============================] - 0s 227us/step - loss: 0.0057 - accuracy: 0.9952\n",
            "Epoch 162/200\n",
            "208/208 [==============================] - 0s 230us/step - loss: 0.0055 - accuracy: 0.9952\n",
            "Epoch 163/200\n",
            "208/208 [==============================] - 0s 242us/step - loss: 0.0055 - accuracy: 0.9952\n",
            "Epoch 164/200\n",
            "208/208 [==============================] - 0s 228us/step - loss: 0.0056 - accuracy: 0.9952\n",
            "Epoch 165/200\n",
            "208/208 [==============================] - 0s 229us/step - loss: 0.0055 - accuracy: 0.9952\n",
            "Epoch 166/200\n",
            "208/208 [==============================] - 0s 243us/step - loss: 0.0054 - accuracy: 0.9952\n",
            "Epoch 167/200\n",
            "208/208 [==============================] - 0s 219us/step - loss: 0.0055 - accuracy: 0.9952\n",
            "Epoch 168/200\n",
            "208/208 [==============================] - 0s 232us/step - loss: 0.0054 - accuracy: 0.9952\n",
            "Epoch 169/200\n",
            "208/208 [==============================] - 0s 292us/step - loss: 0.0052 - accuracy: 0.9952\n",
            "Epoch 170/200\n",
            "208/208 [==============================] - 0s 219us/step - loss: 0.0055 - accuracy: 0.9952\n",
            "Epoch 171/200\n",
            "208/208 [==============================] - 0s 247us/step - loss: 0.0053 - accuracy: 0.9952\n",
            "Epoch 172/200\n",
            "208/208 [==============================] - 0s 243us/step - loss: 0.0053 - accuracy: 0.9952\n",
            "Epoch 173/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0052 - accuracy: 0.9952\n",
            "Epoch 174/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0051 - accuracy: 0.9952\n",
            "Epoch 175/200\n",
            "208/208 [==============================] - 0s 238us/step - loss: 0.0049 - accuracy: 0.9952\n",
            "Epoch 176/200\n",
            "208/208 [==============================] - 0s 265us/step - loss: 0.0049 - accuracy: 0.9952\n",
            "Epoch 177/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0046 - accuracy: 0.9952\n",
            "Epoch 178/200\n",
            "208/208 [==============================] - 0s 218us/step - loss: 0.0046 - accuracy: 0.9952\n",
            "Epoch 179/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.0042 - accuracy: 0.9952\n",
            "Epoch 180/200\n",
            "208/208 [==============================] - 0s 227us/step - loss: 0.0150 - accuracy: 0.9856\n",
            "Epoch 181/200\n",
            "208/208 [==============================] - 0s 233us/step - loss: 0.0153 - accuracy: 0.9760\n",
            "Epoch 182/200\n",
            "208/208 [==============================] - 0s 233us/step - loss: 0.0078 - accuracy: 0.9856\n",
            "Epoch 183/200\n",
            "208/208 [==============================] - 0s 317us/step - loss: 0.0067 - accuracy: 0.9952\n",
            "Epoch 184/200\n",
            "208/208 [==============================] - 0s 236us/step - loss: 0.0030 - accuracy: 0.9952\n",
            "Epoch 185/200\n",
            "208/208 [==============================] - 0s 225us/step - loss: 0.0023 - accuracy: 0.9952\n",
            "Epoch 186/200\n",
            "208/208 [==============================] - 0s 226us/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "208/208 [==============================] - 0s 221us/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "208/208 [==============================] - 0s 224us/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "208/208 [==============================] - 0s 255us/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "208/208 [==============================] - 0s 266us/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "208/208 [==============================] - 0s 248us/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "208/208 [==============================] - 0s 323us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "208/208 [==============================] - 0s 239us/step - loss: 8.3749e-04 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "208/208 [==============================] - 0s 251us/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "208/208 [==============================] - 0s 264us/step - loss: 6.9313e-04 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "208/208 [==============================] - 0s 282us/step - loss: 7.4520e-04 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "208/208 [==============================] - 0s 239us/step - loss: 7.8066e-04 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "208/208 [==============================] - 0s 250us/step - loss: 7.2201e-04 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "208/208 [==============================] - 0s 245us/step - loss: 5.8980e-04 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "208/208 [==============================] - 0s 237us/step - loss: 5.9300e-04 - accuracy: 1.0000\n",
            "208/208 [==============================] - 0s 99us/step\n",
            "\n",
            " Accuracy:1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHX_O00HoX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9ef267a-b82a-4e24-ef67-76e4c46a3dca"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "df = pd.read_csv('sonar.csv', header=None)\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:60]\n",
        "Y_obj = dataset[:, 60]\n",
        "\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_dim=60, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, epochs=130, batch_size=5)\n",
        "\n",
        "print('\\n Test Accuracy:%.4f'%(model.evaluate(X_test, Y_test)[1]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/130\n",
            "145/145 [==============================] - 0s 832us/step - loss: 0.2522 - accuracy: 0.5310\n",
            "Epoch 2/130\n",
            "145/145 [==============================] - 0s 259us/step - loss: 0.2463 - accuracy: 0.5172\n",
            "Epoch 3/130\n",
            "145/145 [==============================] - 0s 251us/step - loss: 0.2440 - accuracy: 0.5379\n",
            "Epoch 4/130\n",
            "145/145 [==============================] - 0s 255us/step - loss: 0.2420 - accuracy: 0.5310\n",
            "Epoch 5/130\n",
            "145/145 [==============================] - 0s 264us/step - loss: 0.2398 - accuracy: 0.5448\n",
            "Epoch 6/130\n",
            "145/145 [==============================] - 0s 264us/step - loss: 0.2382 - accuracy: 0.5517\n",
            "Epoch 7/130\n",
            "145/145 [==============================] - 0s 265us/step - loss: 0.2340 - accuracy: 0.5448\n",
            "Epoch 8/130\n",
            "145/145 [==============================] - 0s 230us/step - loss: 0.2300 - accuracy: 0.5586\n",
            "Epoch 9/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.2211 - accuracy: 0.6552\n",
            "Epoch 10/130\n",
            "145/145 [==============================] - 0s 251us/step - loss: 0.2130 - accuracy: 0.6621\n",
            "Epoch 11/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.2081 - accuracy: 0.6552\n",
            "Epoch 12/130\n",
            "145/145 [==============================] - 0s 222us/step - loss: 0.2021 - accuracy: 0.7103\n",
            "Epoch 13/130\n",
            "145/145 [==============================] - 0s 231us/step - loss: 0.1888 - accuracy: 0.7172\n",
            "Epoch 14/130\n",
            "145/145 [==============================] - 0s 230us/step - loss: 0.1777 - accuracy: 0.7310\n",
            "Epoch 15/130\n",
            "145/145 [==============================] - 0s 236us/step - loss: 0.1712 - accuracy: 0.7586\n",
            "Epoch 16/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.1651 - accuracy: 0.7724\n",
            "Epoch 17/130\n",
            "145/145 [==============================] - 0s 223us/step - loss: 0.1603 - accuracy: 0.7655\n",
            "Epoch 18/130\n",
            "145/145 [==============================] - 0s 242us/step - loss: 0.1558 - accuracy: 0.7655\n",
            "Epoch 19/130\n",
            "145/145 [==============================] - 0s 232us/step - loss: 0.1540 - accuracy: 0.7862\n",
            "Epoch 20/130\n",
            "145/145 [==============================] - 0s 242us/step - loss: 0.1487 - accuracy: 0.7931\n",
            "Epoch 21/130\n",
            "145/145 [==============================] - 0s 236us/step - loss: 0.1493 - accuracy: 0.8069\n",
            "Epoch 22/130\n",
            "145/145 [==============================] - 0s 223us/step - loss: 0.1436 - accuracy: 0.8138\n",
            "Epoch 23/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.1427 - accuracy: 0.8000\n",
            "Epoch 24/130\n",
            "145/145 [==============================] - 0s 224us/step - loss: 0.1366 - accuracy: 0.8345\n",
            "Epoch 25/130\n",
            "145/145 [==============================] - 0s 224us/step - loss: 0.1356 - accuracy: 0.8414\n",
            "Epoch 26/130\n",
            "145/145 [==============================] - 0s 259us/step - loss: 0.1351 - accuracy: 0.8345\n",
            "Epoch 27/130\n",
            "145/145 [==============================] - 0s 263us/step - loss: 0.1309 - accuracy: 0.8483\n",
            "Epoch 28/130\n",
            "145/145 [==============================] - 0s 275us/step - loss: 0.1353 - accuracy: 0.8069\n",
            "Epoch 29/130\n",
            "145/145 [==============================] - 0s 280us/step - loss: 0.1282 - accuracy: 0.8483\n",
            "Epoch 30/130\n",
            "145/145 [==============================] - 0s 248us/step - loss: 0.1359 - accuracy: 0.8138\n",
            "Epoch 31/130\n",
            "145/145 [==============================] - 0s 233us/step - loss: 0.1263 - accuracy: 0.8276\n",
            "Epoch 32/130\n",
            "145/145 [==============================] - 0s 237us/step - loss: 0.1259 - accuracy: 0.8483\n",
            "Epoch 33/130\n",
            "145/145 [==============================] - 0s 232us/step - loss: 0.1213 - accuracy: 0.8483\n",
            "Epoch 34/130\n",
            "145/145 [==============================] - 0s 227us/step - loss: 0.1204 - accuracy: 0.8621\n",
            "Epoch 35/130\n",
            "145/145 [==============================] - 0s 227us/step - loss: 0.1201 - accuracy: 0.8621\n",
            "Epoch 36/130\n",
            "145/145 [==============================] - 0s 261us/step - loss: 0.1217 - accuracy: 0.8621\n",
            "Epoch 37/130\n",
            "145/145 [==============================] - 0s 226us/step - loss: 0.1221 - accuracy: 0.8276\n",
            "Epoch 38/130\n",
            "145/145 [==============================] - 0s 223us/step - loss: 0.1117 - accuracy: 0.8483\n",
            "Epoch 39/130\n",
            "145/145 [==============================] - 0s 239us/step - loss: 0.1138 - accuracy: 0.8552\n",
            "Epoch 40/130\n",
            "145/145 [==============================] - 0s 238us/step - loss: 0.1111 - accuracy: 0.8552\n",
            "Epoch 41/130\n",
            "145/145 [==============================] - 0s 232us/step - loss: 0.1106 - accuracy: 0.8483\n",
            "Epoch 42/130\n",
            "145/145 [==============================] - 0s 226us/step - loss: 0.1084 - accuracy: 0.8552\n",
            "Epoch 43/130\n",
            "145/145 [==============================] - 0s 243us/step - loss: 0.1085 - accuracy: 0.8621\n",
            "Epoch 44/130\n",
            "145/145 [==============================] - 0s 234us/step - loss: 0.1069 - accuracy: 0.8621\n",
            "Epoch 45/130\n",
            "145/145 [==============================] - 0s 233us/step - loss: 0.1070 - accuracy: 0.8414\n",
            "Epoch 46/130\n",
            "145/145 [==============================] - 0s 223us/step - loss: 0.1077 - accuracy: 0.8759\n",
            "Epoch 47/130\n",
            "145/145 [==============================] - 0s 226us/step - loss: 0.1049 - accuracy: 0.8621\n",
            "Epoch 48/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.1010 - accuracy: 0.8759\n",
            "Epoch 49/130\n",
            "145/145 [==============================] - 0s 223us/step - loss: 0.1019 - accuracy: 0.8759\n",
            "Epoch 50/130\n",
            "145/145 [==============================] - 0s 227us/step - loss: 0.1030 - accuracy: 0.8621\n",
            "Epoch 51/130\n",
            "145/145 [==============================] - 0s 229us/step - loss: 0.0992 - accuracy: 0.8759\n",
            "Epoch 52/130\n",
            "145/145 [==============================] - 0s 215us/step - loss: 0.1015 - accuracy: 0.8621\n",
            "Epoch 53/130\n",
            "145/145 [==============================] - 0s 231us/step - loss: 0.0951 - accuracy: 0.8759\n",
            "Epoch 54/130\n",
            "145/145 [==============================] - 0s 261us/step - loss: 0.0953 - accuracy: 0.8966\n",
            "Epoch 55/130\n",
            "145/145 [==============================] - 0s 224us/step - loss: 0.0940 - accuracy: 0.8966\n",
            "Epoch 56/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.0934 - accuracy: 0.8897\n",
            "Epoch 57/130\n",
            "145/145 [==============================] - 0s 241us/step - loss: 0.0910 - accuracy: 0.8897\n",
            "Epoch 58/130\n",
            "145/145 [==============================] - 0s 265us/step - loss: 0.0889 - accuracy: 0.8759\n",
            "Epoch 59/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0907 - accuracy: 0.8759\n",
            "Epoch 60/130\n",
            "145/145 [==============================] - 0s 224us/step - loss: 0.0889 - accuracy: 0.8966\n",
            "Epoch 61/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.0854 - accuracy: 0.8897\n",
            "Epoch 62/130\n",
            "145/145 [==============================] - 0s 272us/step - loss: 0.0855 - accuracy: 0.8966\n",
            "Epoch 63/130\n",
            "145/145 [==============================] - 0s 240us/step - loss: 0.0917 - accuracy: 0.8759\n",
            "Epoch 64/130\n",
            "145/145 [==============================] - 0s 246us/step - loss: 0.0882 - accuracy: 0.8897\n",
            "Epoch 65/130\n",
            "145/145 [==============================] - 0s 252us/step - loss: 0.0878 - accuracy: 0.8897\n",
            "Epoch 66/130\n",
            "145/145 [==============================] - 0s 243us/step - loss: 0.0854 - accuracy: 0.8897\n",
            "Epoch 67/130\n",
            "145/145 [==============================] - 0s 264us/step - loss: 0.0810 - accuracy: 0.8966\n",
            "Epoch 68/130\n",
            "145/145 [==============================] - 0s 256us/step - loss: 0.0804 - accuracy: 0.8966\n",
            "Epoch 69/130\n",
            "145/145 [==============================] - 0s 267us/step - loss: 0.0784 - accuracy: 0.9172\n",
            "Epoch 70/130\n",
            "145/145 [==============================] - 0s 276us/step - loss: 0.0778 - accuracy: 0.9103\n",
            "Epoch 71/130\n",
            "145/145 [==============================] - 0s 280us/step - loss: 0.0760 - accuracy: 0.9103\n",
            "Epoch 72/130\n",
            "145/145 [==============================] - 0s 261us/step - loss: 0.0787 - accuracy: 0.8897\n",
            "Epoch 73/130\n",
            "145/145 [==============================] - 0s 241us/step - loss: 0.0736 - accuracy: 0.9034\n",
            "Epoch 74/130\n",
            "145/145 [==============================] - 0s 257us/step - loss: 0.0775 - accuracy: 0.8897\n",
            "Epoch 75/130\n",
            "145/145 [==============================] - 0s 272us/step - loss: 0.0743 - accuracy: 0.9103\n",
            "Epoch 76/130\n",
            "145/145 [==============================] - 0s 270us/step - loss: 0.0730 - accuracy: 0.9172\n",
            "Epoch 77/130\n",
            "145/145 [==============================] - 0s 238us/step - loss: 0.0701 - accuracy: 0.9172\n",
            "Epoch 78/130\n",
            "145/145 [==============================] - 0s 241us/step - loss: 0.0693 - accuracy: 0.9034\n",
            "Epoch 79/130\n",
            "145/145 [==============================] - 0s 219us/step - loss: 0.0683 - accuracy: 0.9034\n",
            "Epoch 80/130\n",
            "145/145 [==============================] - 0s 229us/step - loss: 0.0670 - accuracy: 0.9103\n",
            "Epoch 81/130\n",
            "145/145 [==============================] - 0s 264us/step - loss: 0.0675 - accuracy: 0.9310\n",
            "Epoch 82/130\n",
            "145/145 [==============================] - 0s 252us/step - loss: 0.0634 - accuracy: 0.9241\n",
            "Epoch 83/130\n",
            "145/145 [==============================] - 0s 264us/step - loss: 0.0638 - accuracy: 0.9310\n",
            "Epoch 84/130\n",
            "145/145 [==============================] - 0s 265us/step - loss: 0.0612 - accuracy: 0.9310\n",
            "Epoch 85/130\n",
            "145/145 [==============================] - 0s 228us/step - loss: 0.0605 - accuracy: 0.9586\n",
            "Epoch 86/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0602 - accuracy: 0.9310\n",
            "Epoch 87/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.0586 - accuracy: 0.9379\n",
            "Epoch 88/130\n",
            "145/145 [==============================] - 0s 237us/step - loss: 0.0576 - accuracy: 0.9310\n",
            "Epoch 89/130\n",
            "145/145 [==============================] - 0s 228us/step - loss: 0.0543 - accuracy: 0.9448\n",
            "Epoch 90/130\n",
            "145/145 [==============================] - 0s 263us/step - loss: 0.0553 - accuracy: 0.9517\n",
            "Epoch 91/130\n",
            "145/145 [==============================] - 0s 249us/step - loss: 0.0601 - accuracy: 0.9103\n",
            "Epoch 92/130\n",
            "145/145 [==============================] - 0s 240us/step - loss: 0.0528 - accuracy: 0.9517\n",
            "Epoch 93/130\n",
            "145/145 [==============================] - 0s 222us/step - loss: 0.0523 - accuracy: 0.9586\n",
            "Epoch 94/130\n",
            "145/145 [==============================] - 0s 255us/step - loss: 0.0498 - accuracy: 0.9586\n",
            "Epoch 95/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0499 - accuracy: 0.9517\n",
            "Epoch 96/130\n",
            "145/145 [==============================] - 0s 229us/step - loss: 0.0487 - accuracy: 0.9517\n",
            "Epoch 97/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0454 - accuracy: 0.9655\n",
            "Epoch 98/130\n",
            "145/145 [==============================] - 0s 234us/step - loss: 0.0440 - accuracy: 0.9724\n",
            "Epoch 99/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.0433 - accuracy: 0.9793\n",
            "Epoch 100/130\n",
            "145/145 [==============================] - 0s 230us/step - loss: 0.0448 - accuracy: 0.9655\n",
            "Epoch 101/130\n",
            "145/145 [==============================] - 0s 239us/step - loss: 0.0469 - accuracy: 0.9517\n",
            "Epoch 102/130\n",
            "145/145 [==============================] - 0s 255us/step - loss: 0.0443 - accuracy: 0.9517\n",
            "Epoch 103/130\n",
            "145/145 [==============================] - 0s 248us/step - loss: 0.0430 - accuracy: 0.9586\n",
            "Epoch 104/130\n",
            "145/145 [==============================] - 0s 227us/step - loss: 0.0438 - accuracy: 0.9517\n",
            "Epoch 105/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0411 - accuracy: 0.9586\n",
            "Epoch 106/130\n",
            "145/145 [==============================] - 0s 226us/step - loss: 0.0444 - accuracy: 0.9586\n",
            "Epoch 107/130\n",
            "145/145 [==============================] - 0s 233us/step - loss: 0.0377 - accuracy: 0.9862\n",
            "Epoch 108/130\n",
            "145/145 [==============================] - 0s 236us/step - loss: 0.0368 - accuracy: 0.9862\n",
            "Epoch 109/130\n",
            "145/145 [==============================] - 0s 265us/step - loss: 0.0439 - accuracy: 0.9517\n",
            "Epoch 110/130\n",
            "145/145 [==============================] - 0s 230us/step - loss: 0.0387 - accuracy: 0.9724\n",
            "Epoch 111/130\n",
            "145/145 [==============================] - 0s 232us/step - loss: 0.0347 - accuracy: 0.9655\n",
            "Epoch 112/130\n",
            "145/145 [==============================] - 0s 233us/step - loss: 0.0339 - accuracy: 0.9931\n",
            "Epoch 113/130\n",
            "145/145 [==============================] - 0s 227us/step - loss: 0.0346 - accuracy: 0.9793\n",
            "Epoch 114/130\n",
            "145/145 [==============================] - 0s 231us/step - loss: 0.0345 - accuracy: 0.9793\n",
            "Epoch 115/130\n",
            "145/145 [==============================] - 0s 228us/step - loss: 0.0322 - accuracy: 0.9931\n",
            "Epoch 116/130\n",
            "145/145 [==============================] - 0s 225us/step - loss: 0.0338 - accuracy: 0.9793\n",
            "Epoch 117/130\n",
            "145/145 [==============================] - 0s 229us/step - loss: 0.0297 - accuracy: 0.9862\n",
            "Epoch 118/130\n",
            "145/145 [==============================] - 0s 234us/step - loss: 0.0294 - accuracy: 0.9931\n",
            "Epoch 119/130\n",
            "145/145 [==============================] - 0s 241us/step - loss: 0.0299 - accuracy: 0.9931\n",
            "Epoch 120/130\n",
            "145/145 [==============================] - 0s 241us/step - loss: 0.0283 - accuracy: 0.9931\n",
            "Epoch 121/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0299 - accuracy: 0.9862\n",
            "Epoch 122/130\n",
            "145/145 [==============================] - 0s 270us/step - loss: 0.0290 - accuracy: 0.9931\n",
            "Epoch 123/130\n",
            "145/145 [==============================] - 0s 224us/step - loss: 0.0277 - accuracy: 0.9862\n",
            "Epoch 124/130\n",
            "145/145 [==============================] - 0s 266us/step - loss: 0.0275 - accuracy: 0.9931\n",
            "Epoch 125/130\n",
            "145/145 [==============================] - 0s 248us/step - loss: 0.0264 - accuracy: 0.9931\n",
            "Epoch 126/130\n",
            "145/145 [==============================] - 0s 235us/step - loss: 0.0262 - accuracy: 0.9931\n",
            "Epoch 127/130\n",
            "145/145 [==============================] - 0s 236us/step - loss: 0.0263 - accuracy: 0.9862\n",
            "Epoch 128/130\n",
            "145/145 [==============================] - 0s 233us/step - loss: 0.0260 - accuracy: 0.9931\n",
            "Epoch 129/130\n",
            "145/145 [==============================] - 0s 239us/step - loss: 0.0240 - accuracy: 0.9931\n",
            "Epoch 130/130\n",
            "145/145 [==============================] - 0s 230us/step - loss: 0.0219 - accuracy: 0.9931\n",
            "63/63 [==============================] - 0s 226us/step\n",
            "\n",
            " Test Accuracy:0.8095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59YIaqBzIwp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12f772c0-2a41-45a4-8eb9-7aa7fe3a91b9"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "df = pd.read_csv('sonar.csv', header=None)\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:60]\n",
        "Y_obj = dataset[:, 60]\n",
        "\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)\n",
        "\n",
        "n_fold = 10\n",
        "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "for train, test in skf.split(X, Y):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(24, input_dim=60, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "  model.fit(X[train], Y[train], epochs=100, batch_size=5)\n",
        "  k_accuracy = '%.4f'%(model.evaluate(X[test], Y[test])[1])\n",
        "  accuracy.append(k_accuracy)\n",
        "\n",
        "print('\\n %.f fold Accuracy:'%n_fold, accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 613us/step - loss: 0.2530 - accuracy: 0.4866\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.2441 - accuracy: 0.5401\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.2404 - accuracy: 0.5348\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.2342 - accuracy: 0.5348\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.2289 - accuracy: 0.5455\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.2179 - accuracy: 0.6043\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.2068 - accuracy: 0.6791\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1948 - accuracy: 0.6845\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1834 - accuracy: 0.7487\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1738 - accuracy: 0.7647\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1700 - accuracy: 0.7487\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.1580 - accuracy: 0.7701\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.1500 - accuracy: 0.8075\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 271us/step - loss: 0.1427 - accuracy: 0.8182\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.1424 - accuracy: 0.8075\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.1352 - accuracy: 0.8289\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.1358 - accuracy: 0.8075\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.1317 - accuracy: 0.7968\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.1376 - accuracy: 0.7861\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.1242 - accuracy: 0.8075\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.1235 - accuracy: 0.8235\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.1186 - accuracy: 0.8128\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.1221 - accuracy: 0.8128\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.1174 - accuracy: 0.8182\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.1217 - accuracy: 0.8342\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.1107 - accuracy: 0.8449\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.1190 - accuracy: 0.8128\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1120 - accuracy: 0.8449\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.1088 - accuracy: 0.8396\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1044 - accuracy: 0.8396\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.1041 - accuracy: 0.8717\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1049 - accuracy: 0.8449\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1066 - accuracy: 0.8824\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.1010 - accuracy: 0.8556\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1013 - accuracy: 0.8610\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.1031 - accuracy: 0.8770\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.1008 - accuracy: 0.8610\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0953 - accuracy: 0.8770\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0962 - accuracy: 0.8877\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0925 - accuracy: 0.8877\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0982 - accuracy: 0.8717\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0952 - accuracy: 0.8984\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0939 - accuracy: 0.8824\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0943 - accuracy: 0.8663\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0947 - accuracy: 0.8770\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0900 - accuracy: 0.8824\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0915 - accuracy: 0.8770\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0879 - accuracy: 0.9091\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0884 - accuracy: 0.8877\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0867 - accuracy: 0.8877\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0864 - accuracy: 0.8824\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0899 - accuracy: 0.8770\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0885 - accuracy: 0.8770\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0834 - accuracy: 0.9037\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0811 - accuracy: 0.9037\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0868 - accuracy: 0.8824\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0820 - accuracy: 0.9091\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0855 - accuracy: 0.8877\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0784 - accuracy: 0.9091\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0799 - accuracy: 0.8877\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0792 - accuracy: 0.8930\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0784 - accuracy: 0.9037\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0775 - accuracy: 0.9144\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0819 - accuracy: 0.8877\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.0820 - accuracy: 0.8824\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0791 - accuracy: 0.9091\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0749 - accuracy: 0.9144\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0795 - accuracy: 0.9251\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0780 - accuracy: 0.8824\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0714 - accuracy: 0.9144\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0705 - accuracy: 0.9251\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0692 - accuracy: 0.9251\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0703 - accuracy: 0.9198\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0670 - accuracy: 0.9198\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0695 - accuracy: 0.9198\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0655 - accuracy: 0.9198\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0757 - accuracy: 0.8877\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 280us/step - loss: 0.0688 - accuracy: 0.9144\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 335us/step - loss: 0.0615 - accuracy: 0.9305\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.0652 - accuracy: 0.9198\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0635 - accuracy: 0.9144\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0623 - accuracy: 0.9198\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 264us/step - loss: 0.0585 - accuracy: 0.9305\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0631 - accuracy: 0.9198\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0586 - accuracy: 0.9305\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0572 - accuracy: 0.9251\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0554 - accuracy: 0.9358\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 364us/step - loss: 0.0590 - accuracy: 0.9144\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 262us/step - loss: 0.0573 - accuracy: 0.9305\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 283us/step - loss: 0.0554 - accuracy: 0.9305\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 273us/step - loss: 0.0534 - accuracy: 0.9465\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0576 - accuracy: 0.9144\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.0552 - accuracy: 0.9465\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0552 - accuracy: 0.9412\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0548 - accuracy: 0.9198\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 265us/step - loss: 0.0532 - accuracy: 0.9358\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 293us/step - loss: 0.0502 - accuracy: 0.9412\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0493 - accuracy: 0.9519\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 283us/step - loss: 0.0468 - accuracy: 0.9519\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0501 - accuracy: 0.9305\n",
            "21/21 [==============================] - 0s 637us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 616us/step - loss: 0.2485 - accuracy: 0.5080\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.2409 - accuracy: 0.5882\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.2323 - accuracy: 0.6631\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.2256 - accuracy: 0.7005\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.2159 - accuracy: 0.6684\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.2100 - accuracy: 0.6791\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1993 - accuracy: 0.7807\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.2008 - accuracy: 0.6845\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 263us/step - loss: 0.1845 - accuracy: 0.7701\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 297us/step - loss: 0.1746 - accuracy: 0.7754\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 269us/step - loss: 0.1681 - accuracy: 0.7861\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.1629 - accuracy: 0.7540\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.1554 - accuracy: 0.7861\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.1502 - accuracy: 0.7968\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.1555 - accuracy: 0.7861\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 214us/step - loss: 0.1466 - accuracy: 0.7914\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.1423 - accuracy: 0.7914\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.1368 - accuracy: 0.8128\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1344 - accuracy: 0.8235\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.1315 - accuracy: 0.8128\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.1315 - accuracy: 0.8075\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 267us/step - loss: 0.1313 - accuracy: 0.7968\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.1237 - accuracy: 0.8396\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 267us/step - loss: 0.1209 - accuracy: 0.8396\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.1174 - accuracy: 0.8396\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 274us/step - loss: 0.1148 - accuracy: 0.8396\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.1142 - accuracy: 0.8610\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 261us/step - loss: 0.1108 - accuracy: 0.8449\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 273us/step - loss: 0.1171 - accuracy: 0.8342\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.1129 - accuracy: 0.8556\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 277us/step - loss: 0.1080 - accuracy: 0.8770\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.1052 - accuracy: 0.8770\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 267us/step - loss: 0.0985 - accuracy: 0.8663\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0987 - accuracy: 0.8770\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0997 - accuracy: 0.8610\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0954 - accuracy: 0.8930\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0929 - accuracy: 0.8717\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0962 - accuracy: 0.8877\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0939 - accuracy: 0.8877\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.0878 - accuracy: 0.8984\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 262us/step - loss: 0.0881 - accuracy: 0.9037\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 261us/step - loss: 0.0827 - accuracy: 0.8984\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 278us/step - loss: 0.0830 - accuracy: 0.8930\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0788 - accuracy: 0.9251\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0798 - accuracy: 0.9091\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0751 - accuracy: 0.9198\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0735 - accuracy: 0.9251\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0795 - accuracy: 0.9091\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0702 - accuracy: 0.9358\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0720 - accuracy: 0.9198\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0722 - accuracy: 0.9251\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 274us/step - loss: 0.0691 - accuracy: 0.9144\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 285us/step - loss: 0.0683 - accuracy: 0.9251\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 271us/step - loss: 0.0726 - accuracy: 0.9091\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0669 - accuracy: 0.9305\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0629 - accuracy: 0.9358\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0703 - accuracy: 0.9251\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0639 - accuracy: 0.9305\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0585 - accuracy: 0.9465\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0567 - accuracy: 0.9465\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0580 - accuracy: 0.9412\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0560 - accuracy: 0.9412\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 273us/step - loss: 0.0560 - accuracy: 0.9358\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 370us/step - loss: 0.0587 - accuracy: 0.9251\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 322us/step - loss: 0.0536 - accuracy: 0.9358\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0508 - accuracy: 0.9519\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0503 - accuracy: 0.9519\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0472 - accuracy: 0.9679\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0517 - accuracy: 0.9412\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0471 - accuracy: 0.9572\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.0479 - accuracy: 0.9412\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 280us/step - loss: 0.0507 - accuracy: 0.9465\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0474 - accuracy: 0.9572\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0435 - accuracy: 0.9679\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0405 - accuracy: 0.9840\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0434 - accuracy: 0.9733\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0440 - accuracy: 0.9733\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 269us/step - loss: 0.0415 - accuracy: 0.9733\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0402 - accuracy: 0.9626\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0472 - accuracy: 0.9465\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 265us/step - loss: 0.0369 - accuracy: 0.9786\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0383 - accuracy: 0.9679\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 266us/step - loss: 0.0369 - accuracy: 0.9733\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.0340 - accuracy: 0.9840\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0341 - accuracy: 0.9786\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0334 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0316 - accuracy: 0.9840\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0330 - accuracy: 0.9786\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0449 - accuracy: 0.9519\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0335 - accuracy: 0.9840\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 265us/step - loss: 0.0310 - accuracy: 0.9840\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 284us/step - loss: 0.0303 - accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 268us/step - loss: 0.0301 - accuracy: 0.9733\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0324 - accuracy: 0.9840\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0322 - accuracy: 0.9786\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0290 - accuracy: 0.9733\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0272 - accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0264 - accuracy: 0.9840\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0271 - accuracy: 0.9786\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.0263 - accuracy: 0.9786\n",
            "21/21 [==============================] - 0s 616us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 595us/step - loss: 0.2443 - accuracy: 0.5722\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.2287 - accuracy: 0.6257\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.2195 - accuracy: 0.6791\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.2103 - accuracy: 0.7059\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.2014 - accuracy: 0.7112\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.1948 - accuracy: 0.7326\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 267us/step - loss: 0.1852 - accuracy: 0.7326\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.1784 - accuracy: 0.7487\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1768 - accuracy: 0.7594\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1689 - accuracy: 0.7701\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.1644 - accuracy: 0.7540\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1564 - accuracy: 0.7754\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1551 - accuracy: 0.8075\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1501 - accuracy: 0.7914\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.1423 - accuracy: 0.8021\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 261us/step - loss: 0.1435 - accuracy: 0.7968\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.1391 - accuracy: 0.8021\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.1333 - accuracy: 0.8235\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.1308 - accuracy: 0.8289\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1294 - accuracy: 0.8396\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.1198 - accuracy: 0.8556\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.1183 - accuracy: 0.8717\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.1179 - accuracy: 0.8663\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.1161 - accuracy: 0.8449\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.1093 - accuracy: 0.8663\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.1091 - accuracy: 0.8610\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 292us/step - loss: 0.1062 - accuracy: 0.8717\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.1025 - accuracy: 0.8877\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.1000 - accuracy: 0.8877\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.1009 - accuracy: 0.8984\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 265us/step - loss: 0.0949 - accuracy: 0.8824\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.0961 - accuracy: 0.8717\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0955 - accuracy: 0.8824\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0894 - accuracy: 0.8824\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0930 - accuracy: 0.8877\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0878 - accuracy: 0.9037\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 264us/step - loss: 0.0887 - accuracy: 0.9144\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0923 - accuracy: 0.8930\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 269us/step - loss: 0.0842 - accuracy: 0.9198\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.0797 - accuracy: 0.9198\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 277us/step - loss: 0.0817 - accuracy: 0.9144\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.0798 - accuracy: 0.9251\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 264us/step - loss: 0.0771 - accuracy: 0.9091\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 268us/step - loss: 0.0714 - accuracy: 0.9251\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 262us/step - loss: 0.0780 - accuracy: 0.9091\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0725 - accuracy: 0.9251\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.0701 - accuracy: 0.9305\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0690 - accuracy: 0.9251\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0683 - accuracy: 0.9305\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0653 - accuracy: 0.9305\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0647 - accuracy: 0.9358\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0621 - accuracy: 0.9412\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0622 - accuracy: 0.9358\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0599 - accuracy: 0.9251\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0632 - accuracy: 0.9251\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0607 - accuracy: 0.9305\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0577 - accuracy: 0.9412\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0570 - accuracy: 0.9465\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0561 - accuracy: 0.9251\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 282us/step - loss: 0.0521 - accuracy: 0.9412\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0538 - accuracy: 0.9358\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0519 - accuracy: 0.9465\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0516 - accuracy: 0.9412\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0465 - accuracy: 0.9412\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0456 - accuracy: 0.9412\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 216us/step - loss: 0.0483 - accuracy: 0.9465\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0450 - accuracy: 0.9465\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0434 - accuracy: 0.9412\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0431 - accuracy: 0.9465\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0409 - accuracy: 0.9572\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0415 - accuracy: 0.9572\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0370 - accuracy: 0.9519\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0390 - accuracy: 0.9572\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0365 - accuracy: 0.9572\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0351 - accuracy: 0.9733\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0353 - accuracy: 0.9519\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0324 - accuracy: 0.9679\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0349 - accuracy: 0.9519\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0324 - accuracy: 0.9679\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0312 - accuracy: 0.9679\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0301 - accuracy: 0.9679\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0295 - accuracy: 0.9786\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0292 - accuracy: 0.9626\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0280 - accuracy: 0.9893\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0269 - accuracy: 0.9733\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0278 - accuracy: 0.9733\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0263 - accuracy: 0.9893\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0245 - accuracy: 0.9733\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0238 - accuracy: 0.9786\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0225 - accuracy: 0.9786\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0224 - accuracy: 0.9893\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0219 - accuracy: 0.9893\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0199 - accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0227 - accuracy: 0.9893\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0205 - accuracy: 0.9893\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0187 - accuracy: 0.9947\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0170 - accuracy: 0.9947\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0182 - accuracy: 0.9840\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0227 - accuracy: 0.9893\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0185 - accuracy: 0.9947\n",
            "21/21 [==============================] - 0s 586us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 571us/step - loss: 0.2542 - accuracy: 0.5080\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.2361 - accuracy: 0.6524\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.2232 - accuracy: 0.6952\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.2076 - accuracy: 0.7166\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.1900 - accuracy: 0.7701\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1795 - accuracy: 0.7594\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1687 - accuracy: 0.8021\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1577 - accuracy: 0.8235\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.1552 - accuracy: 0.8128\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1456 - accuracy: 0.8235\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1411 - accuracy: 0.8342\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1371 - accuracy: 0.8128\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1372 - accuracy: 0.8075\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.1275 - accuracy: 0.8396\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1252 - accuracy: 0.8503\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1230 - accuracy: 0.8449\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.1213 - accuracy: 0.8503\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1167 - accuracy: 0.8449\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1136 - accuracy: 0.8449\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1161 - accuracy: 0.8396\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.1115 - accuracy: 0.8556\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.1075 - accuracy: 0.8610\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1102 - accuracy: 0.8449\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1039 - accuracy: 0.8610\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1013 - accuracy: 0.8717\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0973 - accuracy: 0.8717\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0952 - accuracy: 0.8717\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0923 - accuracy: 0.8984\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0910 - accuracy: 0.8877\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0934 - accuracy: 0.8610\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0892 - accuracy: 0.9091\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0849 - accuracy: 0.9091\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.0832 - accuracy: 0.9091\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0835 - accuracy: 0.9198\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0809 - accuracy: 0.9091\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0789 - accuracy: 0.9091\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0762 - accuracy: 0.9091\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0771 - accuracy: 0.9144\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0751 - accuracy: 0.9251\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0792 - accuracy: 0.9144\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0838 - accuracy: 0.8824\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 273us/step - loss: 0.0712 - accuracy: 0.9144\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0699 - accuracy: 0.9198\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0695 - accuracy: 0.9251\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0636 - accuracy: 0.9358\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 262us/step - loss: 0.0619 - accuracy: 0.9519\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 279us/step - loss: 0.0610 - accuracy: 0.9519\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0593 - accuracy: 0.9358\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 318us/step - loss: 0.0648 - accuracy: 0.9465\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0576 - accuracy: 0.9465\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0532 - accuracy: 0.9626\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 246us/step - loss: 0.0534 - accuracy: 0.9572\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0515 - accuracy: 0.9519\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0505 - accuracy: 0.9626\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0544 - accuracy: 0.9465\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0474 - accuracy: 0.9519\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0458 - accuracy: 0.9679\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0458 - accuracy: 0.9626\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0473 - accuracy: 0.9519\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0487 - accuracy: 0.9679\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0503 - accuracy: 0.9198\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0512 - accuracy: 0.9519\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0438 - accuracy: 0.9679\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0385 - accuracy: 0.9679\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 246us/step - loss: 0.0375 - accuracy: 0.9679\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0371 - accuracy: 0.9786\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.0374 - accuracy: 0.9679\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0401 - accuracy: 0.9679\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0376 - accuracy: 0.9733\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0356 - accuracy: 0.9733\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0321 - accuracy: 0.9786\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0302 - accuracy: 0.9786\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0291 - accuracy: 0.9733\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0308 - accuracy: 0.9786\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0289 - accuracy: 0.9786\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0332 - accuracy: 0.9733\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0289 - accuracy: 0.9733\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0254 - accuracy: 0.9786\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0253 - accuracy: 0.9786\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0243 - accuracy: 0.9786\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0243 - accuracy: 0.9840\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0277 - accuracy: 0.9786\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 267us/step - loss: 0.0244 - accuracy: 0.9786\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0217 - accuracy: 0.9893\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0222 - accuracy: 0.9786\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0200 - accuracy: 0.9840\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0220 - accuracy: 0.9840\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0190 - accuracy: 0.9840\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0187 - accuracy: 0.9840\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0177 - accuracy: 0.9786\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0191 - accuracy: 0.9893\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0174 - accuracy: 0.9893\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0194 - accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0154 - accuracy: 0.9893\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0172 - accuracy: 0.9893\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0142 - accuracy: 0.9893\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0182 - accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0130 - accuracy: 0.9893\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0117 - accuracy: 0.9893\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0110 - accuracy: 0.9893\n",
            "21/21 [==============================] - 0s 579us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 578us/step - loss: 0.2478 - accuracy: 0.5561\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.2352 - accuracy: 0.6631\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.2243 - accuracy: 0.6524\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.2143 - accuracy: 0.7273\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.2028 - accuracy: 0.8021\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.1891 - accuracy: 0.7861\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1784 - accuracy: 0.8182\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.1680 - accuracy: 0.8075\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.1585 - accuracy: 0.8289\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.1539 - accuracy: 0.8075\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 263us/step - loss: 0.1539 - accuracy: 0.7647\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 276us/step - loss: 0.1364 - accuracy: 0.8663\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.1382 - accuracy: 0.8289\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.1250 - accuracy: 0.8503\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1270 - accuracy: 0.8289\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1159 - accuracy: 0.8717\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.1152 - accuracy: 0.8717\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1124 - accuracy: 0.8503\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1076 - accuracy: 0.8717\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1038 - accuracy: 0.8877\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1018 - accuracy: 0.8717\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0964 - accuracy: 0.8984\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0981 - accuracy: 0.8930\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0933 - accuracy: 0.8824\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0896 - accuracy: 0.8610\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0976 - accuracy: 0.8717\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0861 - accuracy: 0.8984\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0812 - accuracy: 0.8930\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0821 - accuracy: 0.9037\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0808 - accuracy: 0.8984\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0767 - accuracy: 0.8984\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 262us/step - loss: 0.0812 - accuracy: 0.8984\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 261us/step - loss: 0.0706 - accuracy: 0.9251\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0723 - accuracy: 0.9037\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0669 - accuracy: 0.9358\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0667 - accuracy: 0.9144\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0681 - accuracy: 0.9198\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0609 - accuracy: 0.9412\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0739 - accuracy: 0.9037\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0638 - accuracy: 0.9091\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0612 - accuracy: 0.9305\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 274us/step - loss: 0.0566 - accuracy: 0.9519\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.0552 - accuracy: 0.9465\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0527 - accuracy: 0.9465\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0563 - accuracy: 0.9144\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0517 - accuracy: 0.9626\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0459 - accuracy: 0.9786\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0446 - accuracy: 0.9733\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 247us/step - loss: 0.0503 - accuracy: 0.9358\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 305us/step - loss: 0.0446 - accuracy: 0.9679\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0414 - accuracy: 0.9733\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0477 - accuracy: 0.9358\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0452 - accuracy: 0.9519\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.0390 - accuracy: 0.9733\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0407 - accuracy: 0.9679\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0399 - accuracy: 0.9626\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0387 - accuracy: 0.9519\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0321 - accuracy: 0.9786\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0325 - accuracy: 0.9786\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0325 - accuracy: 0.9786\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0310 - accuracy: 0.9893\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0287 - accuracy: 0.9786\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0307 - accuracy: 0.9840\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.0294 - accuracy: 0.9893\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0275 - accuracy: 0.9947\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0272 - accuracy: 0.9893\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0275 - accuracy: 0.9893\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0240 - accuracy: 0.9893\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0284 - accuracy: 0.9733\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0231 - accuracy: 0.9893\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 263us/step - loss: 0.0216 - accuracy: 0.9893\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0220 - accuracy: 0.9893\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0230 - accuracy: 0.9786\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0274 - accuracy: 0.9840\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0249 - accuracy: 0.9840\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0245 - accuracy: 0.9840\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0204 - accuracy: 0.9840\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 216us/step - loss: 0.0199 - accuracy: 0.9893\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0183 - accuracy: 0.9893\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0165 - accuracy: 0.9893\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0172 - accuracy: 0.9840\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.0159 - accuracy: 0.9893\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0159 - accuracy: 0.9947\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.0164 - accuracy: 0.9893\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0154 - accuracy: 0.9893\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0143 - accuracy: 0.9893\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0138 - accuracy: 0.9947\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0147 - accuracy: 0.9893\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0139 - accuracy: 0.9947\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0134 - accuracy: 0.9893\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0126 - accuracy: 0.9947\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0126 - accuracy: 0.9947\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0125 - accuracy: 0.9893\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0128 - accuracy: 0.9947\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0114 - accuracy: 0.9947\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0121 - accuracy: 0.9947\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0120 - accuracy: 0.9947\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.0124 - accuracy: 0.9947\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0112 - accuracy: 0.9947\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0121 - accuracy: 0.9947\n",
            "21/21 [==============================] - 0s 572us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 666us/step - loss: 0.2625 - accuracy: 0.4652\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.2463 - accuracy: 0.5348\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.2436 - accuracy: 0.6364\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.2399 - accuracy: 0.6043\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.2376 - accuracy: 0.6684\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.2298 - accuracy: 0.7326\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.2144 - accuracy: 0.7219\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1993 - accuracy: 0.7487\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1893 - accuracy: 0.7433\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.1729 - accuracy: 0.8021\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1669 - accuracy: 0.7540\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 216us/step - loss: 0.1590 - accuracy: 0.7968\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1491 - accuracy: 0.7807\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1441 - accuracy: 0.8021\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1353 - accuracy: 0.8075\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1311 - accuracy: 0.8182\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1294 - accuracy: 0.8235\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1271 - accuracy: 0.8342\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1198 - accuracy: 0.8663\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.1186 - accuracy: 0.8503\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.1111 - accuracy: 0.8824\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1110 - accuracy: 0.8556\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.1103 - accuracy: 0.8663\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.1081 - accuracy: 0.8610\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1031 - accuracy: 0.8610\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 216us/step - loss: 0.1025 - accuracy: 0.8717\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0964 - accuracy: 0.8930\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.0982 - accuracy: 0.8717\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.0935 - accuracy: 0.8770\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0913 - accuracy: 0.8984\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 265us/step - loss: 0.0892 - accuracy: 0.9198\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 265us/step - loss: 0.0861 - accuracy: 0.9305\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 272us/step - loss: 0.0845 - accuracy: 0.9251\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 263us/step - loss: 0.0913 - accuracy: 0.8770\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.0809 - accuracy: 0.9251\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.0807 - accuracy: 0.9358\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0817 - accuracy: 0.8984\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0805 - accuracy: 0.9091\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0790 - accuracy: 0.9198\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0763 - accuracy: 0.8984\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0719 - accuracy: 0.9305\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0711 - accuracy: 0.9358\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0727 - accuracy: 0.9144\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0692 - accuracy: 0.9358\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0663 - accuracy: 0.9519\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0626 - accuracy: 0.9572\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0622 - accuracy: 0.9465\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0617 - accuracy: 0.9519\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0606 - accuracy: 0.9519\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.0575 - accuracy: 0.9572\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0610 - accuracy: 0.9465\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.0667 - accuracy: 0.9251\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0538 - accuracy: 0.9465\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0548 - accuracy: 0.9465\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0504 - accuracy: 0.9626\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.0499 - accuracy: 0.9626\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 247us/step - loss: 0.0474 - accuracy: 0.9733\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0467 - accuracy: 0.9626\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0454 - accuracy: 0.9626\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0441 - accuracy: 0.9626\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 268us/step - loss: 0.0455 - accuracy: 0.9679\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 287us/step - loss: 0.0449 - accuracy: 0.9572\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0453 - accuracy: 0.9679\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0403 - accuracy: 0.9733\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0434 - accuracy: 0.9626\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 246us/step - loss: 0.0402 - accuracy: 0.9786\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0363 - accuracy: 0.9786\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0362 - accuracy: 0.9786\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0369 - accuracy: 0.9786\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0375 - accuracy: 0.9733\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0329 - accuracy: 0.9786\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0367 - accuracy: 0.9733\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 276us/step - loss: 0.0465 - accuracy: 0.9679\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.0341 - accuracy: 0.9786\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0339 - accuracy: 0.9733\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0299 - accuracy: 0.9786\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0298 - accuracy: 0.9786\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0287 - accuracy: 0.9786\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0320 - accuracy: 0.9786\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 290us/step - loss: 0.0325 - accuracy: 0.9733\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0320 - accuracy: 0.9786\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0285 - accuracy: 0.9786\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 260us/step - loss: 0.0267 - accuracy: 0.9786\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 266us/step - loss: 0.0287 - accuracy: 0.9786\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 261us/step - loss: 0.0245 - accuracy: 0.9786\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 264us/step - loss: 0.0253 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 257us/step - loss: 0.0265 - accuracy: 0.9786\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0268 - accuracy: 0.9733\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0257 - accuracy: 0.9840\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0232 - accuracy: 0.9840\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.0225 - accuracy: 0.9786\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0210 - accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0205 - accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0187 - accuracy: 0.9840\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0258 - accuracy: 0.9733\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0218 - accuracy: 0.9840\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0180 - accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 238us/step - loss: 0.0176 - accuracy: 0.9893\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 266us/step - loss: 0.0204 - accuracy: 0.9840\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.0160 - accuracy: 0.9840\n",
            "21/21 [==============================] - 0s 670us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 672us/step - loss: 0.2496 - accuracy: 0.5134\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.2432 - accuracy: 0.5401\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.2357 - accuracy: 0.6257\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 268us/step - loss: 0.2258 - accuracy: 0.6417\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 246us/step - loss: 0.2195 - accuracy: 0.7059\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.2092 - accuracy: 0.6738\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.2017 - accuracy: 0.7701\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 247us/step - loss: 0.1968 - accuracy: 0.7059\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 276us/step - loss: 0.1870 - accuracy: 0.7701\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.1796 - accuracy: 0.7754\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.1779 - accuracy: 0.8021\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.1677 - accuracy: 0.7914\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.1634 - accuracy: 0.7914\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1604 - accuracy: 0.7968\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.1551 - accuracy: 0.8021\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1547 - accuracy: 0.7701\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.1466 - accuracy: 0.7968\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.1454 - accuracy: 0.8075\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1407 - accuracy: 0.8235\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1400 - accuracy: 0.8235\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1368 - accuracy: 0.8021\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1353 - accuracy: 0.8128\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.1304 - accuracy: 0.8342\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.1281 - accuracy: 0.8449\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.1269 - accuracy: 0.8342\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 323us/step - loss: 0.1234 - accuracy: 0.8235\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.1223 - accuracy: 0.8610\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.1191 - accuracy: 0.8503\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.1179 - accuracy: 0.8503\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.1136 - accuracy: 0.8610\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 241us/step - loss: 0.1232 - accuracy: 0.8342\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.1150 - accuracy: 0.8503\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1094 - accuracy: 0.8770\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.1087 - accuracy: 0.8610\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.1067 - accuracy: 0.8663\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1065 - accuracy: 0.8663\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.1058 - accuracy: 0.8556\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1019 - accuracy: 0.8663\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.1017 - accuracy: 0.8770\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.1009 - accuracy: 0.8610\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0922 - accuracy: 0.8930\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1035 - accuracy: 0.8663\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0935 - accuracy: 0.8824\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0911 - accuracy: 0.8930\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0905 - accuracy: 0.9037\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0891 - accuracy: 0.9037\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0908 - accuracy: 0.8877\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0839 - accuracy: 0.8824\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.0837 - accuracy: 0.8930\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0960 - accuracy: 0.8824\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.0855 - accuracy: 0.9144\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0810 - accuracy: 0.9037\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0865 - accuracy: 0.8984\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0773 - accuracy: 0.9305\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0800 - accuracy: 0.8984\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0813 - accuracy: 0.8877\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0766 - accuracy: 0.9305\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0818 - accuracy: 0.9091\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0775 - accuracy: 0.9091\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0690 - accuracy: 0.9305\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0778 - accuracy: 0.9198\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0733 - accuracy: 0.9251\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0700 - accuracy: 0.9091\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 247us/step - loss: 0.0669 - accuracy: 0.9198\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0660 - accuracy: 0.9358\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 264us/step - loss: 0.0678 - accuracy: 0.9251\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0632 - accuracy: 0.9358\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0642 - accuracy: 0.9305\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0599 - accuracy: 0.9465\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0667 - accuracy: 0.9305\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0598 - accuracy: 0.9412\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0578 - accuracy: 0.9465\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.0627 - accuracy: 0.9251\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0570 - accuracy: 0.9519\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0544 - accuracy: 0.9412\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0555 - accuracy: 0.9358\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0525 - accuracy: 0.9519\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0542 - accuracy: 0.9465\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0520 - accuracy: 0.9572\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.0507 - accuracy: 0.9465\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0512 - accuracy: 0.9519\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0501 - accuracy: 0.9519\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0493 - accuracy: 0.9519\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0471 - accuracy: 0.9519\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0508 - accuracy: 0.9412\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0450 - accuracy: 0.9626\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0453 - accuracy: 0.9519\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0456 - accuracy: 0.9572\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 237us/step - loss: 0.0413 - accuracy: 0.9572\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0406 - accuracy: 0.9519\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0447 - accuracy: 0.9626\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0399 - accuracy: 0.9679\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 229us/step - loss: 0.0395 - accuracy: 0.9465\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0385 - accuracy: 0.9679\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0387 - accuracy: 0.9733\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0409 - accuracy: 0.9626\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0358 - accuracy: 0.9679\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0350 - accuracy: 0.9679\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 228us/step - loss: 0.0368 - accuracy: 0.9733\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0343 - accuracy: 0.9786\n",
            "21/21 [==============================] - 0s 594us/step\n",
            "Epoch 1/100\n",
            "187/187 [==============================] - 0s 650us/step - loss: 0.2558 - accuracy: 0.4920\n",
            "Epoch 2/100\n",
            "187/187 [==============================] - 0s 259us/step - loss: 0.2474 - accuracy: 0.5401\n",
            "Epoch 3/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.2408 - accuracy: 0.6310\n",
            "Epoch 4/100\n",
            "187/187 [==============================] - 0s 344us/step - loss: 0.2331 - accuracy: 0.6578\n",
            "Epoch 5/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.2301 - accuracy: 0.6364\n",
            "Epoch 6/100\n",
            "187/187 [==============================] - 0s 286us/step - loss: 0.2213 - accuracy: 0.6738\n",
            "Epoch 7/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.2102 - accuracy: 0.7433\n",
            "Epoch 8/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.2012 - accuracy: 0.7326\n",
            "Epoch 9/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.1914 - accuracy: 0.7112\n",
            "Epoch 10/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1816 - accuracy: 0.7540\n",
            "Epoch 11/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1704 - accuracy: 0.7701\n",
            "Epoch 12/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.1634 - accuracy: 0.7861\n",
            "Epoch 13/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.1542 - accuracy: 0.8503\n",
            "Epoch 14/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1494 - accuracy: 0.8021\n",
            "Epoch 15/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1426 - accuracy: 0.8128\n",
            "Epoch 16/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.1403 - accuracy: 0.8075\n",
            "Epoch 17/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.1368 - accuracy: 0.8021\n",
            "Epoch 18/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.1298 - accuracy: 0.8503\n",
            "Epoch 19/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.1295 - accuracy: 0.8342\n",
            "Epoch 20/100\n",
            "187/187 [==============================] - 0s 216us/step - loss: 0.1249 - accuracy: 0.8396\n",
            "Epoch 21/100\n",
            "187/187 [==============================] - 0s 213us/step - loss: 0.1222 - accuracy: 0.8289\n",
            "Epoch 22/100\n",
            "187/187 [==============================] - 0s 233us/step - loss: 0.1167 - accuracy: 0.8663\n",
            "Epoch 23/100\n",
            "187/187 [==============================] - 0s 218us/step - loss: 0.1148 - accuracy: 0.8610\n",
            "Epoch 24/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.1143 - accuracy: 0.8717\n",
            "Epoch 25/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1099 - accuracy: 0.8824\n",
            "Epoch 26/100\n",
            "187/187 [==============================] - 0s 245us/step - loss: 0.1064 - accuracy: 0.8770\n",
            "Epoch 27/100\n",
            "187/187 [==============================] - 0s 242us/step - loss: 0.1095 - accuracy: 0.8503\n",
            "Epoch 28/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.1030 - accuracy: 0.8877\n",
            "Epoch 29/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1078 - accuracy: 0.8663\n",
            "Epoch 30/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.1022 - accuracy: 0.8930\n",
            "Epoch 31/100\n",
            "187/187 [==============================] - 0s 224us/step - loss: 0.0984 - accuracy: 0.8930\n",
            "Epoch 32/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0933 - accuracy: 0.9037\n",
            "Epoch 33/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0921 - accuracy: 0.9037\n",
            "Epoch 34/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.0920 - accuracy: 0.8717\n",
            "Epoch 35/100\n",
            "187/187 [==============================] - 0s 235us/step - loss: 0.0914 - accuracy: 0.8824\n",
            "Epoch 36/100\n",
            "187/187 [==============================] - 0s 220us/step - loss: 0.0859 - accuracy: 0.9144\n",
            "Epoch 37/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0916 - accuracy: 0.8930\n",
            "Epoch 38/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0894 - accuracy: 0.8984\n",
            "Epoch 39/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.0890 - accuracy: 0.8930\n",
            "Epoch 40/100\n",
            "187/187 [==============================] - 0s 234us/step - loss: 0.0824 - accuracy: 0.9144\n",
            "Epoch 41/100\n",
            "187/187 [==============================] - 0s 244us/step - loss: 0.0783 - accuracy: 0.9251\n",
            "Epoch 42/100\n",
            "187/187 [==============================] - 0s 221us/step - loss: 0.0773 - accuracy: 0.9251\n",
            "Epoch 43/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0748 - accuracy: 0.9198\n",
            "Epoch 44/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0737 - accuracy: 0.9251\n",
            "Epoch 45/100\n",
            "187/187 [==============================] - 0s 246us/step - loss: 0.0709 - accuracy: 0.9305\n",
            "Epoch 46/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0707 - accuracy: 0.9305\n",
            "Epoch 47/100\n",
            "187/187 [==============================] - 0s 239us/step - loss: 0.0736 - accuracy: 0.9091\n",
            "Epoch 48/100\n",
            "187/187 [==============================] - 0s 254us/step - loss: 0.0709 - accuracy: 0.9305\n",
            "Epoch 49/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0756 - accuracy: 0.9144\n",
            "Epoch 50/100\n",
            "187/187 [==============================] - 0s 279us/step - loss: 0.0661 - accuracy: 0.9251\n",
            "Epoch 51/100\n",
            "187/187 [==============================] - 0s 240us/step - loss: 0.0752 - accuracy: 0.9037\n",
            "Epoch 52/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.0679 - accuracy: 0.9251\n",
            "Epoch 53/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0654 - accuracy: 0.9358\n",
            "Epoch 54/100\n",
            "187/187 [==============================] - 0s 219us/step - loss: 0.0591 - accuracy: 0.9465\n",
            "Epoch 55/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0590 - accuracy: 0.9465\n",
            "Epoch 56/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0580 - accuracy: 0.9465\n",
            "Epoch 57/100\n",
            "187/187 [==============================] - 0s 216us/step - loss: 0.0561 - accuracy: 0.9465\n",
            "Epoch 58/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.0553 - accuracy: 0.9519\n",
            "Epoch 59/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0555 - accuracy: 0.9198\n",
            "Epoch 60/100\n",
            "187/187 [==============================] - 0s 215us/step - loss: 0.0533 - accuracy: 0.9519\n",
            "Epoch 61/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0534 - accuracy: 0.9465\n",
            "Epoch 62/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0531 - accuracy: 0.9465\n",
            "Epoch 63/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0498 - accuracy: 0.9626\n",
            "Epoch 64/100\n",
            "187/187 [==============================] - 0s 250us/step - loss: 0.0504 - accuracy: 0.9626\n",
            "Epoch 65/100\n",
            "187/187 [==============================] - 0s 247us/step - loss: 0.0489 - accuracy: 0.9572\n",
            "Epoch 66/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0464 - accuracy: 0.9679\n",
            "Epoch 67/100\n",
            "187/187 [==============================] - 0s 243us/step - loss: 0.0498 - accuracy: 0.9626\n",
            "Epoch 68/100\n",
            "187/187 [==============================] - 0s 249us/step - loss: 0.0481 - accuracy: 0.9572\n",
            "Epoch 69/100\n",
            "187/187 [==============================] - 0s 258us/step - loss: 0.0445 - accuracy: 0.9626\n",
            "Epoch 70/100\n",
            "187/187 [==============================] - 0s 264us/step - loss: 0.0405 - accuracy: 0.9626\n",
            "Epoch 71/100\n",
            "187/187 [==============================] - 0s 246us/step - loss: 0.0411 - accuracy: 0.9679\n",
            "Epoch 72/100\n",
            "187/187 [==============================] - 0s 278us/step - loss: 0.0446 - accuracy: 0.9572\n",
            "Epoch 73/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0395 - accuracy: 0.9679\n",
            "Epoch 74/100\n",
            "187/187 [==============================] - 0s 251us/step - loss: 0.0375 - accuracy: 0.9679\n",
            "Epoch 75/100\n",
            "187/187 [==============================] - 0s 255us/step - loss: 0.0376 - accuracy: 0.9733\n",
            "Epoch 76/100\n",
            "187/187 [==============================] - 0s 256us/step - loss: 0.0367 - accuracy: 0.9733\n",
            "Epoch 77/100\n",
            "187/187 [==============================] - 0s 252us/step - loss: 0.0357 - accuracy: 0.9679\n",
            "Epoch 78/100\n",
            "187/187 [==============================] - 0s 269us/step - loss: 0.0335 - accuracy: 0.9733\n",
            "Epoch 79/100\n",
            "187/187 [==============================] - 0s 263us/step - loss: 0.0333 - accuracy: 0.9786\n",
            "Epoch 80/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0329 - accuracy: 0.9786\n",
            "Epoch 81/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0316 - accuracy: 0.9733\n",
            "Epoch 82/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0314 - accuracy: 0.9679\n",
            "Epoch 83/100\n",
            "187/187 [==============================] - 0s 253us/step - loss: 0.0310 - accuracy: 0.9786\n",
            "Epoch 84/100\n",
            "187/187 [==============================] - 0s 230us/step - loss: 0.0280 - accuracy: 0.9786\n",
            "Epoch 85/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0305 - accuracy: 0.9733\n",
            "Epoch 86/100\n",
            "187/187 [==============================] - 0s 227us/step - loss: 0.0309 - accuracy: 0.9786\n",
            "Epoch 87/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0267 - accuracy: 0.9679\n",
            "Epoch 88/100\n",
            "187/187 [==============================] - 0s 231us/step - loss: 0.0261 - accuracy: 0.9679\n",
            "Epoch 89/100\n",
            "187/187 [==============================] - 0s 236us/step - loss: 0.0240 - accuracy: 0.9840\n",
            "Epoch 90/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0222 - accuracy: 0.9840\n",
            "Epoch 91/100\n",
            "187/187 [==============================] - 0s 217us/step - loss: 0.0243 - accuracy: 0.9786\n",
            "Epoch 92/100\n",
            "187/187 [==============================] - 0s 226us/step - loss: 0.0217 - accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "187/187 [==============================] - 0s 214us/step - loss: 0.0226 - accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "187/187 [==============================] - 0s 248us/step - loss: 0.0197 - accuracy: 0.9893\n",
            "Epoch 95/100\n",
            "187/187 [==============================] - 0s 225us/step - loss: 0.0219 - accuracy: 0.9786\n",
            "Epoch 96/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0189 - accuracy: 0.9840\n",
            "Epoch 97/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0207 - accuracy: 0.9893\n",
            "Epoch 98/100\n",
            "187/187 [==============================] - 0s 222us/step - loss: 0.0173 - accuracy: 0.9947\n",
            "Epoch 99/100\n",
            "187/187 [==============================] - 0s 223us/step - loss: 0.0161 - accuracy: 0.9947\n",
            "Epoch 100/100\n",
            "187/187 [==============================] - 0s 232us/step - loss: 0.0158 - accuracy: 0.9947\n",
            "21/21 [==============================] - 0s 657us/step\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - 0s 574us/step - loss: 0.2354 - accuracy: 0.5745\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.2237 - accuracy: 0.6543\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 0s 228us/step - loss: 0.2142 - accuracy: 0.7021\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.2058 - accuracy: 0.7021\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 0s 247us/step - loss: 0.1988 - accuracy: 0.7074\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 0s 229us/step - loss: 0.1906 - accuracy: 0.7394\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 0s 237us/step - loss: 0.1805 - accuracy: 0.7287\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 0s 213us/step - loss: 0.1747 - accuracy: 0.7979\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 0s 226us/step - loss: 0.1648 - accuracy: 0.7979\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.1578 - accuracy: 0.7926\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 0s 219us/step - loss: 0.1530 - accuracy: 0.7926\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 0s 221us/step - loss: 0.1487 - accuracy: 0.8085\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.1451 - accuracy: 0.8085\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.1381 - accuracy: 0.8457\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.1350 - accuracy: 0.8191\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 0s 214us/step - loss: 0.1316 - accuracy: 0.8404\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 0s 235us/step - loss: 0.1281 - accuracy: 0.8564\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 0s 220us/step - loss: 0.1293 - accuracy: 0.8404\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.1361 - accuracy: 0.8032\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.1251 - accuracy: 0.8457\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 0s 218us/step - loss: 0.1285 - accuracy: 0.8351\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 0s 221us/step - loss: 0.1152 - accuracy: 0.8564\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 0s 221us/step - loss: 0.1121 - accuracy: 0.8723\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.1114 - accuracy: 0.8457\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - 0s 221us/step - loss: 0.1092 - accuracy: 0.8777\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - 0s 240us/step - loss: 0.1070 - accuracy: 0.8617\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - 0s 215us/step - loss: 0.1076 - accuracy: 0.8564\n",
            "Epoch 28/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.1039 - accuracy: 0.8936\n",
            "Epoch 29/100\n",
            "188/188 [==============================] - 0s 254us/step - loss: 0.1179 - accuracy: 0.8245\n",
            "Epoch 30/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.1074 - accuracy: 0.8617\n",
            "Epoch 31/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0979 - accuracy: 0.8989\n",
            "Epoch 32/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.0975 - accuracy: 0.9043\n",
            "Epoch 33/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0995 - accuracy: 0.8777\n",
            "Epoch 34/100\n",
            "188/188 [==============================] - 0s 232us/step - loss: 0.0928 - accuracy: 0.8989\n",
            "Epoch 35/100\n",
            "188/188 [==============================] - 0s 228us/step - loss: 0.0918 - accuracy: 0.8936\n",
            "Epoch 36/100\n",
            "188/188 [==============================] - 0s 217us/step - loss: 0.0927 - accuracy: 0.8883\n",
            "Epoch 37/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.0919 - accuracy: 0.8670\n",
            "Epoch 38/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0865 - accuracy: 0.9255\n",
            "Epoch 39/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0859 - accuracy: 0.9096\n",
            "Epoch 40/100\n",
            "188/188 [==============================] - 0s 211us/step - loss: 0.0896 - accuracy: 0.8830\n",
            "Epoch 41/100\n",
            "188/188 [==============================] - 0s 226us/step - loss: 0.0839 - accuracy: 0.9096\n",
            "Epoch 42/100\n",
            "188/188 [==============================] - 0s 229us/step - loss: 0.0920 - accuracy: 0.8936\n",
            "Epoch 43/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0821 - accuracy: 0.9149\n",
            "Epoch 44/100\n",
            "188/188 [==============================] - 0s 237us/step - loss: 0.0805 - accuracy: 0.9202\n",
            "Epoch 45/100\n",
            "188/188 [==============================] - 0s 240us/step - loss: 0.0791 - accuracy: 0.9362\n",
            "Epoch 46/100\n",
            "188/188 [==============================] - 0s 262us/step - loss: 0.0791 - accuracy: 0.9096\n",
            "Epoch 47/100\n",
            "188/188 [==============================] - 0s 253us/step - loss: 0.0737 - accuracy: 0.9255\n",
            "Epoch 48/100\n",
            "188/188 [==============================] - 0s 253us/step - loss: 0.0756 - accuracy: 0.9255\n",
            "Epoch 49/100\n",
            "188/188 [==============================] - 0s 250us/step - loss: 0.0721 - accuracy: 0.9362\n",
            "Epoch 50/100\n",
            "188/188 [==============================] - 0s 273us/step - loss: 0.0718 - accuracy: 0.9043\n",
            "Epoch 51/100\n",
            "188/188 [==============================] - 0s 371us/step - loss: 0.0689 - accuracy: 0.9362\n",
            "Epoch 52/100\n",
            "188/188 [==============================] - 0s 317us/step - loss: 0.0677 - accuracy: 0.9309\n",
            "Epoch 53/100\n",
            "188/188 [==============================] - 0s 262us/step - loss: 0.0691 - accuracy: 0.9309\n",
            "Epoch 54/100\n",
            "188/188 [==============================] - 0s 281us/step - loss: 0.0681 - accuracy: 0.9309\n",
            "Epoch 55/100\n",
            "188/188 [==============================] - 0s 256us/step - loss: 0.0658 - accuracy: 0.9362\n",
            "Epoch 56/100\n",
            "188/188 [==============================] - 0s 257us/step - loss: 0.0675 - accuracy: 0.9309\n",
            "Epoch 57/100\n",
            "188/188 [==============================] - 0s 280us/step - loss: 0.0672 - accuracy: 0.9096\n",
            "Epoch 58/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0649 - accuracy: 0.9362\n",
            "Epoch 59/100\n",
            "188/188 [==============================] - 0s 249us/step - loss: 0.0641 - accuracy: 0.9255\n",
            "Epoch 60/100\n",
            "188/188 [==============================] - 0s 248us/step - loss: 0.0595 - accuracy: 0.9415\n",
            "Epoch 61/100\n",
            "188/188 [==============================] - 0s 271us/step - loss: 0.0607 - accuracy: 0.9415\n",
            "Epoch 62/100\n",
            "188/188 [==============================] - 0s 268us/step - loss: 0.0585 - accuracy: 0.9415\n",
            "Epoch 63/100\n",
            "188/188 [==============================] - 0s 260us/step - loss: 0.0591 - accuracy: 0.9415\n",
            "Epoch 64/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0544 - accuracy: 0.9468\n",
            "Epoch 65/100\n",
            "188/188 [==============================] - 0s 265us/step - loss: 0.0572 - accuracy: 0.9255\n",
            "Epoch 66/100\n",
            "188/188 [==============================] - 0s 271us/step - loss: 0.0603 - accuracy: 0.9415\n",
            "Epoch 67/100\n",
            "188/188 [==============================] - 0s 247us/step - loss: 0.0525 - accuracy: 0.9468\n",
            "Epoch 68/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0523 - accuracy: 0.9362\n",
            "Epoch 69/100\n",
            "188/188 [==============================] - 0s 262us/step - loss: 0.0499 - accuracy: 0.9468\n",
            "Epoch 70/100\n",
            "188/188 [==============================] - 0s 280us/step - loss: 0.0506 - accuracy: 0.9415\n",
            "Epoch 71/100\n",
            "188/188 [==============================] - 0s 240us/step - loss: 0.0507 - accuracy: 0.9521\n",
            "Epoch 72/100\n",
            "188/188 [==============================] - 0s 246us/step - loss: 0.0522 - accuracy: 0.9521\n",
            "Epoch 73/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0466 - accuracy: 0.9574\n",
            "Epoch 74/100\n",
            "188/188 [==============================] - 0s 252us/step - loss: 0.0485 - accuracy: 0.9574\n",
            "Epoch 75/100\n",
            "188/188 [==============================] - 0s 311us/step - loss: 0.0463 - accuracy: 0.9574\n",
            "Epoch 76/100\n",
            "188/188 [==============================] - 0s 241us/step - loss: 0.0440 - accuracy: 0.9521\n",
            "Epoch 77/100\n",
            "188/188 [==============================] - 0s 258us/step - loss: 0.0433 - accuracy: 0.9574\n",
            "Epoch 78/100\n",
            "188/188 [==============================] - 0s 254us/step - loss: 0.0474 - accuracy: 0.9574\n",
            "Epoch 79/100\n",
            "188/188 [==============================] - 0s 259us/step - loss: 0.0435 - accuracy: 0.9628\n",
            "Epoch 80/100\n",
            "188/188 [==============================] - 0s 283us/step - loss: 0.0414 - accuracy: 0.9628\n",
            "Epoch 81/100\n",
            "188/188 [==============================] - 0s 258us/step - loss: 0.0403 - accuracy: 0.9628\n",
            "Epoch 82/100\n",
            "188/188 [==============================] - 0s 255us/step - loss: 0.0384 - accuracy: 0.9574\n",
            "Epoch 83/100\n",
            "188/188 [==============================] - 0s 248us/step - loss: 0.0404 - accuracy: 0.9574\n",
            "Epoch 84/100\n",
            "188/188 [==============================] - 0s 230us/step - loss: 0.0376 - accuracy: 0.9681\n",
            "Epoch 85/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.0390 - accuracy: 0.9628\n",
            "Epoch 86/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.0378 - accuracy: 0.9681\n",
            "Epoch 87/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0360 - accuracy: 0.9628\n",
            "Epoch 88/100\n",
            "188/188 [==============================] - 0s 232us/step - loss: 0.0329 - accuracy: 0.9734\n",
            "Epoch 89/100\n",
            "188/188 [==============================] - 0s 244us/step - loss: 0.0341 - accuracy: 0.9734\n",
            "Epoch 90/100\n",
            "188/188 [==============================] - 0s 216us/step - loss: 0.0328 - accuracy: 0.9787\n",
            "Epoch 91/100\n",
            "188/188 [==============================] - 0s 247us/step - loss: 0.0358 - accuracy: 0.9628\n",
            "Epoch 92/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.0341 - accuracy: 0.9681\n",
            "Epoch 93/100\n",
            "188/188 [==============================] - 0s 217us/step - loss: 0.0344 - accuracy: 0.9628\n",
            "Epoch 94/100\n",
            "188/188 [==============================] - 0s 225us/step - loss: 0.0340 - accuracy: 0.9734\n",
            "Epoch 95/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0308 - accuracy: 0.9681\n",
            "Epoch 96/100\n",
            "188/188 [==============================] - 0s 231us/step - loss: 0.0288 - accuracy: 0.9734\n",
            "Epoch 97/100\n",
            "188/188 [==============================] - 0s 256us/step - loss: 0.0307 - accuracy: 0.9681\n",
            "Epoch 98/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0294 - accuracy: 0.9681\n",
            "Epoch 99/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0275 - accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "188/188 [==============================] - 0s 229us/step - loss: 0.0264 - accuracy: 0.9840\n",
            "20/20 [==============================] - 0s 606us/step\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - 0s 586us/step - loss: 0.2473 - accuracy: 0.5691\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.2375 - accuracy: 0.6862\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 0s 259us/step - loss: 0.2301 - accuracy: 0.7181\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.2186 - accuracy: 0.7553\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 0s 230us/step - loss: 0.2081 - accuracy: 0.7394\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 0s 221us/step - loss: 0.1970 - accuracy: 0.7181\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 0s 228us/step - loss: 0.1833 - accuracy: 0.7606\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.1760 - accuracy: 0.7660\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.1658 - accuracy: 0.7766\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.1563 - accuracy: 0.7979\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.1523 - accuracy: 0.8298\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 0s 235us/step - loss: 0.1475 - accuracy: 0.8191\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 0s 335us/step - loss: 0.1414 - accuracy: 0.8191\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.1334 - accuracy: 0.8245\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.1335 - accuracy: 0.8138\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 0s 226us/step - loss: 0.1332 - accuracy: 0.8138\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 0s 252us/step - loss: 0.1276 - accuracy: 0.8138\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 0s 237us/step - loss: 0.1280 - accuracy: 0.8245\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 0s 226us/step - loss: 0.1205 - accuracy: 0.8457\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 0s 246us/step - loss: 0.1214 - accuracy: 0.8351\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 0s 225us/step - loss: 0.1185 - accuracy: 0.8457\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 0s 228us/step - loss: 0.1158 - accuracy: 0.8457\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.1132 - accuracy: 0.8723\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 0s 229us/step - loss: 0.1134 - accuracy: 0.8457\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - 0s 249us/step - loss: 0.1121 - accuracy: 0.8670\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - 0s 219us/step - loss: 0.1054 - accuracy: 0.8457\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - 0s 220us/step - loss: 0.1051 - accuracy: 0.8457\n",
            "Epoch 28/100\n",
            "188/188 [==============================] - 0s 222us/step - loss: 0.1020 - accuracy: 0.8830\n",
            "Epoch 29/100\n",
            "188/188 [==============================] - 0s 258us/step - loss: 0.1018 - accuracy: 0.8670\n",
            "Epoch 30/100\n",
            "188/188 [==============================] - 0s 265us/step - loss: 0.0998 - accuracy: 0.8777\n",
            "Epoch 31/100\n",
            "188/188 [==============================] - 0s 260us/step - loss: 0.1019 - accuracy: 0.8617\n",
            "Epoch 32/100\n",
            "188/188 [==============================] - 0s 247us/step - loss: 0.0999 - accuracy: 0.8830\n",
            "Epoch 33/100\n",
            "188/188 [==============================] - 0s 263us/step - loss: 0.0981 - accuracy: 0.8883\n",
            "Epoch 34/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0935 - accuracy: 0.8883\n",
            "Epoch 35/100\n",
            "188/188 [==============================] - 0s 235us/step - loss: 0.0928 - accuracy: 0.8830\n",
            "Epoch 36/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0920 - accuracy: 0.8883\n",
            "Epoch 37/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0935 - accuracy: 0.8989\n",
            "Epoch 38/100\n",
            "188/188 [==============================] - 0s 228us/step - loss: 0.0872 - accuracy: 0.8883\n",
            "Epoch 39/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0824 - accuracy: 0.9149\n",
            "Epoch 40/100\n",
            "188/188 [==============================] - 0s 225us/step - loss: 0.0876 - accuracy: 0.9096\n",
            "Epoch 41/100\n",
            "188/188 [==============================] - 0s 225us/step - loss: 0.0924 - accuracy: 0.8617\n",
            "Epoch 42/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0821 - accuracy: 0.9202\n",
            "Epoch 43/100\n",
            "188/188 [==============================] - 0s 231us/step - loss: 0.0869 - accuracy: 0.9149\n",
            "Epoch 44/100\n",
            "188/188 [==============================] - 0s 237us/step - loss: 0.0804 - accuracy: 0.8936\n",
            "Epoch 45/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0787 - accuracy: 0.9255\n",
            "Epoch 46/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0789 - accuracy: 0.9149\n",
            "Epoch 47/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0752 - accuracy: 0.9202\n",
            "Epoch 48/100\n",
            "188/188 [==============================] - 0s 219us/step - loss: 0.0739 - accuracy: 0.9309\n",
            "Epoch 49/100\n",
            "188/188 [==============================] - 0s 227us/step - loss: 0.0711 - accuracy: 0.9202\n",
            "Epoch 50/100\n",
            "188/188 [==============================] - 0s 225us/step - loss: 0.0702 - accuracy: 0.9255\n",
            "Epoch 51/100\n",
            "188/188 [==============================] - 0s 228us/step - loss: 0.0693 - accuracy: 0.9309\n",
            "Epoch 52/100\n",
            "188/188 [==============================] - 0s 232us/step - loss: 0.0713 - accuracy: 0.9149\n",
            "Epoch 53/100\n",
            "188/188 [==============================] - 0s 243us/step - loss: 0.0655 - accuracy: 0.9255\n",
            "Epoch 54/100\n",
            "188/188 [==============================] - 0s 216us/step - loss: 0.0773 - accuracy: 0.8830\n",
            "Epoch 55/100\n",
            "188/188 [==============================] - 0s 225us/step - loss: 0.0676 - accuracy: 0.9149\n",
            "Epoch 56/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0633 - accuracy: 0.9309\n",
            "Epoch 57/100\n",
            "188/188 [==============================] - 0s 246us/step - loss: 0.0657 - accuracy: 0.9149\n",
            "Epoch 58/100\n",
            "188/188 [==============================] - 0s 220us/step - loss: 0.0632 - accuracy: 0.9309\n",
            "Epoch 59/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0618 - accuracy: 0.9255\n",
            "Epoch 60/100\n",
            "188/188 [==============================] - 0s 231us/step - loss: 0.0674 - accuracy: 0.9149\n",
            "Epoch 61/100\n",
            "188/188 [==============================] - 0s 230us/step - loss: 0.0831 - accuracy: 0.8883\n",
            "Epoch 62/100\n",
            "188/188 [==============================] - 0s 246us/step - loss: 0.0708 - accuracy: 0.8936\n",
            "Epoch 63/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0632 - accuracy: 0.9096\n",
            "Epoch 64/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0582 - accuracy: 0.9362\n",
            "Epoch 65/100\n",
            "188/188 [==============================] - 0s 223us/step - loss: 0.0583 - accuracy: 0.9362\n",
            "Epoch 66/100\n",
            "188/188 [==============================] - 0s 219us/step - loss: 0.0554 - accuracy: 0.9521\n",
            "Epoch 67/100\n",
            "188/188 [==============================] - 0s 221us/step - loss: 0.0574 - accuracy: 0.9309\n",
            "Epoch 68/100\n",
            "188/188 [==============================] - 0s 229us/step - loss: 0.0574 - accuracy: 0.9468\n",
            "Epoch 69/100\n",
            "188/188 [==============================] - 0s 237us/step - loss: 0.0584 - accuracy: 0.9309\n",
            "Epoch 70/100\n",
            "188/188 [==============================] - 0s 252us/step - loss: 0.0540 - accuracy: 0.9309\n",
            "Epoch 71/100\n",
            "188/188 [==============================] - 0s 226us/step - loss: 0.0531 - accuracy: 0.9309\n",
            "Epoch 72/100\n",
            "188/188 [==============================] - 0s 215us/step - loss: 0.0486 - accuracy: 0.9415\n",
            "Epoch 73/100\n",
            "188/188 [==============================] - 0s 220us/step - loss: 0.0514 - accuracy: 0.9468\n",
            "Epoch 74/100\n",
            "188/188 [==============================] - 0s 217us/step - loss: 0.0550 - accuracy: 0.9521\n",
            "Epoch 75/100\n",
            "188/188 [==============================] - 0s 218us/step - loss: 0.0475 - accuracy: 0.9574\n",
            "Epoch 76/100\n",
            "188/188 [==============================] - 0s 220us/step - loss: 0.0475 - accuracy: 0.9468\n",
            "Epoch 77/100\n",
            "188/188 [==============================] - 0s 219us/step - loss: 0.0557 - accuracy: 0.9255\n",
            "Epoch 78/100\n",
            "188/188 [==============================] - 0s 229us/step - loss: 0.0451 - accuracy: 0.9521\n",
            "Epoch 79/100\n",
            "188/188 [==============================] - 0s 251us/step - loss: 0.0491 - accuracy: 0.9574\n",
            "Epoch 80/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0442 - accuracy: 0.9521\n",
            "Epoch 81/100\n",
            "188/188 [==============================] - 0s 234us/step - loss: 0.0426 - accuracy: 0.9574\n",
            "Epoch 82/100\n",
            "188/188 [==============================] - 0s 234us/step - loss: 0.0423 - accuracy: 0.9468\n",
            "Epoch 83/100\n",
            "188/188 [==============================] - 0s 248us/step - loss: 0.0469 - accuracy: 0.9521\n",
            "Epoch 84/100\n",
            "188/188 [==============================] - 0s 242us/step - loss: 0.0413 - accuracy: 0.9521\n",
            "Epoch 85/100\n",
            "188/188 [==============================] - 0s 240us/step - loss: 0.0421 - accuracy: 0.9574\n",
            "Epoch 86/100\n",
            "188/188 [==============================] - 0s 252us/step - loss: 0.0447 - accuracy: 0.9628\n",
            "Epoch 87/100\n",
            "188/188 [==============================] - 0s 248us/step - loss: 0.0416 - accuracy: 0.9628\n",
            "Epoch 88/100\n",
            "188/188 [==============================] - 0s 256us/step - loss: 0.0411 - accuracy: 0.9681\n",
            "Epoch 89/100\n",
            "188/188 [==============================] - 0s 264us/step - loss: 0.0385 - accuracy: 0.9574\n",
            "Epoch 90/100\n",
            "188/188 [==============================] - 0s 264us/step - loss: 0.0375 - accuracy: 0.9574\n",
            "Epoch 91/100\n",
            "188/188 [==============================] - 0s 280us/step - loss: 0.0364 - accuracy: 0.9681\n",
            "Epoch 92/100\n",
            "188/188 [==============================] - 0s 294us/step - loss: 0.0383 - accuracy: 0.9681\n",
            "Epoch 93/100\n",
            "188/188 [==============================] - 0s 252us/step - loss: 0.0389 - accuracy: 0.9681\n",
            "Epoch 94/100\n",
            "188/188 [==============================] - 0s 255us/step - loss: 0.0522 - accuracy: 0.9309\n",
            "Epoch 95/100\n",
            "188/188 [==============================] - 0s 253us/step - loss: 0.0420 - accuracy: 0.9574\n",
            "Epoch 96/100\n",
            "188/188 [==============================] - 0s 267us/step - loss: 0.0312 - accuracy: 0.9787\n",
            "Epoch 97/100\n",
            "188/188 [==============================] - 0s 302us/step - loss: 0.0323 - accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "188/188 [==============================] - 0s 266us/step - loss: 0.0303 - accuracy: 0.9787\n",
            "Epoch 99/100\n",
            "188/188 [==============================] - 0s 250us/step - loss: 0.0307 - accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "188/188 [==============================] - 0s 224us/step - loss: 0.0298 - accuracy: 0.9787\n",
            "20/20 [==============================] - 0s 708us/step\n",
            "\n",
            " 10 fold Accuracy: ['0.6667', '0.7619', '0.8095', '0.9048', '0.8095', '0.8571', '0.9048', '0.8095', '0.9500', '0.8500']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSLsx111w6I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '1lzDJerOjrYCntwKNTh4_7mCp5c5T0Y4D'\n",
        "downloaded3 = drive.CreateFile({'id': file_id})\n",
        "downloaded3.GetContentFile('wine.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk-1UioOxBUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e7dcd7af-278e-4818-e16d-cbaac52ebd75"
      },
      "source": [
        "df_pre = pd.read_csv('wine.csv', header=None)\n",
        "df = df_pre.sample(frac=1)\n",
        "df.head(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>8.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.089</td>\n",
              "      <td>17.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99803</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.55</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1941</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.42</td>\n",
              "      <td>9.7</td>\n",
              "      <td>0.044</td>\n",
              "      <td>30.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.99620</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.47</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.23</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.080</td>\n",
              "      <td>11.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.99538</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.70</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3048</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.49</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.036</td>\n",
              "      <td>49.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.99320</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.27</td>\n",
              "      <td>11.5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2749</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.17</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0.042</td>\n",
              "      <td>69.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.99590</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.40</td>\n",
              "      <td>8.9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     2    3      4     5   ...       7     8     9     10  11  12\n",
              "751   8.3  0.65  0.10  2.9  0.089  17.0  ...  0.99803  3.29  0.55   9.5   5   1\n",
              "1941  6.4  0.26  0.42  9.7  0.044  30.0  ...  0.99620  3.18  0.47   9.1   6   0\n",
              "1184  6.7  0.64  0.23  2.1  0.080  11.0  ...  0.99538  3.36  0.70  10.9   5   1\n",
              "3048  6.9  0.19  0.49  6.6  0.036  49.0  ...  0.99320  3.20  0.27  11.5   6   0\n",
              "2749  6.9  0.32  0.17  7.6  0.042  69.0  ...  0.99590  3.13  0.40   8.9   5   0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjUa1KsPxJhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b4e1657b-a3b4-4cba-e42b-0ba881ede027"
      },
      "source": [
        "df.info"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of        0     1     2     3      4     5   ...       7     8     9     10  11  12\n",
              "751   8.3  0.65  0.10   2.9  0.089  17.0  ...  0.99803  3.29  0.55   9.5   5   1\n",
              "1941  6.4  0.26  0.42   9.7  0.044  30.0  ...  0.99620  3.18  0.47   9.1   6   0\n",
              "1184  6.7  0.64  0.23   2.1  0.080  11.0  ...  0.99538  3.36  0.70  10.9   5   1\n",
              "3048  6.9  0.19  0.49   6.6  0.036  49.0  ...  0.99320  3.20  0.27  11.5   6   0\n",
              "2749  6.9  0.32  0.17   7.6  0.042  69.0  ...  0.99590  3.13  0.40   8.9   5   0\n",
              "...   ...   ...   ...   ...    ...   ...  ...      ...   ...   ...   ...  ..  ..\n",
              "4106  7.1  0.34  0.31   5.2  0.032  36.0  ...  0.99166  3.35  0.47  12.3   7   0\n",
              "1126  5.8  0.29  0.26   1.7  0.063   3.0  ...  0.99150  3.39  0.54  13.5   6   1\n",
              "2303  5.6  0.25  0.26   3.6  0.037  18.0  ...  0.99040  3.42  0.50  12.6   6   0\n",
              "5799  8.0  0.24  0.33   1.2  0.044  28.0  ...  0.99035  3.03  0.43  12.5   6   0\n",
              "5613  6.5  0.18  0.48  18.0  0.054  56.0  ...  1.00038  2.98  0.61   8.5   6   0\n",
              "\n",
              "[6497 rows x 13 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCv8i3OxS4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dcd042d-cdd2-4daf-9a47-73d36ac39ece"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "df_pre = pd.read_csv('wine.csv', header=None)\n",
        "df = df_pre.sample(frac=1)\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:12]\n",
        "Y = dataset[:, 12]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, Y, epochs=200, batch_size=200)\n",
        "\n",
        "print('\\n Accuracy:%.4f'%(model.evaluate(X, Y)[1]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "6497/6497 [==============================] - 0s 24us/step - loss: 3.5323 - accuracy: 0.2461\n",
            "Epoch 2/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.4326 - accuracy: 0.8110\n",
            "Epoch 3/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.2418 - accuracy: 0.9257\n",
            "Epoch 4/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.2142 - accuracy: 0.9300\n",
            "Epoch 5/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.2039 - accuracy: 0.9306\n",
            "Epoch 6/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1979 - accuracy: 0.9320\n",
            "Epoch 7/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1931 - accuracy: 0.9324\n",
            "Epoch 8/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1888 - accuracy: 0.9324\n",
            "Epoch 9/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1865 - accuracy: 0.9329\n",
            "Epoch 10/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1842 - accuracy: 0.9335\n",
            "Epoch 11/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1825 - accuracy: 0.9340\n",
            "Epoch 12/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1799 - accuracy: 0.9340\n",
            "Epoch 13/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1779 - accuracy: 0.9361\n",
            "Epoch 14/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1756 - accuracy: 0.9380\n",
            "Epoch 15/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1665 - accuracy: 0.9395\n",
            "Epoch 16/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1573 - accuracy: 0.9431\n",
            "Epoch 17/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1526 - accuracy: 0.9467\n",
            "Epoch 18/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1452 - accuracy: 0.9469\n",
            "Epoch 19/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.1401 - accuracy: 0.9487\n",
            "Epoch 20/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1387 - accuracy: 0.9483\n",
            "Epoch 21/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1318 - accuracy: 0.9527\n",
            "Epoch 22/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1276 - accuracy: 0.9535\n",
            "Epoch 23/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.1230 - accuracy: 0.9551\n",
            "Epoch 24/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1221 - accuracy: 0.9554\n",
            "Epoch 25/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1180 - accuracy: 0.9591\n",
            "Epoch 26/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.1113 - accuracy: 0.9611\n",
            "Epoch 27/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1108 - accuracy: 0.9612\n",
            "Epoch 28/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.1108 - accuracy: 0.9618\n",
            "Epoch 29/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1058 - accuracy: 0.9624\n",
            "Epoch 30/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1048 - accuracy: 0.9651\n",
            "Epoch 31/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.1027 - accuracy: 0.9657\n",
            "Epoch 32/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0979 - accuracy: 0.9700\n",
            "Epoch 33/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0964 - accuracy: 0.9698\n",
            "Epoch 34/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0942 - accuracy: 0.9692\n",
            "Epoch 35/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0918 - accuracy: 0.9724\n",
            "Epoch 36/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0896 - accuracy: 0.9726\n",
            "Epoch 37/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0878 - accuracy: 0.9738\n",
            "Epoch 38/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0861 - accuracy: 0.9726\n",
            "Epoch 39/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0914 - accuracy: 0.9689\n",
            "Epoch 40/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0878 - accuracy: 0.9723\n",
            "Epoch 41/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0857 - accuracy: 0.9720\n",
            "Epoch 42/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0876 - accuracy: 0.9729\n",
            "Epoch 43/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0878 - accuracy: 0.9700\n",
            "Epoch 44/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0803 - accuracy: 0.9749\n",
            "Epoch 45/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0798 - accuracy: 0.9746\n",
            "Epoch 46/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0757 - accuracy: 0.9769\n",
            "Epoch 47/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0739 - accuracy: 0.9778\n",
            "Epoch 48/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0728 - accuracy: 0.9775\n",
            "Epoch 49/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0767 - accuracy: 0.9758\n",
            "Epoch 50/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0728 - accuracy: 0.9774\n",
            "Epoch 51/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0701 - accuracy: 0.9788\n",
            "Epoch 52/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0701 - accuracy: 0.9792\n",
            "Epoch 53/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0779 - accuracy: 0.9766\n",
            "Epoch 54/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0702 - accuracy: 0.9771\n",
            "Epoch 55/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0728 - accuracy: 0.9778\n",
            "Epoch 56/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0691 - accuracy: 0.9786\n",
            "Epoch 57/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0656 - accuracy: 0.9801\n",
            "Epoch 58/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0656 - accuracy: 0.9803\n",
            "Epoch 59/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0665 - accuracy: 0.9803\n",
            "Epoch 60/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0653 - accuracy: 0.9808\n",
            "Epoch 61/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0643 - accuracy: 0.9809\n",
            "Epoch 62/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0645 - accuracy: 0.9806\n",
            "Epoch 63/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0669 - accuracy: 0.9808\n",
            "Epoch 64/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0625 - accuracy: 0.9812\n",
            "Epoch 65/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0637 - accuracy: 0.9812\n",
            "Epoch 66/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0628 - accuracy: 0.9817\n",
            "Epoch 67/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0649 - accuracy: 0.9808\n",
            "Epoch 68/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0634 - accuracy: 0.9818\n",
            "Epoch 69/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0638 - accuracy: 0.9808\n",
            "Epoch 70/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0649 - accuracy: 0.9805\n",
            "Epoch 71/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0625 - accuracy: 0.9805\n",
            "Epoch 72/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0615 - accuracy: 0.9809\n",
            "Epoch 73/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0617 - accuracy: 0.9821\n",
            "Epoch 74/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0652 - accuracy: 0.9809\n",
            "Epoch 75/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0647 - accuracy: 0.9823\n",
            "Epoch 76/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0582 - accuracy: 0.9825\n",
            "Epoch 77/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0589 - accuracy: 0.9823\n",
            "Epoch 78/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0590 - accuracy: 0.9815\n",
            "Epoch 79/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0611 - accuracy: 0.9831\n",
            "Epoch 80/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0591 - accuracy: 0.9825\n",
            "Epoch 81/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0601 - accuracy: 0.9823\n",
            "Epoch 82/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0622 - accuracy: 0.9817\n",
            "Epoch 83/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0568 - accuracy: 0.9826\n",
            "Epoch 84/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0561 - accuracy: 0.9841\n",
            "Epoch 85/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0560 - accuracy: 0.9832\n",
            "Epoch 86/200\n",
            "6497/6497 [==============================] - 0s 10us/step - loss: 0.0572 - accuracy: 0.9832\n",
            "Epoch 87/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0714 - accuracy: 0.9785\n",
            "Epoch 88/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0698 - accuracy: 0.9803\n",
            "Epoch 89/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0566 - accuracy: 0.9835\n",
            "Epoch 90/200\n",
            "6497/6497 [==============================] - 0s 9us/step - loss: 0.0558 - accuracy: 0.9832\n",
            "Epoch 91/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0571 - accuracy: 0.9831\n",
            "Epoch 92/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0566 - accuracy: 0.9831\n",
            "Epoch 93/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0573 - accuracy: 0.9815\n",
            "Epoch 94/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0559 - accuracy: 0.9829\n",
            "Epoch 95/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0634 - accuracy: 0.9809\n",
            "Epoch 96/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0543 - accuracy: 0.9845\n",
            "Epoch 97/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0552 - accuracy: 0.9848\n",
            "Epoch 98/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0547 - accuracy: 0.9843\n",
            "Epoch 99/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0555 - accuracy: 0.9821\n",
            "Epoch 100/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0574 - accuracy: 0.9829\n",
            "Epoch 101/200\n",
            "6497/6497 [==============================] - 0s 9us/step - loss: 0.0572 - accuracy: 0.9831\n",
            "Epoch 102/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0535 - accuracy: 0.9854\n",
            "Epoch 103/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0557 - accuracy: 0.9848\n",
            "Epoch 104/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0547 - accuracy: 0.9826\n",
            "Epoch 105/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0570 - accuracy: 0.9838\n",
            "Epoch 106/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0555 - accuracy: 0.9835\n",
            "Epoch 107/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0527 - accuracy: 0.9843\n",
            "Epoch 108/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0622 - accuracy: 0.9815\n",
            "Epoch 109/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0557 - accuracy: 0.9834\n",
            "Epoch 110/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0543 - accuracy: 0.9832\n",
            "Epoch 111/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0527 - accuracy: 0.9854\n",
            "Epoch 112/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0541 - accuracy: 0.9843\n",
            "Epoch 113/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0586 - accuracy: 0.9829\n",
            "Epoch 114/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0577 - accuracy: 0.9848\n",
            "Epoch 115/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0564 - accuracy: 0.9835\n",
            "Epoch 116/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0544 - accuracy: 0.9845\n",
            "Epoch 117/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0566 - accuracy: 0.9831\n",
            "Epoch 118/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0557 - accuracy: 0.9831\n",
            "Epoch 119/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0567 - accuracy: 0.9832\n",
            "Epoch 120/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0568 - accuracy: 0.9838\n",
            "Epoch 121/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0557 - accuracy: 0.9829\n",
            "Epoch 122/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0531 - accuracy: 0.9855\n",
            "Epoch 123/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0562 - accuracy: 0.9840\n",
            "Epoch 124/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0540 - accuracy: 0.9841\n",
            "Epoch 125/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0542 - accuracy: 0.9841\n",
            "Epoch 126/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0514 - accuracy: 0.9849\n",
            "Epoch 127/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0546 - accuracy: 0.9840\n",
            "Epoch 128/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0577 - accuracy: 0.9805\n",
            "Epoch 129/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0522 - accuracy: 0.9855\n",
            "Epoch 130/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0499 - accuracy: 0.9860\n",
            "Epoch 131/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0528 - accuracy: 0.9843\n",
            "Epoch 132/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0523 - accuracy: 0.9854\n",
            "Epoch 133/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0512 - accuracy: 0.9845\n",
            "Epoch 134/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0574 - accuracy: 0.9832\n",
            "Epoch 135/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0511 - accuracy: 0.9854\n",
            "Epoch 136/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0500 - accuracy: 0.9857\n",
            "Epoch 137/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0511 - accuracy: 0.9849\n",
            "Epoch 138/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0566 - accuracy: 0.9838\n",
            "Epoch 139/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0536 - accuracy: 0.9846\n",
            "Epoch 140/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0514 - accuracy: 0.9848\n",
            "Epoch 141/200\n",
            "6497/6497 [==============================] - 0s 10us/step - loss: 0.0529 - accuracy: 0.9855\n",
            "Epoch 142/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0507 - accuracy: 0.9840\n",
            "Epoch 143/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0539 - accuracy: 0.9837\n",
            "Epoch 144/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0515 - accuracy: 0.9851\n",
            "Epoch 145/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0599 - accuracy: 0.9818\n",
            "Epoch 146/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0580 - accuracy: 0.9809\n",
            "Epoch 147/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0587 - accuracy: 0.9820\n",
            "Epoch 148/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0497 - accuracy: 0.9851\n",
            "Epoch 149/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0521 - accuracy: 0.9857\n",
            "Epoch 150/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0506 - accuracy: 0.9855\n",
            "Epoch 151/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0519 - accuracy: 0.9845\n",
            "Epoch 152/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0520 - accuracy: 0.9846\n",
            "Epoch 153/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0494 - accuracy: 0.9854\n",
            "Epoch 154/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0496 - accuracy: 0.9858\n",
            "Epoch 155/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0535 - accuracy: 0.9849\n",
            "Epoch 156/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0515 - accuracy: 0.9849\n",
            "Epoch 157/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0549 - accuracy: 0.9840\n",
            "Epoch 158/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0509 - accuracy: 0.9854\n",
            "Epoch 159/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0496 - accuracy: 0.9854\n",
            "Epoch 160/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0616 - accuracy: 0.9798\n",
            "Epoch 161/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0485 - accuracy: 0.9863\n",
            "Epoch 162/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0496 - accuracy: 0.9852\n",
            "Epoch 163/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0492 - accuracy: 0.9858\n",
            "Epoch 164/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0508 - accuracy: 0.9860\n",
            "Epoch 165/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0499 - accuracy: 0.9849\n",
            "Epoch 166/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0579 - accuracy: 0.9831\n",
            "Epoch 167/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0524 - accuracy: 0.9838\n",
            "Epoch 168/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0501 - accuracy: 0.9854\n",
            "Epoch 169/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0554 - accuracy: 0.9823\n",
            "Epoch 170/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0562 - accuracy: 0.9832\n",
            "Epoch 171/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0502 - accuracy: 0.9858\n",
            "Epoch 172/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0496 - accuracy: 0.9854\n",
            "Epoch 173/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0560 - accuracy: 0.9821\n",
            "Epoch 174/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0505 - accuracy: 0.9849\n",
            "Epoch 175/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0508 - accuracy: 0.9860\n",
            "Epoch 176/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0523 - accuracy: 0.9840\n",
            "Epoch 177/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0491 - accuracy: 0.9865\n",
            "Epoch 178/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0501 - accuracy: 0.9855\n",
            "Epoch 179/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0498 - accuracy: 0.9854\n",
            "Epoch 180/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0589 - accuracy: 0.9795\n",
            "Epoch 181/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0498 - accuracy: 0.9846\n",
            "Epoch 182/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0483 - accuracy: 0.9857\n",
            "Epoch 183/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0501 - accuracy: 0.9851\n",
            "Epoch 184/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0494 - accuracy: 0.9855\n",
            "Epoch 185/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0499 - accuracy: 0.9857\n",
            "Epoch 186/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0479 - accuracy: 0.9861\n",
            "Epoch 187/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0486 - accuracy: 0.9854\n",
            "Epoch 188/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0526 - accuracy: 0.9849\n",
            "Epoch 189/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0525 - accuracy: 0.9837\n",
            "Epoch 190/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0486 - accuracy: 0.9851\n",
            "Epoch 191/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0556 - accuracy: 0.9835\n",
            "Epoch 192/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0481 - accuracy: 0.9857\n",
            "Epoch 193/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0478 - accuracy: 0.9869\n",
            "Epoch 194/200\n",
            "6497/6497 [==============================] - 0s 7us/step - loss: 0.0501 - accuracy: 0.9846\n",
            "Epoch 195/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0479 - accuracy: 0.9866\n",
            "Epoch 196/200\n",
            "6497/6497 [==============================] - 0s 10us/step - loss: 0.0531 - accuracy: 0.9845\n",
            "Epoch 197/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0548 - accuracy: 0.9837\n",
            "Epoch 198/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0494 - accuracy: 0.9861\n",
            "Epoch 199/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0494 - accuracy: 0.9846\n",
            "Epoch 200/200\n",
            "6497/6497 [==============================] - 0s 8us/step - loss: 0.0489 - accuracy: 0.9861\n",
            "6497/6497 [==============================] - 0s 22us/step\n",
            "\n",
            " Accuracy:0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYEEO9c8De0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cd33cd9-dd4c-4464-c48b-8e49a29288b1"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 0\n",
        "numpy.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "df_pre = pd.read_csv('wine.csv', header=None)\n",
        "df = df_pre.sample(frac=0.15)\n",
        "\n",
        "dataset = df.values\n",
        "X = dataset[:,0:12]\n",
        "Y = dataset[:,12]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = './model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "   os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X, Y, validation_split=0.33, epochs=1000, batch_size=500)\n",
        "y_vloss=history.history['val_loss']\n",
        "y_acc=history.history['acc']\n",
        "\n",
        "x_len = numpy.arange(len(y_acc))\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 653 samples, validate on 322 samples\n",
            "Epoch 1/1000\n",
            "653/653 [==============================] - 0s 207us/step - loss: 0.5552 - accuracy: 0.7596 - val_loss: 0.4822 - val_accuracy: 0.7826\n",
            "Epoch 2/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.5047 - accuracy: 0.7596 - val_loss: 0.4472 - val_accuracy: 0.7826\n",
            "Epoch 3/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.4692 - accuracy: 0.7580 - val_loss: 0.4216 - val_accuracy: 0.7826\n",
            "Epoch 4/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.4386 - accuracy: 0.7596 - val_loss: 0.4090 - val_accuracy: 0.7733\n",
            "Epoch 5/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.4211 - accuracy: 0.7565 - val_loss: 0.3965 - val_accuracy: 0.7764\n",
            "Epoch 6/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.4019 - accuracy: 0.7626 - val_loss: 0.3770 - val_accuracy: 0.7888\n",
            "Epoch 7/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.3856 - accuracy: 0.7672 - val_loss: 0.3636 - val_accuracy: 0.7919\n",
            "Epoch 8/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.3748 - accuracy: 0.7825 - val_loss: 0.3557 - val_accuracy: 0.7981\n",
            "Epoch 9/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.3684 - accuracy: 0.7933 - val_loss: 0.3485 - val_accuracy: 0.8106\n",
            "Epoch 10/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.3613 - accuracy: 0.8009 - val_loss: 0.3422 - val_accuracy: 0.8261\n",
            "Epoch 11/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.3537 - accuracy: 0.8147 - val_loss: 0.3383 - val_accuracy: 0.8385\n",
            "Epoch 12/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.3485 - accuracy: 0.8315 - val_loss: 0.3352 - val_accuracy: 0.8540\n",
            "Epoch 13/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.3438 - accuracy: 0.8392 - val_loss: 0.3270 - val_accuracy: 0.8540\n",
            "Epoch 14/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.3375 - accuracy: 0.8484 - val_loss: 0.3195 - val_accuracy: 0.8602\n",
            "Epoch 15/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.3319 - accuracy: 0.8515 - val_loss: 0.3138 - val_accuracy: 0.8602\n",
            "Epoch 16/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.3266 - accuracy: 0.8530 - val_loss: 0.3073 - val_accuracy: 0.8665\n",
            "Epoch 17/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.3207 - accuracy: 0.8576 - val_loss: 0.3015 - val_accuracy: 0.8758\n",
            "Epoch 18/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.3131 - accuracy: 0.8714 - val_loss: 0.2951 - val_accuracy: 0.8758\n",
            "Epoch 19/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.3063 - accuracy: 0.8729 - val_loss: 0.2886 - val_accuracy: 0.8820\n",
            "Epoch 20/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.2994 - accuracy: 0.8806 - val_loss: 0.2827 - val_accuracy: 0.8944\n",
            "Epoch 21/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.2925 - accuracy: 0.8913 - val_loss: 0.2791 - val_accuracy: 0.9068\n",
            "Epoch 22/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.2875 - accuracy: 0.8913 - val_loss: 0.2711 - val_accuracy: 0.9068\n",
            "Epoch 23/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.2795 - accuracy: 0.8943 - val_loss: 0.2617 - val_accuracy: 0.9037\n",
            "Epoch 24/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.2728 - accuracy: 0.8959 - val_loss: 0.2568 - val_accuracy: 0.9037\n",
            "Epoch 25/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.2689 - accuracy: 0.8974 - val_loss: 0.2518 - val_accuracy: 0.9130\n",
            "Epoch 26/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2612 - accuracy: 0.9051 - val_loss: 0.2548 - val_accuracy: 0.9224\n",
            "Epoch 27/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2604 - accuracy: 0.9142 - val_loss: 0.2522 - val_accuracy: 0.9224\n",
            "Epoch 28/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.2572 - accuracy: 0.9188 - val_loss: 0.2438 - val_accuracy: 0.9255\n",
            "Epoch 29/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2496 - accuracy: 0.9173 - val_loss: 0.2375 - val_accuracy: 0.9255\n",
            "Epoch 30/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2447 - accuracy: 0.9142 - val_loss: 0.2356 - val_accuracy: 0.9255\n",
            "Epoch 31/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2432 - accuracy: 0.9142 - val_loss: 0.2324 - val_accuracy: 0.9255\n",
            "Epoch 32/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.2387 - accuracy: 0.9188 - val_loss: 0.2305 - val_accuracy: 0.9286\n",
            "Epoch 33/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.2362 - accuracy: 0.9204 - val_loss: 0.2337 - val_accuracy: 0.9441\n",
            "Epoch 34/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.2373 - accuracy: 0.9219 - val_loss: 0.2282 - val_accuracy: 0.9379\n",
            "Epoch 35/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.2317 - accuracy: 0.9219 - val_loss: 0.2234 - val_accuracy: 0.9286\n",
            "Epoch 36/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.2301 - accuracy: 0.9204 - val_loss: 0.2238 - val_accuracy: 0.9255\n",
            "Epoch 37/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.2292 - accuracy: 0.9204 - val_loss: 0.2200 - val_accuracy: 0.9286\n",
            "Epoch 38/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.2249 - accuracy: 0.9234 - val_loss: 0.2201 - val_accuracy: 0.9410\n",
            "Epoch 39/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.2245 - accuracy: 0.9234 - val_loss: 0.2192 - val_accuracy: 0.9441\n",
            "Epoch 40/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.2225 - accuracy: 0.9219 - val_loss: 0.2156 - val_accuracy: 0.9348\n",
            "Epoch 41/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.2209 - accuracy: 0.9265 - val_loss: 0.2200 - val_accuracy: 0.9224\n",
            "Epoch 42/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.2251 - accuracy: 0.9234 - val_loss: 0.2158 - val_accuracy: 0.9286\n",
            "Epoch 43/1000\n",
            "653/653 [==============================] - 0s 26us/step - loss: 0.2197 - accuracy: 0.9219 - val_loss: 0.2129 - val_accuracy: 0.9441\n",
            "Epoch 44/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2168 - accuracy: 0.9265 - val_loss: 0.2176 - val_accuracy: 0.9472\n",
            "Epoch 45/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.2204 - accuracy: 0.9296 - val_loss: 0.2121 - val_accuracy: 0.9472\n",
            "Epoch 46/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.2155 - accuracy: 0.9280 - val_loss: 0.2086 - val_accuracy: 0.9379\n",
            "Epoch 47/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.2131 - accuracy: 0.9250 - val_loss: 0.2100 - val_accuracy: 0.9317\n",
            "Epoch 48/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.2147 - accuracy: 0.9265 - val_loss: 0.2080 - val_accuracy: 0.9379\n",
            "Epoch 49/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.2122 - accuracy: 0.9265 - val_loss: 0.2051 - val_accuracy: 0.9441\n",
            "Epoch 50/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2104 - accuracy: 0.9250 - val_loss: 0.2069 - val_accuracy: 0.9503\n",
            "Epoch 51/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.2117 - accuracy: 0.9311 - val_loss: 0.2040 - val_accuracy: 0.9503\n",
            "Epoch 52/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2103 - accuracy: 0.9265 - val_loss: 0.2018 - val_accuracy: 0.9441\n",
            "Epoch 53/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2075 - accuracy: 0.9250 - val_loss: 0.2010 - val_accuracy: 0.9441\n",
            "Epoch 54/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.2066 - accuracy: 0.9250 - val_loss: 0.2000 - val_accuracy: 0.9441\n",
            "Epoch 55/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2059 - accuracy: 0.9296 - val_loss: 0.1992 - val_accuracy: 0.9441\n",
            "Epoch 56/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2051 - accuracy: 0.9296 - val_loss: 0.1984 - val_accuracy: 0.9441\n",
            "Epoch 57/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2043 - accuracy: 0.9296 - val_loss: 0.1977 - val_accuracy: 0.9441\n",
            "Epoch 58/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2038 - accuracy: 0.9296 - val_loss: 0.1970 - val_accuracy: 0.9472\n",
            "Epoch 59/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.2029 - accuracy: 0.9280 - val_loss: 0.1967 - val_accuracy: 0.9503\n",
            "Epoch 60/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.2023 - accuracy: 0.9280 - val_loss: 0.1956 - val_accuracy: 0.9503\n",
            "Epoch 61/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2015 - accuracy: 0.9280 - val_loss: 0.1952 - val_accuracy: 0.9441\n",
            "Epoch 62/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.2002 - accuracy: 0.9296 - val_loss: 0.1940 - val_accuracy: 0.9472\n",
            "Epoch 63/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.2000 - accuracy: 0.9296 - val_loss: 0.1933 - val_accuracy: 0.9472\n",
            "Epoch 64/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1987 - accuracy: 0.9280 - val_loss: 0.1947 - val_accuracy: 0.9441\n",
            "Epoch 65/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2004 - accuracy: 0.9280 - val_loss: 0.1968 - val_accuracy: 0.9441\n",
            "Epoch 66/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.2008 - accuracy: 0.9265 - val_loss: 0.1919 - val_accuracy: 0.9441\n",
            "Epoch 67/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1970 - accuracy: 0.9296 - val_loss: 0.1922 - val_accuracy: 0.9472\n",
            "Epoch 68/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1988 - accuracy: 0.9311 - val_loss: 0.1937 - val_accuracy: 0.9472\n",
            "Epoch 69/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1999 - accuracy: 0.9326 - val_loss: 0.1901 - val_accuracy: 0.9472\n",
            "Epoch 70/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1958 - accuracy: 0.9326 - val_loss: 0.1921 - val_accuracy: 0.9441\n",
            "Epoch 71/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1970 - accuracy: 0.9280 - val_loss: 0.1929 - val_accuracy: 0.9441\n",
            "Epoch 72/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1966 - accuracy: 0.9280 - val_loss: 0.1892 - val_accuracy: 0.9472\n",
            "Epoch 73/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1949 - accuracy: 0.9296 - val_loss: 0.1884 - val_accuracy: 0.9472\n",
            "Epoch 74/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1942 - accuracy: 0.9311 - val_loss: 0.1880 - val_accuracy: 0.9472\n",
            "Epoch 75/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1933 - accuracy: 0.9326 - val_loss: 0.1876 - val_accuracy: 0.9472\n",
            "Epoch 76/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1934 - accuracy: 0.9326 - val_loss: 0.1870 - val_accuracy: 0.9472\n",
            "Epoch 77/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1923 - accuracy: 0.9296 - val_loss: 0.1879 - val_accuracy: 0.9472\n",
            "Epoch 78/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1923 - accuracy: 0.9311 - val_loss: 0.1878 - val_accuracy: 0.9472\n",
            "Epoch 79/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1918 - accuracy: 0.9296 - val_loss: 0.1861 - val_accuracy: 0.9472\n",
            "Epoch 80/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1904 - accuracy: 0.9311 - val_loss: 0.1857 - val_accuracy: 0.9472\n",
            "Epoch 81/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1914 - accuracy: 0.9326 - val_loss: 0.1872 - val_accuracy: 0.9472\n",
            "Epoch 82/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.1933 - accuracy: 0.9326 - val_loss: 0.1846 - val_accuracy: 0.9472\n",
            "Epoch 83/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1896 - accuracy: 0.9311 - val_loss: 0.1906 - val_accuracy: 0.9410\n",
            "Epoch 84/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1937 - accuracy: 0.9296 - val_loss: 0.1907 - val_accuracy: 0.9410\n",
            "Epoch 85/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1920 - accuracy: 0.9296 - val_loss: 0.1840 - val_accuracy: 0.9472\n",
            "Epoch 86/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1883 - accuracy: 0.9326 - val_loss: 0.1863 - val_accuracy: 0.9503\n",
            "Epoch 87/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1921 - accuracy: 0.9311 - val_loss: 0.1844 - val_accuracy: 0.9472\n",
            "Epoch 88/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1894 - accuracy: 0.9326 - val_loss: 0.1837 - val_accuracy: 0.9441\n",
            "Epoch 89/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1887 - accuracy: 0.9326 - val_loss: 0.1850 - val_accuracy: 0.9472\n",
            "Epoch 90/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1876 - accuracy: 0.9326 - val_loss: 0.1824 - val_accuracy: 0.9472\n",
            "Epoch 91/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1861 - accuracy: 0.9311 - val_loss: 0.1823 - val_accuracy: 0.9472\n",
            "Epoch 92/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1875 - accuracy: 0.9342 - val_loss: 0.1817 - val_accuracy: 0.9472\n",
            "Epoch 93/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1864 - accuracy: 0.9326 - val_loss: 0.1828 - val_accuracy: 0.9472\n",
            "Epoch 94/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1858 - accuracy: 0.9326 - val_loss: 0.1822 - val_accuracy: 0.9441\n",
            "Epoch 95/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1851 - accuracy: 0.9326 - val_loss: 0.1805 - val_accuracy: 0.9472\n",
            "Epoch 96/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1851 - accuracy: 0.9326 - val_loss: 0.1802 - val_accuracy: 0.9472\n",
            "Epoch 97/1000\n",
            "653/653 [==============================] - 0s 25us/step - loss: 0.1846 - accuracy: 0.9342 - val_loss: 0.1809 - val_accuracy: 0.9441\n",
            "Epoch 98/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1841 - accuracy: 0.9326 - val_loss: 0.1794 - val_accuracy: 0.9472\n",
            "Epoch 99/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1828 - accuracy: 0.9372 - val_loss: 0.1812 - val_accuracy: 0.9503\n",
            "Epoch 100/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1874 - accuracy: 0.9326 - val_loss: 0.1803 - val_accuracy: 0.9503\n",
            "Epoch 101/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1859 - accuracy: 0.9342 - val_loss: 0.1791 - val_accuracy: 0.9441\n",
            "Epoch 102/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1818 - accuracy: 0.9342 - val_loss: 0.1819 - val_accuracy: 0.9472\n",
            "Epoch 103/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1842 - accuracy: 0.9342 - val_loss: 0.1808 - val_accuracy: 0.9472\n",
            "Epoch 104/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1828 - accuracy: 0.9326 - val_loss: 0.1774 - val_accuracy: 0.9472\n",
            "Epoch 105/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1819 - accuracy: 0.9311 - val_loss: 0.1771 - val_accuracy: 0.9472\n",
            "Epoch 106/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1809 - accuracy: 0.9357 - val_loss: 0.1782 - val_accuracy: 0.9441\n",
            "Epoch 107/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1808 - accuracy: 0.9357 - val_loss: 0.1829 - val_accuracy: 0.9472\n",
            "Epoch 108/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1836 - accuracy: 0.9342 - val_loss: 0.1801 - val_accuracy: 0.9472\n",
            "Epoch 109/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1806 - accuracy: 0.9342 - val_loss: 0.1756 - val_accuracy: 0.9472\n",
            "Epoch 110/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1800 - accuracy: 0.9342 - val_loss: 0.1782 - val_accuracy: 0.9503\n",
            "Epoch 111/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1843 - accuracy: 0.9342 - val_loss: 0.1757 - val_accuracy: 0.9503\n",
            "Epoch 112/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1799 - accuracy: 0.9372 - val_loss: 0.1762 - val_accuracy: 0.9441\n",
            "Epoch 113/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1784 - accuracy: 0.9326 - val_loss: 0.1830 - val_accuracy: 0.9472\n",
            "Epoch 114/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1832 - accuracy: 0.9342 - val_loss: 0.1845 - val_accuracy: 0.9441\n",
            "Epoch 115/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1838 - accuracy: 0.9342 - val_loss: 0.1793 - val_accuracy: 0.9472\n",
            "Epoch 116/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1791 - accuracy: 0.9342 - val_loss: 0.1739 - val_accuracy: 0.9503\n",
            "Epoch 117/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1771 - accuracy: 0.9372 - val_loss: 0.1765 - val_accuracy: 0.9503\n",
            "Epoch 118/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1822 - accuracy: 0.9357 - val_loss: 0.1740 - val_accuracy: 0.9503\n",
            "Epoch 119/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1777 - accuracy: 0.9372 - val_loss: 0.1759 - val_accuracy: 0.9441\n",
            "Epoch 120/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1783 - accuracy: 0.9326 - val_loss: 0.1803 - val_accuracy: 0.9472\n",
            "Epoch 121/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1797 - accuracy: 0.9342 - val_loss: 0.1736 - val_accuracy: 0.9441\n",
            "Epoch 122/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1746 - accuracy: 0.9387 - val_loss: 0.1766 - val_accuracy: 0.9503\n",
            "Epoch 123/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1841 - accuracy: 0.9342 - val_loss: 0.1747 - val_accuracy: 0.9503\n",
            "Epoch 124/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1783 - accuracy: 0.9342 - val_loss: 0.1748 - val_accuracy: 0.9441\n",
            "Epoch 125/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1774 - accuracy: 0.9326 - val_loss: 0.1849 - val_accuracy: 0.9441\n",
            "Epoch 126/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1827 - accuracy: 0.9311 - val_loss: 0.1778 - val_accuracy: 0.9472\n",
            "Epoch 127/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1764 - accuracy: 0.9326 - val_loss: 0.1704 - val_accuracy: 0.9503\n",
            "Epoch 128/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1754 - accuracy: 0.9418 - val_loss: 0.1726 - val_accuracy: 0.9503\n",
            "Epoch 129/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1793 - accuracy: 0.9342 - val_loss: 0.1700 - val_accuracy: 0.9503\n",
            "Epoch 130/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1742 - accuracy: 0.9403 - val_loss: 0.1700 - val_accuracy: 0.9441\n",
            "Epoch 131/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1743 - accuracy: 0.9326 - val_loss: 0.1727 - val_accuracy: 0.9441\n",
            "Epoch 132/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1735 - accuracy: 0.9326 - val_loss: 0.1700 - val_accuracy: 0.9441\n",
            "Epoch 133/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1724 - accuracy: 0.9357 - val_loss: 0.1685 - val_accuracy: 0.9472\n",
            "Epoch 134/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1715 - accuracy: 0.9357 - val_loss: 0.1685 - val_accuracy: 0.9441\n",
            "Epoch 135/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1711 - accuracy: 0.9342 - val_loss: 0.1692 - val_accuracy: 0.9441\n",
            "Epoch 136/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1711 - accuracy: 0.9326 - val_loss: 0.1691 - val_accuracy: 0.9441\n",
            "Epoch 137/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1708 - accuracy: 0.9326 - val_loss: 0.1679 - val_accuracy: 0.9472\n",
            "Epoch 138/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1702 - accuracy: 0.9342 - val_loss: 0.1674 - val_accuracy: 0.9472\n",
            "Epoch 139/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.1698 - accuracy: 0.9342 - val_loss: 0.1676 - val_accuracy: 0.9441\n",
            "Epoch 140/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1695 - accuracy: 0.9311 - val_loss: 0.1681 - val_accuracy: 0.9441\n",
            "Epoch 141/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1695 - accuracy: 0.9326 - val_loss: 0.1679 - val_accuracy: 0.9441\n",
            "Epoch 142/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1694 - accuracy: 0.9326 - val_loss: 0.1659 - val_accuracy: 0.9472\n",
            "Epoch 143/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1691 - accuracy: 0.9357 - val_loss: 0.1650 - val_accuracy: 0.9503\n",
            "Epoch 144/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1693 - accuracy: 0.9403 - val_loss: 0.1645 - val_accuracy: 0.9503\n",
            "Epoch 145/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1683 - accuracy: 0.9387 - val_loss: 0.1647 - val_accuracy: 0.9472\n",
            "Epoch 146/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1671 - accuracy: 0.9342 - val_loss: 0.1640 - val_accuracy: 0.9472\n",
            "Epoch 147/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1667 - accuracy: 0.9357 - val_loss: 0.1632 - val_accuracy: 0.9503\n",
            "Epoch 148/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1667 - accuracy: 0.9372 - val_loss: 0.1628 - val_accuracy: 0.9503\n",
            "Epoch 149/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1662 - accuracy: 0.9357 - val_loss: 0.1631 - val_accuracy: 0.9472\n",
            "Epoch 150/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1655 - accuracy: 0.9342 - val_loss: 0.1627 - val_accuracy: 0.9472\n",
            "Epoch 151/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1651 - accuracy: 0.9342 - val_loss: 0.1625 - val_accuracy: 0.9472\n",
            "Epoch 152/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1649 - accuracy: 0.9342 - val_loss: 0.1621 - val_accuracy: 0.9503\n",
            "Epoch 153/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1644 - accuracy: 0.9357 - val_loss: 0.1625 - val_accuracy: 0.9441\n",
            "Epoch 154/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1645 - accuracy: 0.9357 - val_loss: 0.1616 - val_accuracy: 0.9503\n",
            "Epoch 155/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1643 - accuracy: 0.9357 - val_loss: 0.1602 - val_accuracy: 0.9503\n",
            "Epoch 156/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1632 - accuracy: 0.9372 - val_loss: 0.1602 - val_accuracy: 0.9503\n",
            "Epoch 157/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1628 - accuracy: 0.9357 - val_loss: 0.1600 - val_accuracy: 0.9503\n",
            "Epoch 158/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1628 - accuracy: 0.9357 - val_loss: 0.1608 - val_accuracy: 0.9441\n",
            "Epoch 159/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1622 - accuracy: 0.9342 - val_loss: 0.1643 - val_accuracy: 0.9441\n",
            "Epoch 160/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1644 - accuracy: 0.9326 - val_loss: 0.1637 - val_accuracy: 0.9441\n",
            "Epoch 161/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1637 - accuracy: 0.9326 - val_loss: 0.1585 - val_accuracy: 0.9503\n",
            "Epoch 162/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1619 - accuracy: 0.9372 - val_loss: 0.1574 - val_accuracy: 0.9503\n",
            "Epoch 163/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1605 - accuracy: 0.9387 - val_loss: 0.1587 - val_accuracy: 0.9503\n",
            "Epoch 164/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1603 - accuracy: 0.9357 - val_loss: 0.1592 - val_accuracy: 0.9441\n",
            "Epoch 165/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1602 - accuracy: 0.9342 - val_loss: 0.1576 - val_accuracy: 0.9503\n",
            "Epoch 166/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1593 - accuracy: 0.9357 - val_loss: 0.1555 - val_accuracy: 0.9503\n",
            "Epoch 167/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1599 - accuracy: 0.9433 - val_loss: 0.1551 - val_accuracy: 0.9503\n",
            "Epoch 168/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1603 - accuracy: 0.9449 - val_loss: 0.1552 - val_accuracy: 0.9503\n",
            "Epoch 169/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1580 - accuracy: 0.9387 - val_loss: 0.1579 - val_accuracy: 0.9472\n",
            "Epoch 170/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1593 - accuracy: 0.9326 - val_loss: 0.1581 - val_accuracy: 0.9441\n",
            "Epoch 171/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1584 - accuracy: 0.9326 - val_loss: 0.1544 - val_accuracy: 0.9503\n",
            "Epoch 172/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1581 - accuracy: 0.9387 - val_loss: 0.1539 - val_accuracy: 0.9503\n",
            "Epoch 173/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1565 - accuracy: 0.9372 - val_loss: 0.1564 - val_accuracy: 0.9472\n",
            "Epoch 174/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1568 - accuracy: 0.9326 - val_loss: 0.1613 - val_accuracy: 0.9503\n",
            "Epoch 175/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1608 - accuracy: 0.9342 - val_loss: 0.1605 - val_accuracy: 0.9503\n",
            "Epoch 176/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1586 - accuracy: 0.9342 - val_loss: 0.1520 - val_accuracy: 0.9503\n",
            "Epoch 177/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1550 - accuracy: 0.9433 - val_loss: 0.1523 - val_accuracy: 0.9472\n",
            "Epoch 178/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1594 - accuracy: 0.9418 - val_loss: 0.1511 - val_accuracy: 0.9503\n",
            "Epoch 179/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1570 - accuracy: 0.9433 - val_loss: 0.1521 - val_accuracy: 0.9503\n",
            "Epoch 180/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1552 - accuracy: 0.9342 - val_loss: 0.1547 - val_accuracy: 0.9472\n",
            "Epoch 181/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1552 - accuracy: 0.9326 - val_loss: 0.1517 - val_accuracy: 0.9503\n",
            "Epoch 182/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1534 - accuracy: 0.9387 - val_loss: 0.1492 - val_accuracy: 0.9503\n",
            "Epoch 183/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1539 - accuracy: 0.9449 - val_loss: 0.1489 - val_accuracy: 0.9503\n",
            "Epoch 184/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1551 - accuracy: 0.9418 - val_loss: 0.1492 - val_accuracy: 0.9503\n",
            "Epoch 185/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1521 - accuracy: 0.9372 - val_loss: 0.1572 - val_accuracy: 0.9503\n",
            "Epoch 186/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1563 - accuracy: 0.9342 - val_loss: 0.1572 - val_accuracy: 0.9503\n",
            "Epoch 187/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1556 - accuracy: 0.9342 - val_loss: 0.1492 - val_accuracy: 0.9534\n",
            "Epoch 188/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1509 - accuracy: 0.9433 - val_loss: 0.1475 - val_accuracy: 0.9503\n",
            "Epoch 189/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1530 - accuracy: 0.9433 - val_loss: 0.1473 - val_accuracy: 0.9472\n",
            "Epoch 190/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1523 - accuracy: 0.9433 - val_loss: 0.1481 - val_accuracy: 0.9534\n",
            "Epoch 191/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1497 - accuracy: 0.9326 - val_loss: 0.1535 - val_accuracy: 0.9472\n",
            "Epoch 192/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1525 - accuracy: 0.9342 - val_loss: 0.1548 - val_accuracy: 0.9472\n",
            "Epoch 193/1000\n",
            "653/653 [==============================] - 0s 21us/step - loss: 0.1530 - accuracy: 0.9342 - val_loss: 0.1494 - val_accuracy: 0.9503\n",
            "Epoch 194/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1484 - accuracy: 0.9326 - val_loss: 0.1456 - val_accuracy: 0.9503\n",
            "Epoch 195/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.1524 - accuracy: 0.9433 - val_loss: 0.1478 - val_accuracy: 0.9472\n",
            "Epoch 196/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1548 - accuracy: 0.9449 - val_loss: 0.1460 - val_accuracy: 0.9534\n",
            "Epoch 197/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1464 - accuracy: 0.9342 - val_loss: 0.1591 - val_accuracy: 0.9534\n",
            "Epoch 198/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1556 - accuracy: 0.9357 - val_loss: 0.1647 - val_accuracy: 0.9503\n",
            "Epoch 199/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1586 - accuracy: 0.9372 - val_loss: 0.1498 - val_accuracy: 0.9472\n",
            "Epoch 200/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1499 - accuracy: 0.9372 - val_loss: 0.1442 - val_accuracy: 0.9503\n",
            "Epoch 201/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1517 - accuracy: 0.9449 - val_loss: 0.1432 - val_accuracy: 0.9503\n",
            "Epoch 202/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1479 - accuracy: 0.9449 - val_loss: 0.1471 - val_accuracy: 0.9503\n",
            "Epoch 203/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1480 - accuracy: 0.9342 - val_loss: 0.1561 - val_accuracy: 0.9503\n",
            "Epoch 204/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1524 - accuracy: 0.9357 - val_loss: 0.1474 - val_accuracy: 0.9472\n",
            "Epoch 205/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1477 - accuracy: 0.9372 - val_loss: 0.1411 - val_accuracy: 0.9503\n",
            "Epoch 206/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1471 - accuracy: 0.9433 - val_loss: 0.1408 - val_accuracy: 0.9503\n",
            "Epoch 207/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1468 - accuracy: 0.9418 - val_loss: 0.1417 - val_accuracy: 0.9534\n",
            "Epoch 208/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1441 - accuracy: 0.9372 - val_loss: 0.1443 - val_accuracy: 0.9503\n",
            "Epoch 209/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1449 - accuracy: 0.9326 - val_loss: 0.1443 - val_accuracy: 0.9503\n",
            "Epoch 210/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1446 - accuracy: 0.9326 - val_loss: 0.1410 - val_accuracy: 0.9534\n",
            "Epoch 211/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1430 - accuracy: 0.9372 - val_loss: 0.1390 - val_accuracy: 0.9534\n",
            "Epoch 212/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1434 - accuracy: 0.9418 - val_loss: 0.1386 - val_accuracy: 0.9503\n",
            "Epoch 213/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1445 - accuracy: 0.9433 - val_loss: 0.1383 - val_accuracy: 0.9503\n",
            "Epoch 214/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1434 - accuracy: 0.9433 - val_loss: 0.1390 - val_accuracy: 0.9534\n",
            "Epoch 215/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1413 - accuracy: 0.9372 - val_loss: 0.1444 - val_accuracy: 0.9472\n",
            "Epoch 216/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1441 - accuracy: 0.9357 - val_loss: 0.1459 - val_accuracy: 0.9472\n",
            "Epoch 217/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1437 - accuracy: 0.9357 - val_loss: 0.1382 - val_accuracy: 0.9534\n",
            "Epoch 218/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1399 - accuracy: 0.9387 - val_loss: 0.1378 - val_accuracy: 0.9503\n",
            "Epoch 219/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1479 - accuracy: 0.9464 - val_loss: 0.1359 - val_accuracy: 0.9503\n",
            "Epoch 220/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1420 - accuracy: 0.9418 - val_loss: 0.1439 - val_accuracy: 0.9472\n",
            "Epoch 221/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1449 - accuracy: 0.9357 - val_loss: 0.1457 - val_accuracy: 0.9503\n",
            "Epoch 222/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1434 - accuracy: 0.9357 - val_loss: 0.1361 - val_accuracy: 0.9534\n",
            "Epoch 223/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1383 - accuracy: 0.9403 - val_loss: 0.1358 - val_accuracy: 0.9503\n",
            "Epoch 224/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1442 - accuracy: 0.9464 - val_loss: 0.1352 - val_accuracy: 0.9503\n",
            "Epoch 225/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1424 - accuracy: 0.9495 - val_loss: 0.1366 - val_accuracy: 0.9534\n",
            "Epoch 226/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1380 - accuracy: 0.9372 - val_loss: 0.1428 - val_accuracy: 0.9503\n",
            "Epoch 227/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1410 - accuracy: 0.9372 - val_loss: 0.1409 - val_accuracy: 0.9503\n",
            "Epoch 228/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1387 - accuracy: 0.9372 - val_loss: 0.1339 - val_accuracy: 0.9534\n",
            "Epoch 229/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1374 - accuracy: 0.9433 - val_loss: 0.1339 - val_accuracy: 0.9503\n",
            "Epoch 230/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1423 - accuracy: 0.9449 - val_loss: 0.1322 - val_accuracy: 0.9503\n",
            "Epoch 231/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1383 - accuracy: 0.9449 - val_loss: 0.1341 - val_accuracy: 0.9534\n",
            "Epoch 232/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1362 - accuracy: 0.9372 - val_loss: 0.1371 - val_accuracy: 0.9503\n",
            "Epoch 233/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1383 - accuracy: 0.9387 - val_loss: 0.1334 - val_accuracy: 0.9534\n",
            "Epoch 234/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1370 - accuracy: 0.9387 - val_loss: 0.1309 - val_accuracy: 0.9503\n",
            "Epoch 235/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1374 - accuracy: 0.9449 - val_loss: 0.1312 - val_accuracy: 0.9534\n",
            "Epoch 236/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1342 - accuracy: 0.9449 - val_loss: 0.1368 - val_accuracy: 0.9503\n",
            "Epoch 237/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1375 - accuracy: 0.9387 - val_loss: 0.1375 - val_accuracy: 0.9503\n",
            "Epoch 238/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1351 - accuracy: 0.9387 - val_loss: 0.1297 - val_accuracy: 0.9503\n",
            "Epoch 239/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1354 - accuracy: 0.9433 - val_loss: 0.1306 - val_accuracy: 0.9503\n",
            "Epoch 240/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1397 - accuracy: 0.9449 - val_loss: 0.1287 - val_accuracy: 0.9503\n",
            "Epoch 241/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1334 - accuracy: 0.9403 - val_loss: 0.1339 - val_accuracy: 0.9503\n",
            "Epoch 242/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1348 - accuracy: 0.9387 - val_loss: 0.1338 - val_accuracy: 0.9503\n",
            "Epoch 243/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1336 - accuracy: 0.9387 - val_loss: 0.1269 - val_accuracy: 0.9534\n",
            "Epoch 244/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1344 - accuracy: 0.9449 - val_loss: 0.1260 - val_accuracy: 0.9503\n",
            "Epoch 245/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1345 - accuracy: 0.9510 - val_loss: 0.1287 - val_accuracy: 0.9534\n",
            "Epoch 246/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1322 - accuracy: 0.9403 - val_loss: 0.1405 - val_accuracy: 0.9534\n",
            "Epoch 247/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1385 - accuracy: 0.9387 - val_loss: 0.1356 - val_accuracy: 0.9503\n",
            "Epoch 248/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1343 - accuracy: 0.9372 - val_loss: 0.1255 - val_accuracy: 0.9503\n",
            "Epoch 249/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1310 - accuracy: 0.9464 - val_loss: 0.1254 - val_accuracy: 0.9503\n",
            "Epoch 250/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1347 - accuracy: 0.9495 - val_loss: 0.1248 - val_accuracy: 0.9503\n",
            "Epoch 251/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1315 - accuracy: 0.9433 - val_loss: 0.1286 - val_accuracy: 0.9503\n",
            "Epoch 252/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1302 - accuracy: 0.9403 - val_loss: 0.1283 - val_accuracy: 0.9503\n",
            "Epoch 253/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1297 - accuracy: 0.9403 - val_loss: 0.1246 - val_accuracy: 0.9534\n",
            "Epoch 254/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1291 - accuracy: 0.9433 - val_loss: 0.1231 - val_accuracy: 0.9503\n",
            "Epoch 255/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1301 - accuracy: 0.9464 - val_loss: 0.1231 - val_accuracy: 0.9503\n",
            "Epoch 256/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1291 - accuracy: 0.9418 - val_loss: 0.1239 - val_accuracy: 0.9534\n",
            "Epoch 257/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1281 - accuracy: 0.9433 - val_loss: 0.1243 - val_accuracy: 0.9534\n",
            "Epoch 258/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1293 - accuracy: 0.9418 - val_loss: 0.1232 - val_accuracy: 0.9534\n",
            "Epoch 259/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1270 - accuracy: 0.9449 - val_loss: 0.1211 - val_accuracy: 0.9503\n",
            "Epoch 260/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1311 - accuracy: 0.9495 - val_loss: 0.1209 - val_accuracy: 0.9503\n",
            "Epoch 261/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1284 - accuracy: 0.9464 - val_loss: 0.1276 - val_accuracy: 0.9565\n",
            "Epoch 262/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1290 - accuracy: 0.9387 - val_loss: 0.1270 - val_accuracy: 0.9565\n",
            "Epoch 263/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1279 - accuracy: 0.9387 - val_loss: 0.1210 - val_accuracy: 0.9534\n",
            "Epoch 264/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1260 - accuracy: 0.9449 - val_loss: 0.1195 - val_accuracy: 0.9503\n",
            "Epoch 265/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1274 - accuracy: 0.9479 - val_loss: 0.1197 - val_accuracy: 0.9534\n",
            "Epoch 266/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1255 - accuracy: 0.9433 - val_loss: 0.1232 - val_accuracy: 0.9534\n",
            "Epoch 267/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1267 - accuracy: 0.9403 - val_loss: 0.1239 - val_accuracy: 0.9534\n",
            "Epoch 268/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1253 - accuracy: 0.9403 - val_loss: 0.1201 - val_accuracy: 0.9503\n",
            "Epoch 269/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1259 - accuracy: 0.9464 - val_loss: 0.1197 - val_accuracy: 0.9534\n",
            "Epoch 270/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1251 - accuracy: 0.9449 - val_loss: 0.1221 - val_accuracy: 0.9534\n",
            "Epoch 271/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1244 - accuracy: 0.9403 - val_loss: 0.1205 - val_accuracy: 0.9534\n",
            "Epoch 272/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1240 - accuracy: 0.9449 - val_loss: 0.1183 - val_accuracy: 0.9534\n",
            "Epoch 273/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1236 - accuracy: 0.9433 - val_loss: 0.1184 - val_accuracy: 0.9534\n",
            "Epoch 274/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1228 - accuracy: 0.9449 - val_loss: 0.1190 - val_accuracy: 0.9534\n",
            "Epoch 275/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1230 - accuracy: 0.9418 - val_loss: 0.1192 - val_accuracy: 0.9534\n",
            "Epoch 276/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.1220 - accuracy: 0.9449 - val_loss: 0.1171 - val_accuracy: 0.9534\n",
            "Epoch 277/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1225 - accuracy: 0.9449 - val_loss: 0.1170 - val_accuracy: 0.9534\n",
            "Epoch 278/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1221 - accuracy: 0.9449 - val_loss: 0.1188 - val_accuracy: 0.9534\n",
            "Epoch 279/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.1214 - accuracy: 0.9464 - val_loss: 0.1200 - val_accuracy: 0.9534\n",
            "Epoch 280/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1216 - accuracy: 0.9403 - val_loss: 0.1203 - val_accuracy: 0.9534\n",
            "Epoch 281/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1212 - accuracy: 0.9403 - val_loss: 0.1172 - val_accuracy: 0.9534\n",
            "Epoch 282/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1220 - accuracy: 0.9479 - val_loss: 0.1167 - val_accuracy: 0.9534\n",
            "Epoch 283/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1205 - accuracy: 0.9449 - val_loss: 0.1210 - val_accuracy: 0.9534\n",
            "Epoch 284/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.1210 - accuracy: 0.9403 - val_loss: 0.1214 - val_accuracy: 0.9534\n",
            "Epoch 285/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.1211 - accuracy: 0.9418 - val_loss: 0.1173 - val_accuracy: 0.9534\n",
            "Epoch 286/1000\n",
            "653/653 [==============================] - 0s 27us/step - loss: 0.1193 - accuracy: 0.9464 - val_loss: 0.1143 - val_accuracy: 0.9534\n",
            "Epoch 287/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1207 - accuracy: 0.9449 - val_loss: 0.1141 - val_accuracy: 0.9503\n",
            "Epoch 288/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1210 - accuracy: 0.9495 - val_loss: 0.1174 - val_accuracy: 0.9565\n",
            "Epoch 289/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1191 - accuracy: 0.9449 - val_loss: 0.1289 - val_accuracy: 0.9503\n",
            "Epoch 290/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1259 - accuracy: 0.9387 - val_loss: 0.1246 - val_accuracy: 0.9534\n",
            "Epoch 291/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1219 - accuracy: 0.9403 - val_loss: 0.1147 - val_accuracy: 0.9534\n",
            "Epoch 292/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1177 - accuracy: 0.9449 - val_loss: 0.1136 - val_accuracy: 0.9596\n",
            "Epoch 293/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1210 - accuracy: 0.9495 - val_loss: 0.1133 - val_accuracy: 0.9534\n",
            "Epoch 294/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.1166 - accuracy: 0.9464 - val_loss: 0.1207 - val_accuracy: 0.9565\n",
            "Epoch 295/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1197 - accuracy: 0.9418 - val_loss: 0.1271 - val_accuracy: 0.9503\n",
            "Epoch 296/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.1236 - accuracy: 0.9403 - val_loss: 0.1188 - val_accuracy: 0.9565\n",
            "Epoch 297/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1187 - accuracy: 0.9433 - val_loss: 0.1123 - val_accuracy: 0.9503\n",
            "Epoch 298/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1169 - accuracy: 0.9495 - val_loss: 0.1117 - val_accuracy: 0.9534\n",
            "Epoch 299/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1163 - accuracy: 0.9510 - val_loss: 0.1139 - val_accuracy: 0.9534\n",
            "Epoch 300/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1159 - accuracy: 0.9418 - val_loss: 0.1165 - val_accuracy: 0.9565\n",
            "Epoch 301/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1168 - accuracy: 0.9418 - val_loss: 0.1135 - val_accuracy: 0.9565\n",
            "Epoch 302/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1154 - accuracy: 0.9433 - val_loss: 0.1116 - val_accuracy: 0.9534\n",
            "Epoch 303/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1147 - accuracy: 0.9464 - val_loss: 0.1104 - val_accuracy: 0.9534\n",
            "Epoch 304/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1149 - accuracy: 0.9479 - val_loss: 0.1102 - val_accuracy: 0.9534\n",
            "Epoch 305/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1141 - accuracy: 0.9479 - val_loss: 0.1125 - val_accuracy: 0.9565\n",
            "Epoch 306/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1143 - accuracy: 0.9479 - val_loss: 0.1130 - val_accuracy: 0.9565\n",
            "Epoch 307/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1145 - accuracy: 0.9464 - val_loss: 0.1097 - val_accuracy: 0.9534\n",
            "Epoch 308/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1132 - accuracy: 0.9510 - val_loss: 0.1084 - val_accuracy: 0.9596\n",
            "Epoch 309/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1169 - accuracy: 0.9525 - val_loss: 0.1086 - val_accuracy: 0.9534\n",
            "Epoch 310/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1133 - accuracy: 0.9479 - val_loss: 0.1165 - val_accuracy: 0.9565\n",
            "Epoch 311/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1155 - accuracy: 0.9418 - val_loss: 0.1173 - val_accuracy: 0.9565\n",
            "Epoch 312/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1155 - accuracy: 0.9403 - val_loss: 0.1108 - val_accuracy: 0.9565\n",
            "Epoch 313/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1129 - accuracy: 0.9479 - val_loss: 0.1073 - val_accuracy: 0.9596\n",
            "Epoch 314/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1132 - accuracy: 0.9510 - val_loss: 0.1078 - val_accuracy: 0.9534\n",
            "Epoch 315/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1113 - accuracy: 0.9479 - val_loss: 0.1129 - val_accuracy: 0.9565\n",
            "Epoch 316/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1136 - accuracy: 0.9418 - val_loss: 0.1146 - val_accuracy: 0.9565\n",
            "Epoch 317/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1137 - accuracy: 0.9433 - val_loss: 0.1083 - val_accuracy: 0.9534\n",
            "Epoch 318/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1114 - accuracy: 0.9479 - val_loss: 0.1075 - val_accuracy: 0.9596\n",
            "Epoch 319/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1116 - accuracy: 0.9510 - val_loss: 0.1081 - val_accuracy: 0.9534\n",
            "Epoch 320/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1109 - accuracy: 0.9479 - val_loss: 0.1080 - val_accuracy: 0.9534\n",
            "Epoch 321/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1100 - accuracy: 0.9464 - val_loss: 0.1101 - val_accuracy: 0.9565\n",
            "Epoch 322/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1103 - accuracy: 0.9433 - val_loss: 0.1067 - val_accuracy: 0.9534\n",
            "Epoch 323/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1091 - accuracy: 0.9495 - val_loss: 0.1045 - val_accuracy: 0.9596\n",
            "Epoch 324/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1113 - accuracy: 0.9525 - val_loss: 0.1054 - val_accuracy: 0.9596\n",
            "Epoch 325/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1113 - accuracy: 0.9495 - val_loss: 0.1096 - val_accuracy: 0.9565\n",
            "Epoch 326/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1103 - accuracy: 0.9449 - val_loss: 0.1065 - val_accuracy: 0.9565\n",
            "Epoch 327/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.1085 - accuracy: 0.9479 - val_loss: 0.1067 - val_accuracy: 0.9565\n",
            "Epoch 328/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1083 - accuracy: 0.9464 - val_loss: 0.1083 - val_accuracy: 0.9565\n",
            "Epoch 329/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1090 - accuracy: 0.9449 - val_loss: 0.1069 - val_accuracy: 0.9565\n",
            "Epoch 330/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1076 - accuracy: 0.9479 - val_loss: 0.1032 - val_accuracy: 0.9596\n",
            "Epoch 331/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1086 - accuracy: 0.9556 - val_loss: 0.1030 - val_accuracy: 0.9627\n",
            "Epoch 332/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1088 - accuracy: 0.9556 - val_loss: 0.1048 - val_accuracy: 0.9596\n",
            "Epoch 333/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.1067 - accuracy: 0.9495 - val_loss: 0.1093 - val_accuracy: 0.9565\n",
            "Epoch 334/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1081 - accuracy: 0.9433 - val_loss: 0.1083 - val_accuracy: 0.9565\n",
            "Epoch 335/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1077 - accuracy: 0.9464 - val_loss: 0.1049 - val_accuracy: 0.9627\n",
            "Epoch 336/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1063 - accuracy: 0.9495 - val_loss: 0.1027 - val_accuracy: 0.9596\n",
            "Epoch 337/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1066 - accuracy: 0.9556 - val_loss: 0.1030 - val_accuracy: 0.9627\n",
            "Epoch 338/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1116 - accuracy: 0.9571 - val_loss: 0.1022 - val_accuracy: 0.9627\n",
            "Epoch 339/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1079 - accuracy: 0.9556 - val_loss: 0.1057 - val_accuracy: 0.9565\n",
            "Epoch 340/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.1067 - accuracy: 0.9464 - val_loss: 0.1109 - val_accuracy: 0.9534\n",
            "Epoch 341/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1077 - accuracy: 0.9433 - val_loss: 0.1034 - val_accuracy: 0.9627\n",
            "Epoch 342/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1044 - accuracy: 0.9525 - val_loss: 0.1010 - val_accuracy: 0.9627\n",
            "Epoch 343/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1079 - accuracy: 0.9587 - val_loss: 0.1010 - val_accuracy: 0.9627\n",
            "Epoch 344/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1046 - accuracy: 0.9525 - val_loss: 0.1077 - val_accuracy: 0.9565\n",
            "Epoch 345/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1065 - accuracy: 0.9449 - val_loss: 0.1055 - val_accuracy: 0.9565\n",
            "Epoch 346/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.1043 - accuracy: 0.9464 - val_loss: 0.0982 - val_accuracy: 0.9627\n",
            "Epoch 347/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1061 - accuracy: 0.9571 - val_loss: 0.0975 - val_accuracy: 0.9627\n",
            "Epoch 348/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1064 - accuracy: 0.9541 - val_loss: 0.1008 - val_accuracy: 0.9596\n",
            "Epoch 349/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1040 - accuracy: 0.9479 - val_loss: 0.1022 - val_accuracy: 0.9565\n",
            "Epoch 350/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1035 - accuracy: 0.9495 - val_loss: 0.0978 - val_accuracy: 0.9627\n",
            "Epoch 351/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.1031 - accuracy: 0.9571 - val_loss: 0.0969 - val_accuracy: 0.9627\n",
            "Epoch 352/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1037 - accuracy: 0.9556 - val_loss: 0.0984 - val_accuracy: 0.9658\n",
            "Epoch 353/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1020 - accuracy: 0.9571 - val_loss: 0.1022 - val_accuracy: 0.9565\n",
            "Epoch 354/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.1035 - accuracy: 0.9495 - val_loss: 0.1014 - val_accuracy: 0.9596\n",
            "Epoch 355/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1020 - accuracy: 0.9525 - val_loss: 0.0970 - val_accuracy: 0.9627\n",
            "Epoch 356/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1028 - accuracy: 0.9571 - val_loss: 0.0970 - val_accuracy: 0.9627\n",
            "Epoch 357/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1028 - accuracy: 0.9587 - val_loss: 0.0996 - val_accuracy: 0.9658\n",
            "Epoch 358/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1016 - accuracy: 0.9525 - val_loss: 0.1005 - val_accuracy: 0.9627\n",
            "Epoch 359/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1008 - accuracy: 0.9525 - val_loss: 0.0974 - val_accuracy: 0.9627\n",
            "Epoch 360/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1013 - accuracy: 0.9556 - val_loss: 0.0969 - val_accuracy: 0.9627\n",
            "Epoch 361/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.1023 - accuracy: 0.9617 - val_loss: 0.0997 - val_accuracy: 0.9627\n",
            "Epoch 362/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0996 - accuracy: 0.9556 - val_loss: 0.1092 - val_accuracy: 0.9534\n",
            "Epoch 363/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.1049 - accuracy: 0.9433 - val_loss: 0.1084 - val_accuracy: 0.9534\n",
            "Epoch 364/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.1036 - accuracy: 0.9449 - val_loss: 0.0998 - val_accuracy: 0.9596\n",
            "Epoch 365/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0990 - accuracy: 0.9571 - val_loss: 0.0964 - val_accuracy: 0.9627\n",
            "Epoch 366/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.1021 - accuracy: 0.9632 - val_loss: 0.0966 - val_accuracy: 0.9658\n",
            "Epoch 367/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0992 - accuracy: 0.9571 - val_loss: 0.1030 - val_accuracy: 0.9596\n",
            "Epoch 368/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1008 - accuracy: 0.9449 - val_loss: 0.1045 - val_accuracy: 0.9565\n",
            "Epoch 369/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.1021 - accuracy: 0.9464 - val_loss: 0.0979 - val_accuracy: 0.9596\n",
            "Epoch 370/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0980 - accuracy: 0.9602 - val_loss: 0.0962 - val_accuracy: 0.9689\n",
            "Epoch 371/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0982 - accuracy: 0.9602 - val_loss: 0.0962 - val_accuracy: 0.9658\n",
            "Epoch 372/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0976 - accuracy: 0.9602 - val_loss: 0.0988 - val_accuracy: 0.9596\n",
            "Epoch 373/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0979 - accuracy: 0.9571 - val_loss: 0.1001 - val_accuracy: 0.9627\n",
            "Epoch 374/1000\n",
            "653/653 [==============================] - 0s 23us/step - loss: 0.0984 - accuracy: 0.9525 - val_loss: 0.0973 - val_accuracy: 0.9596\n",
            "Epoch 375/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.0966 - accuracy: 0.9602 - val_loss: 0.0941 - val_accuracy: 0.9627\n",
            "Epoch 376/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0991 - accuracy: 0.9663 - val_loss: 0.0940 - val_accuracy: 0.9627\n",
            "Epoch 377/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0996 - accuracy: 0.9617 - val_loss: 0.0954 - val_accuracy: 0.9658\n",
            "Epoch 378/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0965 - accuracy: 0.9617 - val_loss: 0.0968 - val_accuracy: 0.9627\n",
            "Epoch 379/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0964 - accuracy: 0.9587 - val_loss: 0.0951 - val_accuracy: 0.9658\n",
            "Epoch 380/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0967 - accuracy: 0.9602 - val_loss: 0.0945 - val_accuracy: 0.9658\n",
            "Epoch 381/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0956 - accuracy: 0.9602 - val_loss: 0.0971 - val_accuracy: 0.9627\n",
            "Epoch 382/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0966 - accuracy: 0.9541 - val_loss: 0.0941 - val_accuracy: 0.9627\n",
            "Epoch 383/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0964 - accuracy: 0.9602 - val_loss: 0.0914 - val_accuracy: 0.9658\n",
            "Epoch 384/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0962 - accuracy: 0.9602 - val_loss: 0.0925 - val_accuracy: 0.9658\n",
            "Epoch 385/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0948 - accuracy: 0.9602 - val_loss: 0.0933 - val_accuracy: 0.9627\n",
            "Epoch 386/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0947 - accuracy: 0.9602 - val_loss: 0.0943 - val_accuracy: 0.9596\n",
            "Epoch 387/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0949 - accuracy: 0.9602 - val_loss: 0.0908 - val_accuracy: 0.9689\n",
            "Epoch 388/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0959 - accuracy: 0.9617 - val_loss: 0.0901 - val_accuracy: 0.9689\n",
            "Epoch 389/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0941 - accuracy: 0.9617 - val_loss: 0.0960 - val_accuracy: 0.9596\n",
            "Epoch 390/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0965 - accuracy: 0.9556 - val_loss: 0.0949 - val_accuracy: 0.9596\n",
            "Epoch 391/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0957 - accuracy: 0.9571 - val_loss: 0.0895 - val_accuracy: 0.9689\n",
            "Epoch 392/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0945 - accuracy: 0.9617 - val_loss: 0.0903 - val_accuracy: 0.9658\n",
            "Epoch 393/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0939 - accuracy: 0.9617 - val_loss: 0.0940 - val_accuracy: 0.9627\n",
            "Epoch 394/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0934 - accuracy: 0.9602 - val_loss: 0.0920 - val_accuracy: 0.9658\n",
            "Epoch 395/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0933 - accuracy: 0.9617 - val_loss: 0.0918 - val_accuracy: 0.9658\n",
            "Epoch 396/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0929 - accuracy: 0.9632 - val_loss: 0.0938 - val_accuracy: 0.9689\n",
            "Epoch 397/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0929 - accuracy: 0.9587 - val_loss: 0.0931 - val_accuracy: 0.9689\n",
            "Epoch 398/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0926 - accuracy: 0.9617 - val_loss: 0.0913 - val_accuracy: 0.9658\n",
            "Epoch 399/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0922 - accuracy: 0.9648 - val_loss: 0.0901 - val_accuracy: 0.9658\n",
            "Epoch 400/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0919 - accuracy: 0.9648 - val_loss: 0.0891 - val_accuracy: 0.9658\n",
            "Epoch 401/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0921 - accuracy: 0.9632 - val_loss: 0.0891 - val_accuracy: 0.9658\n",
            "Epoch 402/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0916 - accuracy: 0.9602 - val_loss: 0.0890 - val_accuracy: 0.9658\n",
            "Epoch 403/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0913 - accuracy: 0.9648 - val_loss: 0.0897 - val_accuracy: 0.9658\n",
            "Epoch 404/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.0894 - val_accuracy: 0.9658\n",
            "Epoch 405/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0910 - accuracy: 0.9632 - val_loss: 0.0880 - val_accuracy: 0.9596\n",
            "Epoch 406/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.0896 - val_accuracy: 0.9658\n",
            "Epoch 407/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0907 - accuracy: 0.9617 - val_loss: 0.0915 - val_accuracy: 0.9689\n",
            "Epoch 408/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0901 - accuracy: 0.9648 - val_loss: 0.0902 - val_accuracy: 0.9658\n",
            "Epoch 409/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0903 - accuracy: 0.9663 - val_loss: 0.0919 - val_accuracy: 0.9689\n",
            "Epoch 410/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0901 - accuracy: 0.9617 - val_loss: 0.0937 - val_accuracy: 0.9689\n",
            "Epoch 411/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0897 - accuracy: 0.9602 - val_loss: 0.0890 - val_accuracy: 0.9658\n",
            "Epoch 412/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0892 - accuracy: 0.9648 - val_loss: 0.0877 - val_accuracy: 0.9596\n",
            "Epoch 413/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0922 - accuracy: 0.9632 - val_loss: 0.0890 - val_accuracy: 0.9689\n",
            "Epoch 414/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0877 - accuracy: 0.9632 - val_loss: 0.1001 - val_accuracy: 0.9565\n",
            "Epoch 415/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0941 - accuracy: 0.9541 - val_loss: 0.0937 - val_accuracy: 0.9627\n",
            "Epoch 416/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0892 - accuracy: 0.9617 - val_loss: 0.0859 - val_accuracy: 0.9596\n",
            "Epoch 417/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0923 - accuracy: 0.9632 - val_loss: 0.0858 - val_accuracy: 0.9627\n",
            "Epoch 418/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0909 - accuracy: 0.9602 - val_loss: 0.0910 - val_accuracy: 0.9658\n",
            "Epoch 419/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0875 - accuracy: 0.9617 - val_loss: 0.0876 - val_accuracy: 0.9627\n",
            "Epoch 420/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0886 - accuracy: 0.9648 - val_loss: 0.0886 - val_accuracy: 0.9596\n",
            "Epoch 421/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.0882 - accuracy: 0.9632 - val_loss: 0.0941 - val_accuracy: 0.9658\n",
            "Epoch 422/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0863 - accuracy: 0.9678 - val_loss: 0.0930 - val_accuracy: 0.9658\n",
            "Epoch 423/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.0857 - accuracy: 0.9709 - val_loss: 0.0922 - val_accuracy: 0.9658\n",
            "Epoch 424/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0856 - accuracy: 0.9709 - val_loss: 0.0911 - val_accuracy: 0.9658\n",
            "Epoch 425/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0857 - accuracy: 0.9740 - val_loss: 0.0904 - val_accuracy: 0.9658\n",
            "Epoch 426/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0846 - accuracy: 0.9740 - val_loss: 0.0944 - val_accuracy: 0.9658\n",
            "Epoch 427/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0856 - accuracy: 0.9648 - val_loss: 0.0962 - val_accuracy: 0.9658\n",
            "Epoch 428/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0863 - accuracy: 0.9602 - val_loss: 0.0885 - val_accuracy: 0.9689\n",
            "Epoch 429/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0826 - accuracy: 0.9709 - val_loss: 0.0880 - val_accuracy: 0.9720\n",
            "Epoch 430/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0909 - accuracy: 0.9663 - val_loss: 0.0874 - val_accuracy: 0.9689\n",
            "Epoch 431/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0833 - accuracy: 0.9724 - val_loss: 0.1010 - val_accuracy: 0.9596\n",
            "Epoch 432/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0891 - accuracy: 0.9571 - val_loss: 0.0959 - val_accuracy: 0.9627\n",
            "Epoch 433/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0867 - accuracy: 0.9617 - val_loss: 0.0868 - val_accuracy: 0.9658\n",
            "Epoch 434/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0825 - accuracy: 0.9709 - val_loss: 0.0860 - val_accuracy: 0.9658\n",
            "Epoch 435/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0828 - accuracy: 0.9724 - val_loss: 0.0867 - val_accuracy: 0.9658\n",
            "Epoch 436/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0816 - accuracy: 0.9740 - val_loss: 0.0897 - val_accuracy: 0.9658\n",
            "Epoch 437/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0817 - accuracy: 0.9694 - val_loss: 0.0880 - val_accuracy: 0.9658\n",
            "Epoch 438/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0811 - accuracy: 0.9724 - val_loss: 0.0846 - val_accuracy: 0.9658\n",
            "Epoch 439/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0808 - accuracy: 0.9709 - val_loss: 0.0843 - val_accuracy: 0.9658\n",
            "Epoch 440/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0805 - accuracy: 0.9740 - val_loss: 0.0858 - val_accuracy: 0.9658\n",
            "Epoch 441/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0799 - accuracy: 0.9740 - val_loss: 0.0908 - val_accuracy: 0.9658\n",
            "Epoch 442/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0818 - accuracy: 0.9663 - val_loss: 0.0861 - val_accuracy: 0.9658\n",
            "Epoch 443/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0800 - accuracy: 0.9724 - val_loss: 0.0825 - val_accuracy: 0.9689\n",
            "Epoch 444/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0804 - accuracy: 0.9740 - val_loss: 0.0855 - val_accuracy: 0.9689\n",
            "Epoch 445/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0793 - accuracy: 0.9740 - val_loss: 0.0901 - val_accuracy: 0.9658\n",
            "Epoch 446/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0798 - accuracy: 0.9694 - val_loss: 0.0839 - val_accuracy: 0.9720\n",
            "Epoch 447/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0798 - accuracy: 0.9709 - val_loss: 0.0828 - val_accuracy: 0.9689\n",
            "Epoch 448/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0813 - accuracy: 0.9678 - val_loss: 0.0861 - val_accuracy: 0.9689\n",
            "Epoch 449/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0784 - accuracy: 0.9694 - val_loss: 0.0898 - val_accuracy: 0.9658\n",
            "Epoch 450/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0794 - accuracy: 0.9694 - val_loss: 0.0817 - val_accuracy: 0.9689\n",
            "Epoch 451/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0783 - accuracy: 0.9740 - val_loss: 0.0790 - val_accuracy: 0.9720\n",
            "Epoch 452/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0787 - accuracy: 0.9724 - val_loss: 0.0838 - val_accuracy: 0.9658\n",
            "Epoch 453/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0802 - accuracy: 0.9678 - val_loss: 0.0856 - val_accuracy: 0.9658\n",
            "Epoch 454/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0798 - accuracy: 0.9724 - val_loss: 0.0798 - val_accuracy: 0.9720\n",
            "Epoch 455/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0771 - accuracy: 0.9755 - val_loss: 0.0819 - val_accuracy: 0.9720\n",
            "Epoch 456/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0758 - accuracy: 0.9770 - val_loss: 0.0860 - val_accuracy: 0.9689\n",
            "Epoch 457/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0769 - accuracy: 0.9709 - val_loss: 0.0838 - val_accuracy: 0.9689\n",
            "Epoch 458/1000\n",
            "653/653 [==============================] - 0s 22us/step - loss: 0.0766 - accuracy: 0.9740 - val_loss: 0.0820 - val_accuracy: 0.9689\n",
            "Epoch 459/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 0.0848 - val_accuracy: 0.9689\n",
            "Epoch 460/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0761 - accuracy: 0.9724 - val_loss: 0.0853 - val_accuracy: 0.9689\n",
            "Epoch 461/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0755 - accuracy: 0.9740 - val_loss: 0.0824 - val_accuracy: 0.9720\n",
            "Epoch 462/1000\n",
            "653/653 [==============================] - 0s 24us/step - loss: 0.0747 - accuracy: 0.9740 - val_loss: 0.0842 - val_accuracy: 0.9720\n",
            "Epoch 463/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0752 - accuracy: 0.9724 - val_loss: 0.0842 - val_accuracy: 0.9720\n",
            "Epoch 464/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0758 - accuracy: 0.9724 - val_loss: 0.0801 - val_accuracy: 0.9720\n",
            "Epoch 465/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.0806 - val_accuracy: 0.9720\n",
            "Epoch 466/1000\n",
            "653/653 [==============================] - 0s 21us/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.0780 - val_accuracy: 0.9720\n",
            "Epoch 467/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0741 - accuracy: 0.9740 - val_loss: 0.0771 - val_accuracy: 0.9752\n",
            "Epoch 468/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0738 - accuracy: 0.9740 - val_loss: 0.0769 - val_accuracy: 0.9752\n",
            "Epoch 469/1000\n",
            "653/653 [==============================] - 0s 21us/step - loss: 0.0734 - accuracy: 0.9755 - val_loss: 0.0798 - val_accuracy: 0.9720\n",
            "Epoch 470/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0727 - accuracy: 0.9724 - val_loss: 0.0837 - val_accuracy: 0.9689\n",
            "Epoch 471/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0729 - accuracy: 0.9694 - val_loss: 0.0762 - val_accuracy: 0.9752\n",
            "Epoch 472/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.0750 - val_accuracy: 0.9689\n",
            "Epoch 473/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0710 - accuracy: 0.9740 - val_loss: 0.0790 - val_accuracy: 0.9720\n",
            "Epoch 474/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 0.0764 - val_accuracy: 0.9689\n",
            "Epoch 475/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0704 - accuracy: 0.9724 - val_loss: 0.0734 - val_accuracy: 0.9720\n",
            "Epoch 476/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0689 - accuracy: 0.9770 - val_loss: 0.0828 - val_accuracy: 0.9720\n",
            "Epoch 477/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.0748 - val_accuracy: 0.9689\n",
            "Epoch 478/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.0722 - val_accuracy: 0.9689\n",
            "Epoch 479/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0698 - accuracy: 0.9755 - val_loss: 0.0808 - val_accuracy: 0.9720\n",
            "Epoch 480/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.0877 - val_accuracy: 0.9689\n",
            "Epoch 481/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 0.0762 - val_accuracy: 0.9752\n",
            "Epoch 482/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0666 - accuracy: 0.9801 - val_loss: 0.0743 - val_accuracy: 0.9752\n",
            "Epoch 483/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0671 - accuracy: 0.9786 - val_loss: 0.0804 - val_accuracy: 0.9752\n",
            "Epoch 484/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0677 - accuracy: 0.9816 - val_loss: 0.0781 - val_accuracy: 0.9720\n",
            "Epoch 485/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.0744 - val_accuracy: 0.9720\n",
            "Epoch 486/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.0796 - val_accuracy: 0.9720\n",
            "Epoch 487/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0665 - accuracy: 0.9755 - val_loss: 0.0807 - val_accuracy: 0.9720\n",
            "Epoch 488/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0649 - accuracy: 0.9801 - val_loss: 0.0724 - val_accuracy: 0.9752\n",
            "Epoch 489/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0651 - accuracy: 0.9770 - val_loss: 0.0738 - val_accuracy: 0.9720\n",
            "Epoch 490/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0628 - accuracy: 0.9786 - val_loss: 0.0766 - val_accuracy: 0.9752\n",
            "Epoch 491/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0629 - accuracy: 0.9816 - val_loss: 0.0745 - val_accuracy: 0.9752\n",
            "Epoch 492/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0625 - accuracy: 0.9801 - val_loss: 0.0715 - val_accuracy: 0.9720\n",
            "Epoch 493/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0621 - accuracy: 0.9801 - val_loss: 0.0708 - val_accuracy: 0.9752\n",
            "Epoch 494/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0619 - accuracy: 0.9801 - val_loss: 0.0721 - val_accuracy: 0.9752\n",
            "Epoch 495/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0618 - accuracy: 0.9816 - val_loss: 0.0741 - val_accuracy: 0.9720\n",
            "Epoch 496/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0627 - accuracy: 0.9816 - val_loss: 0.0730 - val_accuracy: 0.9752\n",
            "Epoch 497/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0622 - accuracy: 0.9816 - val_loss: 0.0708 - val_accuracy: 0.9720\n",
            "Epoch 498/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.0666 - val_accuracy: 0.9752\n",
            "Epoch 499/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0634 - accuracy: 0.9801 - val_loss: 0.0697 - val_accuracy: 0.9720\n",
            "Epoch 500/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0605 - accuracy: 0.9816 - val_loss: 0.0797 - val_accuracy: 0.9720\n",
            "Epoch 501/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0621 - accuracy: 0.9832 - val_loss: 0.0796 - val_accuracy: 0.9720\n",
            "Epoch 502/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0606 - accuracy: 0.9832 - val_loss: 0.0700 - val_accuracy: 0.9752\n",
            "Epoch 503/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0640 - accuracy: 0.9740 - val_loss: 0.0711 - val_accuracy: 0.9752\n",
            "Epoch 504/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.0813 - val_accuracy: 0.9720\n",
            "Epoch 505/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0618 - accuracy: 0.9816 - val_loss: 0.0737 - val_accuracy: 0.9720\n",
            "Epoch 506/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0593 - accuracy: 0.9832 - val_loss: 0.0725 - val_accuracy: 0.9720\n",
            "Epoch 507/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0589 - accuracy: 0.9832 - val_loss: 0.0737 - val_accuracy: 0.9720\n",
            "Epoch 508/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 0.0772 - val_accuracy: 0.9720\n",
            "Epoch 509/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0612 - accuracy: 0.9801 - val_loss: 0.0728 - val_accuracy: 0.9720\n",
            "Epoch 510/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0598 - accuracy: 0.9801 - val_loss: 0.0667 - val_accuracy: 0.9752\n",
            "Epoch 511/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0609 - accuracy: 0.9816 - val_loss: 0.0721 - val_accuracy: 0.9720\n",
            "Epoch 512/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0720 - val_accuracy: 0.9720\n",
            "Epoch 513/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0677 - val_accuracy: 0.9783\n",
            "Epoch 514/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0592 - accuracy: 0.9816 - val_loss: 0.0718 - val_accuracy: 0.9720\n",
            "Epoch 515/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 0.0812 - val_accuracy: 0.9720\n",
            "Epoch 516/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.0743 - val_accuracy: 0.9720\n",
            "Epoch 517/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0667 - val_accuracy: 0.9752\n",
            "Epoch 518/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0600 - accuracy: 0.9770 - val_loss: 0.0666 - val_accuracy: 0.9752\n",
            "Epoch 519/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0777 - val_accuracy: 0.9720\n",
            "Epoch 520/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0609 - accuracy: 0.9801 - val_loss: 0.0814 - val_accuracy: 0.9720\n",
            "Epoch 521/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0664 - val_accuracy: 0.9783\n",
            "Epoch 522/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0658 - accuracy: 0.9755 - val_loss: 0.0688 - val_accuracy: 0.9752\n",
            "Epoch 523/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0554 - accuracy: 0.9847 - val_loss: 0.0944 - val_accuracy: 0.9720\n",
            "Epoch 524/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 0.0805 - val_accuracy: 0.9720\n",
            "Epoch 525/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0566 - accuracy: 0.9801 - val_loss: 0.0657 - val_accuracy: 0.9752\n",
            "Epoch 526/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0663 - accuracy: 0.9724 - val_loss: 0.0699 - val_accuracy: 0.9720\n",
            "Epoch 527/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0970 - val_accuracy: 0.9658\n",
            "Epoch 528/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0697 - accuracy: 0.9709 - val_loss: 0.0695 - val_accuracy: 0.9720\n",
            "Epoch 529/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0560 - accuracy: 0.9801 - val_loss: 0.0631 - val_accuracy: 0.9752\n",
            "Epoch 530/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0658 - accuracy: 0.9694 - val_loss: 0.0704 - val_accuracy: 0.9720\n",
            "Epoch 531/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.0863 - val_accuracy: 0.9689\n",
            "Epoch 532/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0635 - accuracy: 0.9786 - val_loss: 0.0684 - val_accuracy: 0.9720\n",
            "Epoch 533/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0614 - val_accuracy: 0.9783\n",
            "Epoch 534/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0590 - accuracy: 0.9770 - val_loss: 0.0688 - val_accuracy: 0.9720\n",
            "Epoch 535/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0884 - val_accuracy: 0.9689\n",
            "Epoch 536/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0637 - accuracy: 0.9755 - val_loss: 0.0690 - val_accuracy: 0.9720\n",
            "Epoch 537/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0545 - accuracy: 0.9786 - val_loss: 0.0604 - val_accuracy: 0.9783\n",
            "Epoch 538/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0591 - accuracy: 0.9740 - val_loss: 0.0653 - val_accuracy: 0.9752\n",
            "Epoch 539/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 0.0685 - val_accuracy: 0.9720\n",
            "Epoch 540/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0526 - accuracy: 0.9847 - val_loss: 0.0625 - val_accuracy: 0.9752\n",
            "Epoch 541/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0584 - accuracy: 0.9801 - val_loss: 0.0712 - val_accuracy: 0.9720\n",
            "Epoch 542/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0555 - accuracy: 0.9862 - val_loss: 0.0959 - val_accuracy: 0.9720\n",
            "Epoch 543/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0669 - accuracy: 0.9740 - val_loss: 0.0671 - val_accuracy: 0.9720\n",
            "Epoch 544/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.0647 - val_accuracy: 0.9783\n",
            "Epoch 545/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0710 - accuracy: 0.9663 - val_loss: 0.0665 - val_accuracy: 0.9720\n",
            "Epoch 546/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.0944 - val_accuracy: 0.9658\n",
            "Epoch 547/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0665 - accuracy: 0.9724 - val_loss: 0.0688 - val_accuracy: 0.9720\n",
            "Epoch 548/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0554 - accuracy: 0.9786 - val_loss: 0.0614 - val_accuracy: 0.9752\n",
            "Epoch 549/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0620 - accuracy: 0.9755 - val_loss: 0.0710 - val_accuracy: 0.9720\n",
            "Epoch 550/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9720\n",
            "Epoch 551/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0571 - accuracy: 0.9801 - val_loss: 0.0650 - val_accuracy: 0.9752\n",
            "Epoch 552/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0527 - accuracy: 0.9847 - val_loss: 0.0606 - val_accuracy: 0.9783\n",
            "Epoch 553/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 0.0770 - val_accuracy: 0.9720\n",
            "Epoch 554/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.1039 - val_accuracy: 0.9689\n",
            "Epoch 555/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0728 - accuracy: 0.9694 - val_loss: 0.0708 - val_accuracy: 0.9720\n",
            "Epoch 556/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.0618 - val_accuracy: 0.9783\n",
            "Epoch 557/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0652 - accuracy: 0.9724 - val_loss: 0.0703 - val_accuracy: 0.9720\n",
            "Epoch 558/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0563 - accuracy: 0.9801 - val_loss: 0.0889 - val_accuracy: 0.9720\n",
            "Epoch 559/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 0.0609 - val_accuracy: 0.9752\n",
            "Epoch 560/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0588 - val_accuracy: 0.9783\n",
            "Epoch 561/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0595 - accuracy: 0.9755 - val_loss: 0.0705 - val_accuracy: 0.9720\n",
            "Epoch 562/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.0716 - val_accuracy: 0.9720\n",
            "Epoch 563/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0627 - val_accuracy: 0.9752\n",
            "Epoch 564/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.0615 - val_accuracy: 0.9752\n",
            "Epoch 565/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0651 - val_accuracy: 0.9752\n",
            "Epoch 566/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0508 - accuracy: 0.9816 - val_loss: 0.0707 - val_accuracy: 0.9720\n",
            "Epoch 567/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0652 - val_accuracy: 0.9752\n",
            "Epoch 568/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.0642 - val_accuracy: 0.9752\n",
            "Epoch 569/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.0670 - val_accuracy: 0.9752\n",
            "Epoch 570/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0490 - accuracy: 0.9832 - val_loss: 0.0649 - val_accuracy: 0.9752\n",
            "Epoch 571/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0682 - val_accuracy: 0.9752\n",
            "Epoch 572/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.0723 - val_accuracy: 0.9720\n",
            "Epoch 573/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0636 - val_accuracy: 0.9752\n",
            "Epoch 574/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0482 - accuracy: 0.9847 - val_loss: 0.0594 - val_accuracy: 0.9752\n",
            "Epoch 575/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.0630 - val_accuracy: 0.9752\n",
            "Epoch 576/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.0797 - val_accuracy: 0.9720\n",
            "Epoch 577/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0750 - val_accuracy: 0.9720\n",
            "Epoch 578/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0588 - val_accuracy: 0.9752\n",
            "Epoch 579/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0507 - accuracy: 0.9801 - val_loss: 0.0581 - val_accuracy: 0.9783\n",
            "Epoch 580/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0531 - accuracy: 0.9801 - val_loss: 0.0698 - val_accuracy: 0.9720\n",
            "Epoch 581/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0509 - accuracy: 0.9816 - val_loss: 0.0830 - val_accuracy: 0.9752\n",
            "Epoch 582/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0544 - accuracy: 0.9816 - val_loss: 0.0611 - val_accuracy: 0.9752\n",
            "Epoch 583/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.0579 - val_accuracy: 0.9783\n",
            "Epoch 584/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0506 - accuracy: 0.9832 - val_loss: 0.0689 - val_accuracy: 0.9720\n",
            "Epoch 585/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.0800 - val_accuracy: 0.9720\n",
            "Epoch 586/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.0632 - val_accuracy: 0.9720\n",
            "Epoch 587/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0484 - accuracy: 0.9832 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
            "Epoch 588/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.0676 - val_accuracy: 0.9720\n",
            "Epoch 589/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0726 - val_accuracy: 0.9720\n",
            "Epoch 590/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.0585 - val_accuracy: 0.9752\n",
            "Epoch 591/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0471 - accuracy: 0.9847 - val_loss: 0.0556 - val_accuracy: 0.9783\n",
            "Epoch 592/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0649 - val_accuracy: 0.9720\n",
            "Epoch 593/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0636 - val_accuracy: 0.9720\n",
            "Epoch 594/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
            "Epoch 595/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0470 - accuracy: 0.9816 - val_loss: 0.0646 - val_accuracy: 0.9720\n",
            "Epoch 596/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.0754 - val_accuracy: 0.9752\n",
            "Epoch 597/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0630 - val_accuracy: 0.9752\n",
            "Epoch 598/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.0559 - val_accuracy: 0.9752\n",
            "Epoch 599/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0497 - accuracy: 0.9816 - val_loss: 0.0605 - val_accuracy: 0.9752\n",
            "Epoch 600/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0459 - accuracy: 0.9832 - val_loss: 0.0720 - val_accuracy: 0.9752\n",
            "Epoch 601/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.0627 - val_accuracy: 0.9752\n",
            "Epoch 602/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0461 - accuracy: 0.9847 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
            "Epoch 603/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0452 - accuracy: 0.9877 - val_loss: 0.0648 - val_accuracy: 0.9720\n",
            "Epoch 604/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.0638 - val_accuracy: 0.9720\n",
            "Epoch 605/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.0605 - val_accuracy: 0.9752\n",
            "Epoch 606/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0625 - val_accuracy: 0.9720\n",
            "Epoch 607/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0443 - accuracy: 0.9847 - val_loss: 0.0612 - val_accuracy: 0.9720\n",
            "Epoch 608/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0437 - accuracy: 0.9877 - val_loss: 0.0554 - val_accuracy: 0.9752\n",
            "Epoch 609/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0450 - accuracy: 0.9832 - val_loss: 0.0556 - val_accuracy: 0.9752\n",
            "Epoch 610/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.0632 - val_accuracy: 0.9720\n",
            "Epoch 611/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0684 - val_accuracy: 0.9720\n",
            "Epoch 612/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0468 - accuracy: 0.9816 - val_loss: 0.0613 - val_accuracy: 0.9720\n",
            "Epoch 613/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0451 - accuracy: 0.9832 - val_loss: 0.0567 - val_accuracy: 0.9752\n",
            "Epoch 614/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.0647 - val_accuracy: 0.9752\n",
            "Epoch 615/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.0695 - val_accuracy: 0.9752\n",
            "Epoch 616/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
            "Epoch 617/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0433 - accuracy: 0.9847 - val_loss: 0.0558 - val_accuracy: 0.9752\n",
            "Epoch 618/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
            "Epoch 619/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0657 - val_accuracy: 0.9720\n",
            "Epoch 620/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0446 - accuracy: 0.9847 - val_loss: 0.0642 - val_accuracy: 0.9720\n",
            "Epoch 621/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.0612 - val_accuracy: 0.9720\n",
            "Epoch 622/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.0570 - val_accuracy: 0.9752\n",
            "Epoch 623/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 0.0607 - val_accuracy: 0.9720\n",
            "Epoch 624/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.0655 - val_accuracy: 0.9720\n",
            "Epoch 625/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0438 - accuracy: 0.9847 - val_loss: 0.0587 - val_accuracy: 0.9752\n",
            "Epoch 626/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0423 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9752\n",
            "Epoch 627/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0433 - accuracy: 0.9847 - val_loss: 0.0610 - val_accuracy: 0.9720\n",
            "Epoch 628/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0698 - val_accuracy: 0.9752\n",
            "Epoch 629/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 0.0571 - val_accuracy: 0.9752\n",
            "Epoch 630/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.0529 - val_accuracy: 0.9752\n",
            "Epoch 631/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0463 - accuracy: 0.9847 - val_loss: 0.0639 - val_accuracy: 0.9752\n",
            "Epoch 632/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.0672 - val_accuracy: 0.9752\n",
            "Epoch 633/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.0538 - val_accuracy: 0.9752\n",
            "Epoch 634/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0456 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
            "Epoch 635/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0408 - accuracy: 0.9862 - val_loss: 0.0728 - val_accuracy: 0.9752\n",
            "Epoch 636/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0703 - val_accuracy: 0.9752\n",
            "Epoch 637/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0461 - accuracy: 0.9832 - val_loss: 0.0528 - val_accuracy: 0.9752\n",
            "Epoch 638/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0423 - accuracy: 0.9816 - val_loss: 0.0516 - val_accuracy: 0.9752\n",
            "Epoch 639/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0419 - accuracy: 0.9832 - val_loss: 0.0608 - val_accuracy: 0.9720\n",
            "Epoch 640/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0419 - accuracy: 0.9862 - val_loss: 0.0630 - val_accuracy: 0.9720\n",
            "Epoch 641/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0569 - val_accuracy: 0.9752\n",
            "Epoch 642/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.0566 - val_accuracy: 0.9752\n",
            "Epoch 643/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.0577 - val_accuracy: 0.9752\n",
            "Epoch 644/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.0600 - val_accuracy: 0.9752\n",
            "Epoch 645/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
            "Epoch 646/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0527 - val_accuracy: 0.9752\n",
            "Epoch 647/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0448 - accuracy: 0.9816 - val_loss: 0.0609 - val_accuracy: 0.9752\n",
            "Epoch 648/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.0725 - val_accuracy: 0.9752\n",
            "Epoch 649/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0434 - accuracy: 0.9832 - val_loss: 0.0576 - val_accuracy: 0.9752\n",
            "Epoch 650/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0407 - accuracy: 0.9862 - val_loss: 0.0544 - val_accuracy: 0.9752\n",
            "Epoch 651/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.0649 - val_accuracy: 0.9720\n",
            "Epoch 652/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.0732 - val_accuracy: 0.9752\n",
            "Epoch 653/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0438 - accuracy: 0.9847 - val_loss: 0.0573 - val_accuracy: 0.9752\n",
            "Epoch 654/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.0530 - val_accuracy: 0.9752\n",
            "Epoch 655/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0635 - val_accuracy: 0.9752\n",
            "Epoch 656/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.0671 - val_accuracy: 0.9752\n",
            "Epoch 657/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0410 - accuracy: 0.9862 - val_loss: 0.0545 - val_accuracy: 0.9752\n",
            "Epoch 658/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0404 - accuracy: 0.9877 - val_loss: 0.0526 - val_accuracy: 0.9752\n",
            "Epoch 659/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0422 - accuracy: 0.9847 - val_loss: 0.0568 - val_accuracy: 0.9752\n",
            "Epoch 660/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.0563 - val_accuracy: 0.9752\n",
            "Epoch 661/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.0554 - val_accuracy: 0.9752\n",
            "Epoch 662/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.0549 - val_accuracy: 0.9752\n",
            "Epoch 663/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0398 - accuracy: 0.9893 - val_loss: 0.0588 - val_accuracy: 0.9752\n",
            "Epoch 664/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0392 - accuracy: 0.9893 - val_loss: 0.0626 - val_accuracy: 0.9720\n",
            "Epoch 665/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 0.0569 - val_accuracy: 0.9752\n",
            "Epoch 666/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0387 - accuracy: 0.9862 - val_loss: 0.0543 - val_accuracy: 0.9752\n",
            "Epoch 667/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0398 - accuracy: 0.9832 - val_loss: 0.0550 - val_accuracy: 0.9752\n",
            "Epoch 668/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0390 - accuracy: 0.9832 - val_loss: 0.0554 - val_accuracy: 0.9752\n",
            "Epoch 669/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0394 - accuracy: 0.9832 - val_loss: 0.0562 - val_accuracy: 0.9752\n",
            "Epoch 670/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0396 - accuracy: 0.9847 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
            "Epoch 671/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 0.0639 - val_accuracy: 0.9752\n",
            "Epoch 672/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0385 - accuracy: 0.9862 - val_loss: 0.0534 - val_accuracy: 0.9752\n",
            "Epoch 673/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0401 - accuracy: 0.9862 - val_loss: 0.0527 - val_accuracy: 0.9752\n",
            "Epoch 674/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0406 - accuracy: 0.9847 - val_loss: 0.0615 - val_accuracy: 0.9720\n",
            "Epoch 675/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.0670 - val_accuracy: 0.9752\n",
            "Epoch 676/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.0570 - val_accuracy: 0.9752\n",
            "Epoch 677/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
            "Epoch 678/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0384 - accuracy: 0.9862 - val_loss: 0.0633 - val_accuracy: 0.9720\n",
            "Epoch 679/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 0.0602 - val_accuracy: 0.9752\n",
            "Epoch 680/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0535 - val_accuracy: 0.9752\n",
            "Epoch 681/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 0.0552 - val_accuracy: 0.9752\n",
            "Epoch 682/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0611 - val_accuracy: 0.9720\n",
            "Epoch 683/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0577 - val_accuracy: 0.9752\n",
            "Epoch 684/1000\n",
            "653/653 [==============================] - 0s 21us/step - loss: 0.0370 - accuracy: 0.9877 - val_loss: 0.0573 - val_accuracy: 0.9752\n",
            "Epoch 685/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0559 - val_accuracy: 0.9752\n",
            "Epoch 686/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0370 - accuracy: 0.9877 - val_loss: 0.0556 - val_accuracy: 0.9752\n",
            "Epoch 687/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.0580 - val_accuracy: 0.9783\n",
            "Epoch 688/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.0606 - val_accuracy: 0.9783\n",
            "Epoch 689/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0374 - accuracy: 0.9862 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
            "Epoch 690/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0371 - accuracy: 0.9862 - val_loss: 0.0567 - val_accuracy: 0.9783\n",
            "Epoch 691/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9752\n",
            "Epoch 692/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0563 - val_accuracy: 0.9752\n",
            "Epoch 693/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.0551 - val_accuracy: 0.9752\n",
            "Epoch 694/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.0509 - val_accuracy: 0.9752\n",
            "Epoch 695/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0664 - val_accuracy: 0.9752\n",
            "Epoch 696/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.0744 - val_accuracy: 0.9752\n",
            "Epoch 697/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0409 - accuracy: 0.9847 - val_loss: 0.0534 - val_accuracy: 0.9752\n",
            "Epoch 698/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0393 - accuracy: 0.9862 - val_loss: 0.0513 - val_accuracy: 0.9783\n",
            "Epoch 699/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0675 - val_accuracy: 0.9752\n",
            "Epoch 700/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0391 - accuracy: 0.9832 - val_loss: 0.0705 - val_accuracy: 0.9752\n",
            "Epoch 701/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.0525 - val_accuracy: 0.9752\n",
            "Epoch 702/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0377 - accuracy: 0.9923 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
            "Epoch 703/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0435 - accuracy: 0.9832 - val_loss: 0.0578 - val_accuracy: 0.9752\n",
            "Epoch 704/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0653 - val_accuracy: 0.9752\n",
            "Epoch 705/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9752\n",
            "Epoch 706/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0487 - val_accuracy: 0.9752\n",
            "Epoch 707/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0376 - accuracy: 0.9847 - val_loss: 0.0604 - val_accuracy: 0.9720\n",
            "Epoch 708/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0392 - accuracy: 0.9862 - val_loss: 0.0633 - val_accuracy: 0.9752\n",
            "Epoch 709/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0384 - accuracy: 0.9877 - val_loss: 0.0501 - val_accuracy: 0.9783\n",
            "Epoch 710/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 0.0548 - val_accuracy: 0.9752\n",
            "Epoch 711/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0658 - val_accuracy: 0.9752\n",
            "Epoch 712/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0372 - accuracy: 0.9847 - val_loss: 0.0617 - val_accuracy: 0.9783\n",
            "Epoch 713/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0365 - accuracy: 0.9862 - val_loss: 0.0587 - val_accuracy: 0.9783\n",
            "Epoch 714/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 0.0635 - val_accuracy: 0.9783\n",
            "Epoch 715/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0359 - accuracy: 0.9862 - val_loss: 0.0607 - val_accuracy: 0.9783\n",
            "Epoch 716/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0350 - accuracy: 0.9877 - val_loss: 0.0541 - val_accuracy: 0.9783\n",
            "Epoch 717/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0365 - accuracy: 0.9908 - val_loss: 0.0541 - val_accuracy: 0.9752\n",
            "Epoch 718/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.0649 - val_accuracy: 0.9720\n",
            "Epoch 719/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0370 - accuracy: 0.9877 - val_loss: 0.0645 - val_accuracy: 0.9720\n",
            "Epoch 720/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0533 - val_accuracy: 0.9752\n",
            "Epoch 721/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0364 - accuracy: 0.9847 - val_loss: 0.0575 - val_accuracy: 0.9752\n",
            "Epoch 722/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0346 - accuracy: 0.9877 - val_loss: 0.0695 - val_accuracy: 0.9752\n",
            "Epoch 723/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 0.0570 - val_accuracy: 0.9752\n",
            "Epoch 724/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.0513 - val_accuracy: 0.9783\n",
            "Epoch 725/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 0.0649 - val_accuracy: 0.9752\n",
            "Epoch 726/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0379 - accuracy: 0.9847 - val_loss: 0.0604 - val_accuracy: 0.9752\n",
            "Epoch 727/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0485 - val_accuracy: 0.9814\n",
            "Epoch 728/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.0550 - val_accuracy: 0.9752\n",
            "Epoch 729/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.0815 - val_accuracy: 0.9720\n",
            "Epoch 730/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0443 - accuracy: 0.9816 - val_loss: 0.0687 - val_accuracy: 0.9752\n",
            "Epoch 731/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0370 - accuracy: 0.9862 - val_loss: 0.0527 - val_accuracy: 0.9783\n",
            "Epoch 732/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0364 - accuracy: 0.9939 - val_loss: 0.0559 - val_accuracy: 0.9752\n",
            "Epoch 733/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
            "Epoch 734/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
            "Epoch 735/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0556 - val_accuracy: 0.9752\n",
            "Epoch 736/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0348 - accuracy: 0.9939 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
            "Epoch 737/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.0665 - val_accuracy: 0.9752\n",
            "Epoch 738/1000\n",
            "653/653 [==============================] - 0s 9us/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 0.0599 - val_accuracy: 0.9720\n",
            "Epoch 739/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.0493 - val_accuracy: 0.9783\n",
            "Epoch 740/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0393 - accuracy: 0.9847 - val_loss: 0.0543 - val_accuracy: 0.9752\n",
            "Epoch 741/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0740 - val_accuracy: 0.9752\n",
            "Epoch 742/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0387 - accuracy: 0.9862 - val_loss: 0.0548 - val_accuracy: 0.9752\n",
            "Epoch 743/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.0478 - val_accuracy: 0.9814\n",
            "Epoch 744/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0434 - accuracy: 0.9832 - val_loss: 0.0565 - val_accuracy: 0.9752\n",
            "Epoch 745/1000\n",
            "653/653 [==============================] - 0s 27us/step - loss: 0.0372 - accuracy: 0.9862 - val_loss: 0.0698 - val_accuracy: 0.9752\n",
            "Epoch 746/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0365 - accuracy: 0.9862 - val_loss: 0.0549 - val_accuracy: 0.9752\n",
            "Epoch 747/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0552 - val_accuracy: 0.9752\n",
            "Epoch 748/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
            "Epoch 749/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0341 - accuracy: 0.9877 - val_loss: 0.0599 - val_accuracy: 0.9783\n",
            "Epoch 750/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0334 - accuracy: 0.9862 - val_loss: 0.0531 - val_accuracy: 0.9752\n",
            "Epoch 751/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 0.0514 - val_accuracy: 0.9752\n",
            "Epoch 752/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
            "Epoch 753/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0341 - accuracy: 0.9862 - val_loss: 0.0712 - val_accuracy: 0.9752\n",
            "Epoch 754/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0366 - accuracy: 0.9847 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
            "Epoch 755/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 0.0493 - val_accuracy: 0.9814\n",
            "Epoch 756/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0350 - accuracy: 0.9939 - val_loss: 0.0704 - val_accuracy: 0.9752\n",
            "Epoch 757/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.0657 - val_accuracy: 0.9752\n",
            "Epoch 758/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0472 - val_accuracy: 0.9814\n",
            "Epoch 759/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0379 - accuracy: 0.9893 - val_loss: 0.0479 - val_accuracy: 0.9783\n",
            "Epoch 760/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0331 - accuracy: 0.9877 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
            "Epoch 761/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0684 - val_accuracy: 0.9752\n",
            "Epoch 762/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 0.0499 - val_accuracy: 0.9783\n",
            "Epoch 763/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 0.0456 - val_accuracy: 0.9783\n",
            "Epoch 764/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0346 - accuracy: 0.9923 - val_loss: 0.0608 - val_accuracy: 0.9752\n",
            "Epoch 765/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.0784 - val_accuracy: 0.9752\n",
            "Epoch 766/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.0537 - val_accuracy: 0.9783\n",
            "Epoch 767/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0335 - accuracy: 0.9923 - val_loss: 0.0464 - val_accuracy: 0.9814\n",
            "Epoch 768/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 0.0619 - val_accuracy: 0.9752\n",
            "Epoch 769/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0377 - accuracy: 0.9847 - val_loss: 0.0680 - val_accuracy: 0.9752\n",
            "Epoch 770/1000\n",
            "653/653 [==============================] - 0s 22us/step - loss: 0.0347 - accuracy: 0.9862 - val_loss: 0.0463 - val_accuracy: 0.9783\n",
            "Epoch 771/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.0491 - val_accuracy: 0.9783\n",
            "Epoch 772/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0721 - val_accuracy: 0.9752\n",
            "Epoch 773/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0377 - accuracy: 0.9847 - val_loss: 0.0621 - val_accuracy: 0.9752\n",
            "Epoch 774/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 0.0456 - val_accuracy: 0.9814\n",
            "Epoch 775/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.0488 - val_accuracy: 0.9814\n",
            "Epoch 776/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.0314 - accuracy: 0.9923 - val_loss: 0.0676 - val_accuracy: 0.9752\n",
            "Epoch 777/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0360 - accuracy: 0.9847 - val_loss: 0.0614 - val_accuracy: 0.9752\n",
            "Epoch 778/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0346 - accuracy: 0.9877 - val_loss: 0.0475 - val_accuracy: 0.9783\n",
            "Epoch 779/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0501 - val_accuracy: 0.9783\n",
            "Epoch 780/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0319 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9783\n",
            "Epoch 781/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0545 - val_accuracy: 0.9783\n",
            "Epoch 782/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0538 - val_accuracy: 0.9783\n",
            "Epoch 783/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0471 - val_accuracy: 0.9783\n",
            "Epoch 784/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0489 - val_accuracy: 0.9814\n",
            "Epoch 785/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0309 - accuracy: 0.9939 - val_loss: 0.0575 - val_accuracy: 0.9783\n",
            "Epoch 786/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0629 - val_accuracy: 0.9752\n",
            "Epoch 787/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0333 - accuracy: 0.9877 - val_loss: 0.0558 - val_accuracy: 0.9783\n",
            "Epoch 788/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.0480 - val_accuracy: 0.9814\n",
            "Epoch 789/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0314 - accuracy: 0.9923 - val_loss: 0.0515 - val_accuracy: 0.9814\n",
            "Epoch 790/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0305 - accuracy: 0.9923 - val_loss: 0.0604 - val_accuracy: 0.9752\n",
            "Epoch 791/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.0522 - val_accuracy: 0.9814\n",
            "Epoch 792/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.0434 - val_accuracy: 0.9814\n",
            "Epoch 793/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0350 - accuracy: 0.9908 - val_loss: 0.0498 - val_accuracy: 0.9814\n",
            "Epoch 794/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0302 - accuracy: 0.9923 - val_loss: 0.0716 - val_accuracy: 0.9752\n",
            "Epoch 795/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0376 - accuracy: 0.9862 - val_loss: 0.0552 - val_accuracy: 0.9783\n",
            "Epoch 796/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0300 - accuracy: 0.9923 - val_loss: 0.0446 - val_accuracy: 0.9783\n",
            "Epoch 797/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 0.0541 - val_accuracy: 0.9814\n",
            "Epoch 798/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
            "Epoch 799/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0340 - accuracy: 0.9862 - val_loss: 0.0541 - val_accuracy: 0.9814\n",
            "Epoch 800/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 0.0497 - val_accuracy: 0.9783\n",
            "Epoch 801/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0312 - accuracy: 0.9939 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
            "Epoch 802/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0315 - accuracy: 0.9877 - val_loss: 0.0603 - val_accuracy: 0.9752\n",
            "Epoch 803/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0515 - val_accuracy: 0.9814\n",
            "Epoch 804/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0298 - accuracy: 0.9939 - val_loss: 0.0498 - val_accuracy: 0.9814\n",
            "Epoch 805/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0306 - accuracy: 0.9969 - val_loss: 0.0526 - val_accuracy: 0.9814\n",
            "Epoch 806/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.0579 - val_accuracy: 0.9783\n",
            "Epoch 807/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.0567 - val_accuracy: 0.9783\n",
            "Epoch 808/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0524 - val_accuracy: 0.9814\n",
            "Epoch 809/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0292 - accuracy: 0.9923 - val_loss: 0.0476 - val_accuracy: 0.9814\n",
            "Epoch 810/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0306 - accuracy: 0.9939 - val_loss: 0.0526 - val_accuracy: 0.9814\n",
            "Epoch 811/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0626 - val_accuracy: 0.9752\n",
            "Epoch 812/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0321 - accuracy: 0.9877 - val_loss: 0.0518 - val_accuracy: 0.9814\n",
            "Epoch 813/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0472 - val_accuracy: 0.9814\n",
            "Epoch 814/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0300 - accuracy: 0.9923 - val_loss: 0.0542 - val_accuracy: 0.9814\n",
            "Epoch 815/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0604 - val_accuracy: 0.9783\n",
            "Epoch 816/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
            "Epoch 817/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
            "Epoch 818/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0580 - val_accuracy: 0.9783\n",
            "Epoch 819/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.0543 - val_accuracy: 0.9814\n",
            "Epoch 820/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.0494 - val_accuracy: 0.9814\n",
            "Epoch 821/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.0499 - val_accuracy: 0.9814\n",
            "Epoch 822/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0294 - accuracy: 0.9969 - val_loss: 0.0565 - val_accuracy: 0.9814\n",
            "Epoch 823/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0593 - val_accuracy: 0.9783\n",
            "Epoch 824/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0506 - val_accuracy: 0.9814\n",
            "Epoch 825/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0294 - accuracy: 0.9939 - val_loss: 0.0502 - val_accuracy: 0.9814\n",
            "Epoch 826/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
            "Epoch 827/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0580 - val_accuracy: 0.9814\n",
            "Epoch 828/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0527 - val_accuracy: 0.9814\n",
            "Epoch 829/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0287 - accuracy: 0.9923 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
            "Epoch 830/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0299 - accuracy: 0.9969 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
            "Epoch 831/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0291 - accuracy: 0.9954 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
            "Epoch 832/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
            "Epoch 833/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0570 - val_accuracy: 0.9814\n",
            "Epoch 834/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0515 - val_accuracy: 0.9814\n",
            "Epoch 835/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.0480 - val_accuracy: 0.9814\n",
            "Epoch 836/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.0521 - val_accuracy: 0.9814\n",
            "Epoch 837/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0581 - val_accuracy: 0.9783\n",
            "Epoch 838/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.0553 - val_accuracy: 0.9814\n",
            "Epoch 839/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0505 - val_accuracy: 0.9814\n",
            "Epoch 840/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.0531 - val_accuracy: 0.9814\n",
            "Epoch 841/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
            "Epoch 842/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0524 - val_accuracy: 0.9814\n",
            "Epoch 843/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0281 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9814\n",
            "Epoch 844/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0575 - val_accuracy: 0.9814\n",
            "Epoch 845/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0480 - val_accuracy: 0.9814\n",
            "Epoch 846/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0472 - val_accuracy: 0.9783\n",
            "Epoch 847/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
            "Epoch 848/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
            "Epoch 849/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.0486 - val_accuracy: 0.9814\n",
            "Epoch 850/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0283 - accuracy: 0.9954 - val_loss: 0.0573 - val_accuracy: 0.9814\n",
            "Epoch 851/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0620 - val_accuracy: 0.9783\n",
            "Epoch 852/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0290 - accuracy: 0.9893 - val_loss: 0.0538 - val_accuracy: 0.9814\n",
            "Epoch 853/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.0490 - val_accuracy: 0.9845\n",
            "Epoch 854/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0300 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
            "Epoch 855/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0684 - val_accuracy: 0.9752\n",
            "Epoch 856/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0315 - accuracy: 0.9877 - val_loss: 0.0628 - val_accuracy: 0.9783\n",
            "Epoch 857/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.0501 - val_accuracy: 0.9814\n",
            "Epoch 858/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0539 - val_accuracy: 0.9814\n",
            "Epoch 859/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0665 - val_accuracy: 0.9783\n",
            "Epoch 860/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0555 - val_accuracy: 0.9814\n",
            "Epoch 861/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.0505 - val_accuracy: 0.9814\n",
            "Epoch 862/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0280 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9814\n",
            "Epoch 863/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0623 - val_accuracy: 0.9814\n",
            "Epoch 864/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0517 - val_accuracy: 0.9814\n",
            "Epoch 865/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0278 - accuracy: 0.9969 - val_loss: 0.0494 - val_accuracy: 0.9814\n",
            "Epoch 866/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0281 - accuracy: 0.9939 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
            "Epoch 867/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.0595 - val_accuracy: 0.9783\n",
            "Epoch 868/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0578 - val_accuracy: 0.9814\n",
            "Epoch 869/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
            "Epoch 870/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0278 - accuracy: 0.9969 - val_loss: 0.0490 - val_accuracy: 0.9845\n",
            "Epoch 871/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0291 - accuracy: 0.9969 - val_loss: 0.0570 - val_accuracy: 0.9814\n",
            "Epoch 872/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
            "Epoch 873/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0501 - val_accuracy: 0.9845\n",
            "Epoch 874/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0283 - accuracy: 0.9969 - val_loss: 0.0502 - val_accuracy: 0.9845\n",
            "Epoch 875/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0279 - accuracy: 0.9969 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
            "Epoch 876/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0268 - accuracy: 0.9939 - val_loss: 0.0604 - val_accuracy: 0.9814\n",
            "Epoch 877/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0277 - accuracy: 0.9893 - val_loss: 0.0549 - val_accuracy: 0.9814\n",
            "Epoch 878/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.0510 - val_accuracy: 0.9814\n",
            "Epoch 879/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.0577 - val_accuracy: 0.9814\n",
            "Epoch 880/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0554 - val_accuracy: 0.9814\n",
            "Epoch 881/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
            "Epoch 882/1000\n",
            "653/653 [==============================] - 0s 22us/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0580 - val_accuracy: 0.9814\n",
            "Epoch 883/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0556 - val_accuracy: 0.9814\n",
            "Epoch 884/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
            "Epoch 885/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0554 - val_accuracy: 0.9814\n",
            "Epoch 886/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0561 - val_accuracy: 0.9814\n",
            "Epoch 887/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0562 - val_accuracy: 0.9814\n",
            "Epoch 888/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0263 - accuracy: 0.9954 - val_loss: 0.0524 - val_accuracy: 0.9814\n",
            "Epoch 889/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0270 - accuracy: 0.9969 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
            "Epoch 890/1000\n",
            "653/653 [==============================] - 0s 20us/step - loss: 0.0265 - accuracy: 0.9954 - val_loss: 0.0626 - val_accuracy: 0.9783\n",
            "Epoch 891/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0521 - val_accuracy: 0.9814\n",
            "Epoch 892/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0270 - accuracy: 0.9969 - val_loss: 0.0454 - val_accuracy: 0.9814\n",
            "Epoch 893/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 0.0611 - val_accuracy: 0.9814\n",
            "Epoch 894/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0806 - val_accuracy: 0.9752\n",
            "Epoch 895/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0359 - accuracy: 0.9877 - val_loss: 0.0544 - val_accuracy: 0.9814\n",
            "Epoch 896/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.0450 - val_accuracy: 0.9814\n",
            "Epoch 897/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0613 - val_accuracy: 0.9814\n",
            "Epoch 898/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0302 - accuracy: 0.9862 - val_loss: 0.0860 - val_accuracy: 0.9720\n",
            "Epoch 899/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0404 - accuracy: 0.9801 - val_loss: 0.0511 - val_accuracy: 0.9814\n",
            "Epoch 900/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.0432 - val_accuracy: 0.9814\n",
            "Epoch 901/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
            "Epoch 902/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0705 - val_accuracy: 0.9783\n",
            "Epoch 903/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.0451 - val_accuracy: 0.9814\n",
            "Epoch 904/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0280 - accuracy: 0.9954 - val_loss: 0.0410 - val_accuracy: 0.9814\n",
            "Epoch 905/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0535 - val_accuracy: 0.9814\n",
            "Epoch 906/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0271 - accuracy: 0.9893 - val_loss: 0.0768 - val_accuracy: 0.9783\n",
            "Epoch 907/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
            "Epoch 908/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0436 - val_accuracy: 0.9814\n",
            "Epoch 909/1000\n",
            "653/653 [==============================] - 0s 18us/step - loss: 0.0330 - accuracy: 0.9923 - val_loss: 0.0526 - val_accuracy: 0.9814\n",
            "Epoch 910/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0268 - accuracy: 0.9954 - val_loss: 0.0742 - val_accuracy: 0.9752\n",
            "Epoch 911/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0323 - accuracy: 0.9862 - val_loss: 0.0606 - val_accuracy: 0.9814\n",
            "Epoch 912/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0492 - val_accuracy: 0.9845\n",
            "Epoch 913/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0274 - accuracy: 0.9954 - val_loss: 0.0533 - val_accuracy: 0.9814\n",
            "Epoch 914/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9783\n",
            "Epoch 915/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0677 - val_accuracy: 0.9783\n",
            "Epoch 916/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.0553 - val_accuracy: 0.9814\n",
            "Epoch 917/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0486 - val_accuracy: 0.9783\n",
            "Epoch 918/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0272 - accuracy: 0.9954 - val_loss: 0.0516 - val_accuracy: 0.9814\n",
            "Epoch 919/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.0634 - val_accuracy: 0.9783\n",
            "Epoch 920/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0553 - val_accuracy: 0.9814\n",
            "Epoch 921/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.0478 - val_accuracy: 0.9814\n",
            "Epoch 922/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0310 - accuracy: 0.9939 - val_loss: 0.0562 - val_accuracy: 0.9814\n",
            "Epoch 923/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0252 - accuracy: 0.9969 - val_loss: 0.0695 - val_accuracy: 0.9783\n",
            "Epoch 924/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.0563 - val_accuracy: 0.9814\n",
            "Epoch 925/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 0.0434 - val_accuracy: 0.9814\n",
            "Epoch 926/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0513 - val_accuracy: 0.9814\n",
            "Epoch 927/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0713 - val_accuracy: 0.9783\n",
            "Epoch 928/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 0.0545 - val_accuracy: 0.9814\n",
            "Epoch 929/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0450 - val_accuracy: 0.9814\n",
            "Epoch 930/1000\n",
            "653/653 [==============================] - 0s 17us/step - loss: 0.0288 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9814\n",
            "Epoch 931/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0256 - accuracy: 0.9954 - val_loss: 0.0641 - val_accuracy: 0.9783\n",
            "Epoch 932/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0273 - accuracy: 0.9893 - val_loss: 0.0571 - val_accuracy: 0.9814\n",
            "Epoch 933/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0474 - val_accuracy: 0.9845\n",
            "Epoch 934/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0277 - accuracy: 0.9954 - val_loss: 0.0544 - val_accuracy: 0.9814\n",
            "Epoch 935/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0253 - accuracy: 0.9954 - val_loss: 0.0698 - val_accuracy: 0.9783\n",
            "Epoch 936/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
            "Epoch 937/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0534 - val_accuracy: 0.9845\n",
            "Epoch 938/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0269 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
            "Epoch 939/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0705 - val_accuracy: 0.9814\n",
            "Epoch 940/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0590 - val_accuracy: 0.9814\n",
            "Epoch 941/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.0584 - val_accuracy: 0.9814\n",
            "Epoch 942/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.0640 - val_accuracy: 0.9783\n",
            "Epoch 943/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0574 - val_accuracy: 0.9814\n",
            "Epoch 944/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 0.0544 - val_accuracy: 0.9814\n",
            "Epoch 945/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9814\n",
            "Epoch 946/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.0549 - val_accuracy: 0.9814\n",
            "Epoch 947/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.0483 - val_accuracy: 0.9845\n",
            "Epoch 948/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0271 - accuracy: 0.9969 - val_loss: 0.0534 - val_accuracy: 0.9814\n",
            "Epoch 949/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0243 - accuracy: 0.9954 - val_loss: 0.0655 - val_accuracy: 0.9783\n",
            "Epoch 950/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0268 - accuracy: 0.9893 - val_loss: 0.0609 - val_accuracy: 0.9814\n",
            "Epoch 951/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0489 - val_accuracy: 0.9845\n",
            "Epoch 952/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0257 - accuracy: 0.9969 - val_loss: 0.0515 - val_accuracy: 0.9814\n",
            "Epoch 953/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0244 - accuracy: 0.9954 - val_loss: 0.0628 - val_accuracy: 0.9814\n",
            "Epoch 954/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0646 - val_accuracy: 0.9814\n",
            "Epoch 955/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0256 - accuracy: 0.9908 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
            "Epoch 956/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0242 - accuracy: 0.9969 - val_loss: 0.0492 - val_accuracy: 0.9845\n",
            "Epoch 957/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0269 - accuracy: 0.9954 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
            "Epoch 958/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9783\n",
            "Epoch 959/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.0612 - val_accuracy: 0.9814\n",
            "Epoch 960/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0540 - val_accuracy: 0.9814\n",
            "Epoch 961/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.0586 - val_accuracy: 0.9814\n",
            "Epoch 962/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0647 - val_accuracy: 0.9814\n",
            "Epoch 963/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0636 - val_accuracy: 0.9814\n",
            "Epoch 964/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0576 - val_accuracy: 0.9814\n",
            "Epoch 965/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0245 - accuracy: 0.9954 - val_loss: 0.0551 - val_accuracy: 0.9814\n",
            "Epoch 966/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.0610 - val_accuracy: 0.9814\n",
            "Epoch 967/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0599 - val_accuracy: 0.9814\n",
            "Epoch 968/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0499 - val_accuracy: 0.9814\n",
            "Epoch 969/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0257 - accuracy: 0.9969 - val_loss: 0.0485 - val_accuracy: 0.9814\n",
            "Epoch 970/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.0585 - val_accuracy: 0.9814\n",
            "Epoch 971/1000\n",
            "653/653 [==============================] - 0s 19us/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
            "Epoch 972/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0589 - val_accuracy: 0.9814\n",
            "Epoch 973/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0238 - accuracy: 0.9969 - val_loss: 0.0540 - val_accuracy: 0.9845\n",
            "Epoch 974/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0255 - accuracy: 0.9969 - val_loss: 0.0580 - val_accuracy: 0.9814\n",
            "Epoch 975/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0255 - accuracy: 0.9939 - val_loss: 0.0648 - val_accuracy: 0.9783\n",
            "Epoch 976/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0244 - accuracy: 0.9908 - val_loss: 0.0531 - val_accuracy: 0.9814\n",
            "Epoch 977/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0243 - accuracy: 0.9969 - val_loss: 0.0491 - val_accuracy: 0.9783\n",
            "Epoch 978/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0254 - accuracy: 0.9954 - val_loss: 0.0553 - val_accuracy: 0.9814\n",
            "Epoch 979/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 0.0632 - val_accuracy: 0.9814\n",
            "Epoch 980/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.0571 - val_accuracy: 0.9814\n",
            "Epoch 981/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0532 - val_accuracy: 0.9845\n",
            "Epoch 982/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.0605 - val_accuracy: 0.9814\n",
            "Epoch 983/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0239 - accuracy: 0.9969 - val_loss: 0.0631 - val_accuracy: 0.9814\n",
            "Epoch 984/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0240 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
            "Epoch 985/1000\n",
            "653/653 [==============================] - 0s 15us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
            "Epoch 986/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0241 - accuracy: 0.9969 - val_loss: 0.0678 - val_accuracy: 0.9783\n",
            "Epoch 987/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0650 - val_accuracy: 0.9814\n",
            "Epoch 988/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9814\n",
            "Epoch 989/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0240 - accuracy: 0.9969 - val_loss: 0.0609 - val_accuracy: 0.9814\n",
            "Epoch 990/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 0.0638 - val_accuracy: 0.9814\n",
            "Epoch 991/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0243 - accuracy: 0.9954 - val_loss: 0.0603 - val_accuracy: 0.9814\n",
            "Epoch 992/1000\n",
            "653/653 [==============================] - 0s 11us/step - loss: 0.0236 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9814\n",
            "Epoch 993/1000\n",
            "653/653 [==============================] - 0s 10us/step - loss: 0.0234 - accuracy: 0.9969 - val_loss: 0.0595 - val_accuracy: 0.9814\n",
            "Epoch 994/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 0.0626 - val_accuracy: 0.9814\n",
            "Epoch 995/1000\n",
            "653/653 [==============================] - 0s 16us/step - loss: 0.0238 - accuracy: 0.9969 - val_loss: 0.0645 - val_accuracy: 0.9814\n",
            "Epoch 996/1000\n",
            "653/653 [==============================] - 0s 13us/step - loss: 0.0235 - accuracy: 0.9969 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
            "Epoch 997/1000\n",
            "653/653 [==============================] - 0s 14us/step - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.0592 - val_accuracy: 0.9814\n",
            "Epoch 998/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0231 - accuracy: 0.9954 - val_loss: 0.0684 - val_accuracy: 0.9783\n",
            "Epoch 999/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.0605 - val_accuracy: 0.9814\n",
            "Epoch 1000/1000\n",
            "653/653 [==============================] - 0s 12us/step - loss: 0.0246 - accuracy: 0.9954 - val_loss: 0.0559 - val_accuracy: 0.9814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-017d98604779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0my_vloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0my_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mx_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1POlmPHEMoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78db8159-2436-4e5d-c028-df6be712d896"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n",
        "model.fit(X, Y, validation_split=0.33, epochs=2000, batch_size=500, callbacks=[early_stopping_callback])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4352 samples, validate on 2145 samples\n",
            "Epoch 1/2000\n",
            "4352/4352 [==============================] - 0s 7us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0617 - val_accuracy: 0.9925\n",
            "Epoch 2/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0603 - val_accuracy: 0.9911\n",
            "Epoch 3/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0605 - val_accuracy: 0.9916\n",
            "Epoch 4/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.0613 - val_accuracy: 0.9916\n",
            "Epoch 5/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0646 - val_accuracy: 0.9916\n",
            "Epoch 6/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0690 - val_accuracy: 0.9902\n",
            "Epoch 7/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0680 - val_accuracy: 0.9911\n",
            "Epoch 8/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0725 - val_accuracy: 0.9888\n",
            "Epoch 9/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0630 - val_accuracy: 0.9911\n",
            "Epoch 10/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.0590 - val_accuracy: 0.9911\n",
            "Epoch 11/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0606 - val_accuracy: 0.9916\n",
            "Epoch 12/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0627 - val_accuracy: 0.9925\n",
            "Epoch 13/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.0617 - val_accuracy: 0.9921\n",
            "Epoch 14/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0614 - val_accuracy: 0.9916\n",
            "Epoch 15/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0670 - val_accuracy: 0.9916\n",
            "Epoch 16/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0694 - val_accuracy: 0.9902\n",
            "Epoch 17/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0749 - val_accuracy: 0.9902\n",
            "Epoch 18/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0604 - val_accuracy: 0.9925\n",
            "Epoch 19/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9897\n",
            "Epoch 20/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0590 - val_accuracy: 0.9916\n",
            "Epoch 21/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0720 - val_accuracy: 0.9907\n",
            "Epoch 22/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0674 - val_accuracy: 0.9907\n",
            "Epoch 23/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.0697 - val_accuracy: 0.9907\n",
            "Epoch 24/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0660 - val_accuracy: 0.9907\n",
            "Epoch 25/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0624 - val_accuracy: 0.9921\n",
            "Epoch 26/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0609 - val_accuracy: 0.9921\n",
            "Epoch 27/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0619 - val_accuracy: 0.9916\n",
            "Epoch 28/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0628 - val_accuracy: 0.9907\n",
            "Epoch 29/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0184 - accuracy: 0.9931 - val_loss: 0.0612 - val_accuracy: 0.9907\n",
            "Epoch 30/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.0600 - val_accuracy: 0.9911\n",
            "Epoch 31/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0623 - val_accuracy: 0.9921\n",
            "Epoch 32/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.0704 - val_accuracy: 0.9911\n",
            "Epoch 33/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0708 - val_accuracy: 0.9897\n",
            "Epoch 34/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0636 - val_accuracy: 0.9911\n",
            "Epoch 35/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0629 - val_accuracy: 0.9916\n",
            "Epoch 36/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 0.0609 - val_accuracy: 0.9916\n",
            "Epoch 37/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0598 - val_accuracy: 0.9916\n",
            "Epoch 38/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0600 - val_accuracy: 0.9916\n",
            "Epoch 39/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0604 - val_accuracy: 0.9916\n",
            "Epoch 40/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0621 - val_accuracy: 0.9916\n",
            "Epoch 41/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0612 - val_accuracy: 0.9911\n",
            "Epoch 42/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0666 - val_accuracy: 0.9916\n",
            "Epoch 43/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0643 - val_accuracy: 0.9907\n",
            "Epoch 44/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0611 - val_accuracy: 0.9911\n",
            "Epoch 45/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0597 - val_accuracy: 0.9916\n",
            "Epoch 46/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.0602 - val_accuracy: 0.9921\n",
            "Epoch 47/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0610 - val_accuracy: 0.9911\n",
            "Epoch 48/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0170 - accuracy: 0.9933 - val_loss: 0.0642 - val_accuracy: 0.9916\n",
            "Epoch 49/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0433 - accuracy: 0.9883 - val_loss: 0.0719 - val_accuracy: 0.9911\n",
            "Epoch 50/2000\n",
            "4352/4352 [==============================] - 0s 7us/step - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.0929 - val_accuracy: 0.9869\n",
            "Epoch 51/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.0636 - val_accuracy: 0.9921\n",
            "Epoch 52/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0652 - val_accuracy: 0.9911\n",
            "Epoch 53/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.0756 - val_accuracy: 0.9893\n",
            "Epoch 54/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0671 - val_accuracy: 0.9911\n",
            "Epoch 55/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.0667 - val_accuracy: 0.9907\n",
            "Epoch 56/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0715 - val_accuracy: 0.9897\n",
            "Epoch 57/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0683 - val_accuracy: 0.9907\n",
            "Epoch 58/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0597 - val_accuracy: 0.9911\n",
            "Epoch 59/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0627 - val_accuracy: 0.9911\n",
            "Epoch 60/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0657 - val_accuracy: 0.9907\n",
            "Epoch 61/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.0612 - val_accuracy: 0.9916\n",
            "Epoch 62/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0610 - val_accuracy: 0.9916\n",
            "Epoch 63/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0629 - val_accuracy: 0.9916\n",
            "Epoch 64/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0614 - val_accuracy: 0.9916\n",
            "Epoch 65/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0625 - val_accuracy: 0.9916\n",
            "Epoch 66/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0604 - val_accuracy: 0.9911\n",
            "Epoch 67/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0602 - val_accuracy: 0.9916\n",
            "Epoch 68/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0648 - val_accuracy: 0.9916\n",
            "Epoch 69/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0660 - val_accuracy: 0.9907\n",
            "Epoch 70/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0615 - val_accuracy: 0.9911\n",
            "Epoch 71/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0657 - val_accuracy: 0.9902\n",
            "Epoch 72/2000\n",
            "4352/4352 [==============================] - 0s 7us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0612 - val_accuracy: 0.9916\n",
            "Epoch 73/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0641 - val_accuracy: 0.9911\n",
            "Epoch 74/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0612 - val_accuracy: 0.9911\n",
            "Epoch 75/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0620 - val_accuracy: 0.9916\n",
            "Epoch 76/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0678 - val_accuracy: 0.9907\n",
            "Epoch 77/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0617 - val_accuracy: 0.9921\n",
            "Epoch 78/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0607 - val_accuracy: 0.9916\n",
            "Epoch 79/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0625 - val_accuracy: 0.9916\n",
            "Epoch 80/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0627 - val_accuracy: 0.9907\n",
            "Epoch 81/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0597 - val_accuracy: 0.9921\n",
            "Epoch 82/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0609 - val_accuracy: 0.9916\n",
            "Epoch 83/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0638 - val_accuracy: 0.9916\n",
            "Epoch 84/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0622 - val_accuracy: 0.9911\n",
            "Epoch 85/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0635 - val_accuracy: 0.9921\n",
            "Epoch 86/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0834 - val_accuracy: 0.9893\n",
            "Epoch 87/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0747 - val_accuracy: 0.9897\n",
            "Epoch 88/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0650 - val_accuracy: 0.9907\n",
            "Epoch 89/2000\n",
            "4352/4352 [==============================] - 0s 7us/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0632 - val_accuracy: 0.9921\n",
            "Epoch 90/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0714 - val_accuracy: 0.9902\n",
            "Epoch 91/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0658 - val_accuracy: 0.9911\n",
            "Epoch 92/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0712 - val_accuracy: 0.9897\n",
            "Epoch 93/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0633 - val_accuracy: 0.9907\n",
            "Epoch 94/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0609 - val_accuracy: 0.9911\n",
            "Epoch 95/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.0642 - val_accuracy: 0.9916\n",
            "Epoch 96/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0688 - val_accuracy: 0.9902\n",
            "Epoch 97/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0124 - accuracy: 0.9945 - val_loss: 0.0751 - val_accuracy: 0.9897\n",
            "Epoch 98/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0613 - val_accuracy: 0.9911\n",
            "Epoch 99/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0716 - val_accuracy: 0.9893\n",
            "Epoch 100/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0769 - val_accuracy: 0.9897\n",
            "Epoch 101/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0157 - accuracy: 0.9936 - val_loss: 0.0757 - val_accuracy: 0.9893\n",
            "Epoch 102/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0717 - val_accuracy: 0.9907\n",
            "Epoch 103/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0592 - val_accuracy: 0.9921\n",
            "Epoch 104/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0690 - val_accuracy: 0.9907\n",
            "Epoch 105/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0650 - val_accuracy: 0.9916\n",
            "Epoch 106/2000\n",
            "4352/4352 [==============================] - 0s 6us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0651 - val_accuracy: 0.9911\n",
            "Epoch 107/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0663 - val_accuracy: 0.9911\n",
            "Epoch 108/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0658 - val_accuracy: 0.9916\n",
            "Epoch 109/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0623 - val_accuracy: 0.9911\n",
            "Epoch 110/2000\n",
            "4352/4352 [==============================] - 0s 5us/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0623 - val_accuracy: 0.9916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f451c4495c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Cwx1L-E3i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials \n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1QZecsECqfJO4dXD0rTYAu6GB35aop1fn'\n",
        "downloaded4 = drive.CreateFile({'id': file_id})\n",
        "downloaded4.GetContentFile('housing.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWVnairoFLSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6f6fea7c-2401-4e57-ffd7-02d18a2adfea"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('housing.csv', delim_whitespace=True, header=None)\n",
        "df.info"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of           0     1      2   3      4   ...     9     10      11    12    13\n",
              "0    0.00632  18.0   2.31   0  0.538  ...  296.0  15.3  396.90  4.98  24.0\n",
              "1    0.02731   0.0   7.07   0  0.469  ...  242.0  17.8  396.90  9.14  21.6\n",
              "2    0.02729   0.0   7.07   0  0.469  ...  242.0  17.8  392.83  4.03  34.7\n",
              "3    0.03237   0.0   2.18   0  0.458  ...  222.0  18.7  394.63  2.94  33.4\n",
              "4    0.06905   0.0   2.18   0  0.458  ...  222.0  18.7  396.90  5.33  36.2\n",
              "..       ...   ...    ...  ..    ...  ...    ...   ...     ...   ...   ...\n",
              "501  0.06263   0.0  11.93   0  0.573  ...  273.0  21.0  391.99  9.67  22.4\n",
              "502  0.04527   0.0  11.93   0  0.573  ...  273.0  21.0  396.90  9.08  20.6\n",
              "503  0.06076   0.0  11.93   0  0.573  ...  273.0  21.0  396.90  5.64  23.9\n",
              "504  0.10959   0.0  11.93   0  0.573  ...  273.0  21.0  393.45  6.48  22.0\n",
              "505  0.04741   0.0  11.93   0  0.573  ...  273.0  21.0  396.90  7.88  11.9\n",
              "\n",
              "[506 rows x 14 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et2FYLc4FznR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ba0081f6-7b37-485c-8b3e-a1d9ac573508"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1     2   3      4      5   ...  8      9     10      11    12    13\n",
              "0  0.00632  18.0  2.31   0  0.538  6.575  ...   1  296.0  15.3  396.90  4.98  24.0\n",
              "1  0.02731   0.0  7.07   0  0.469  6.421  ...   2  242.0  17.8  396.90  9.14  21.6\n",
              "2  0.02729   0.0  7.07   0  0.469  7.185  ...   2  242.0  17.8  392.83  4.03  34.7\n",
              "3  0.03237   0.0  2.18   0  0.458  6.998  ...   3  222.0  18.7  394.63  2.94  33.4\n",
              "4  0.06905   0.0  2.18   0  0.458  7.147  ...   3  222.0  18.7  396.90  5.33  36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y52HxkaLHh5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "573fac4e-bf20-4518-cf0b-e41d75097593"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "df = pd.read_csv('housing.csv', delim_whitespace=True, header=None)\n",
        "\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:13]\n",
        "Y = dataset[:, 13]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=13, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
        "\n",
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(10):\n",
        "  label = Y_test[i]\n",
        "  prediction = Y_prediction[i]\n",
        "  print('real:{} predict:{}'.format(label, prediction))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "354/354 [==============================] - 0s 319us/step - loss: 1759.5766\n",
            "Epoch 2/200\n",
            "354/354 [==============================] - 0s 128us/step - loss: 196.6716\n",
            "Epoch 3/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 112.8408\n",
            "Epoch 4/200\n",
            "354/354 [==============================] - 0s 114us/step - loss: 82.3305\n",
            "Epoch 5/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 68.2427\n",
            "Epoch 6/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 63.4756\n",
            "Epoch 7/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 58.5064\n",
            "Epoch 8/200\n",
            "354/354 [==============================] - 0s 106us/step - loss: 57.7649\n",
            "Epoch 9/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 55.5968\n",
            "Epoch 10/200\n",
            "354/354 [==============================] - 0s 107us/step - loss: 54.5430\n",
            "Epoch 11/200\n",
            "354/354 [==============================] - 0s 116us/step - loss: 52.7896\n",
            "Epoch 12/200\n",
            "354/354 [==============================] - 0s 131us/step - loss: 52.5839\n",
            "Epoch 13/200\n",
            "354/354 [==============================] - 0s 119us/step - loss: 54.4343\n",
            "Epoch 14/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 51.3785\n",
            "Epoch 15/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 51.9678\n",
            "Epoch 16/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 49.3309\n",
            "Epoch 17/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 50.4372\n",
            "Epoch 18/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 50.7146\n",
            "Epoch 19/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 48.7756\n",
            "Epoch 20/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 47.5552\n",
            "Epoch 21/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 46.2478\n",
            "Epoch 22/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 46.2695\n",
            "Epoch 23/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 45.9187\n",
            "Epoch 24/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 46.4650\n",
            "Epoch 25/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 44.9308\n",
            "Epoch 26/200\n",
            "354/354 [==============================] - 0s 126us/step - loss: 44.0750\n",
            "Epoch 27/200\n",
            "354/354 [==============================] - 0s 107us/step - loss: 42.4796\n",
            "Epoch 28/200\n",
            "354/354 [==============================] - 0s 107us/step - loss: 42.5331\n",
            "Epoch 29/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 41.3316\n",
            "Epoch 30/200\n",
            "354/354 [==============================] - 0s 107us/step - loss: 40.6216\n",
            "Epoch 31/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 40.9501\n",
            "Epoch 32/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 41.9817\n",
            "Epoch 33/200\n",
            "354/354 [==============================] - 0s 106us/step - loss: 39.7245\n",
            "Epoch 34/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 43.3018\n",
            "Epoch 35/200\n",
            "354/354 [==============================] - 0s 107us/step - loss: 39.2155\n",
            "Epoch 36/200\n",
            "354/354 [==============================] - 0s 131us/step - loss: 38.8788\n",
            "Epoch 37/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 38.4574\n",
            "Epoch 38/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 41.4686\n",
            "Epoch 39/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 39.9019\n",
            "Epoch 40/200\n",
            "354/354 [==============================] - 0s 129us/step - loss: 38.5073\n",
            "Epoch 41/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 42.5870\n",
            "Epoch 42/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 37.8904\n",
            "Epoch 43/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 36.7594\n",
            "Epoch 44/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 36.4515\n",
            "Epoch 45/200\n",
            "354/354 [==============================] - 0s 118us/step - loss: 37.2414\n",
            "Epoch 46/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 37.7773\n",
            "Epoch 47/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 37.9296\n",
            "Epoch 48/200\n",
            "354/354 [==============================] - 0s 126us/step - loss: 36.6236\n",
            "Epoch 49/200\n",
            "354/354 [==============================] - 0s 120us/step - loss: 38.0994\n",
            "Epoch 50/200\n",
            "354/354 [==============================] - 0s 142us/step - loss: 35.3259\n",
            "Epoch 51/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 34.1671\n",
            "Epoch 52/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 35.3483\n",
            "Epoch 53/200\n",
            "354/354 [==============================] - 0s 135us/step - loss: 38.7464\n",
            "Epoch 54/200\n",
            "354/354 [==============================] - 0s 132us/step - loss: 34.2988\n",
            "Epoch 55/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 38.6103\n",
            "Epoch 56/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 34.1617\n",
            "Epoch 57/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 35.5550\n",
            "Epoch 58/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 37.3202\n",
            "Epoch 59/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 34.5034\n",
            "Epoch 60/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 34.5058\n",
            "Epoch 61/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 32.6464\n",
            "Epoch 62/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 34.9781\n",
            "Epoch 63/200\n",
            "354/354 [==============================] - 0s 126us/step - loss: 34.7009\n",
            "Epoch 64/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 32.9441\n",
            "Epoch 65/200\n",
            "354/354 [==============================] - 0s 106us/step - loss: 32.9321\n",
            "Epoch 66/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 32.0000\n",
            "Epoch 67/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 33.5843\n",
            "Epoch 68/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 33.5214\n",
            "Epoch 69/200\n",
            "354/354 [==============================] - 0s 118us/step - loss: 32.2870\n",
            "Epoch 70/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 32.2566\n",
            "Epoch 71/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 32.7075\n",
            "Epoch 72/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 32.4615\n",
            "Epoch 73/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 32.6771\n",
            "Epoch 74/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 34.3542\n",
            "Epoch 75/200\n",
            "354/354 [==============================] - 0s 106us/step - loss: 32.6213\n",
            "Epoch 76/200\n",
            "354/354 [==============================] - 0s 106us/step - loss: 29.6470\n",
            "Epoch 77/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 32.2194\n",
            "Epoch 78/200\n",
            "354/354 [==============================] - 0s 103us/step - loss: 30.8480\n",
            "Epoch 79/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 32.4689\n",
            "Epoch 80/200\n",
            "354/354 [==============================] - 0s 108us/step - loss: 33.9143\n",
            "Epoch 81/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 34.8514\n",
            "Epoch 82/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 29.9950\n",
            "Epoch 83/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 31.5018\n",
            "Epoch 84/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 31.6339\n",
            "Epoch 85/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 30.9406\n",
            "Epoch 86/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 30.7206\n",
            "Epoch 87/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 30.5441\n",
            "Epoch 88/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 32.6907\n",
            "Epoch 89/200\n",
            "354/354 [==============================] - 0s 116us/step - loss: 30.6144\n",
            "Epoch 90/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 29.6248\n",
            "Epoch 91/200\n",
            "354/354 [==============================] - 0s 108us/step - loss: 30.1984\n",
            "Epoch 92/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 29.8274\n",
            "Epoch 93/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 32.6720\n",
            "Epoch 94/200\n",
            "354/354 [==============================] - 0s 119us/step - loss: 32.4285\n",
            "Epoch 95/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 31.0053\n",
            "Epoch 96/200\n",
            "354/354 [==============================] - 0s 116us/step - loss: 29.8369\n",
            "Epoch 97/200\n",
            "354/354 [==============================] - 0s 134us/step - loss: 31.9885\n",
            "Epoch 98/200\n",
            "354/354 [==============================] - 0s 119us/step - loss: 31.4182\n",
            "Epoch 99/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 32.2081\n",
            "Epoch 100/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 28.6014\n",
            "Epoch 101/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 38.1192\n",
            "Epoch 102/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 32.1686\n",
            "Epoch 103/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 31.6725\n",
            "Epoch 104/200\n",
            "354/354 [==============================] - 0s 119us/step - loss: 30.4924\n",
            "Epoch 105/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 31.1621\n",
            "Epoch 106/200\n",
            "354/354 [==============================] - 0s 118us/step - loss: 30.2630\n",
            "Epoch 107/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 30.0026\n",
            "Epoch 108/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 29.0339\n",
            "Epoch 109/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 30.6541\n",
            "Epoch 110/200\n",
            "354/354 [==============================] - 0s 128us/step - loss: 29.8044\n",
            "Epoch 111/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 28.4312\n",
            "Epoch 112/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 28.5303\n",
            "Epoch 113/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 28.5461\n",
            "Epoch 114/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 28.4670\n",
            "Epoch 115/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 29.8138\n",
            "Epoch 116/200\n",
            "354/354 [==============================] - 0s 108us/step - loss: 33.7340\n",
            "Epoch 117/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 36.9008\n",
            "Epoch 118/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 29.0495\n",
            "Epoch 119/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 29.8967\n",
            "Epoch 120/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 29.3578\n",
            "Epoch 121/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 28.7770\n",
            "Epoch 122/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 27.9795\n",
            "Epoch 123/200\n",
            "354/354 [==============================] - 0s 106us/step - loss: 28.7567\n",
            "Epoch 124/200\n",
            "354/354 [==============================] - 0s 114us/step - loss: 33.1671\n",
            "Epoch 125/200\n",
            "354/354 [==============================] - 0s 107us/step - loss: 30.8999\n",
            "Epoch 126/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 30.5343\n",
            "Epoch 127/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 29.4227\n",
            "Epoch 128/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 28.4891\n",
            "Epoch 129/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 28.2392\n",
            "Epoch 130/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 27.9144\n",
            "Epoch 131/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 27.5609\n",
            "Epoch 132/200\n",
            "354/354 [==============================] - 0s 126us/step - loss: 27.7005\n",
            "Epoch 133/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 25.9258\n",
            "Epoch 134/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 32.2150\n",
            "Epoch 135/200\n",
            "354/354 [==============================] - 0s 114us/step - loss: 26.7096\n",
            "Epoch 136/200\n",
            "354/354 [==============================] - 0s 130us/step - loss: 28.1535\n",
            "Epoch 137/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 27.7086\n",
            "Epoch 138/200\n",
            "354/354 [==============================] - 0s 128us/step - loss: 27.3767\n",
            "Epoch 139/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 33.4887\n",
            "Epoch 140/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 26.6283\n",
            "Epoch 141/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 28.7192\n",
            "Epoch 142/200\n",
            "354/354 [==============================] - 0s 119us/step - loss: 29.3587\n",
            "Epoch 143/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 28.7467\n",
            "Epoch 144/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 27.7674\n",
            "Epoch 145/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 27.5321\n",
            "Epoch 146/200\n",
            "354/354 [==============================] - 0s 108us/step - loss: 27.1139\n",
            "Epoch 147/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 26.3979\n",
            "Epoch 148/200\n",
            "354/354 [==============================] - 0s 133us/step - loss: 29.1787\n",
            "Epoch 149/200\n",
            "354/354 [==============================] - 0s 120us/step - loss: 28.6466\n",
            "Epoch 150/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 29.4405\n",
            "Epoch 151/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 26.6880\n",
            "Epoch 152/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 27.5838\n",
            "Epoch 153/200\n",
            "354/354 [==============================] - 0s 118us/step - loss: 27.4460\n",
            "Epoch 154/200\n",
            "354/354 [==============================] - 0s 130us/step - loss: 28.6456\n",
            "Epoch 155/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 27.6550\n",
            "Epoch 156/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 26.5137\n",
            "Epoch 157/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 30.0056\n",
            "Epoch 158/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 25.8331\n",
            "Epoch 159/200\n",
            "354/354 [==============================] - 0s 135us/step - loss: 27.2398\n",
            "Epoch 160/200\n",
            "354/354 [==============================] - 0s 132us/step - loss: 26.6489\n",
            "Epoch 161/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 27.1012\n",
            "Epoch 162/200\n",
            "354/354 [==============================] - 0s 113us/step - loss: 25.6735\n",
            "Epoch 163/200\n",
            "354/354 [==============================] - 0s 108us/step - loss: 27.0559\n",
            "Epoch 164/200\n",
            "354/354 [==============================] - 0s 108us/step - loss: 29.4801\n",
            "Epoch 165/200\n",
            "354/354 [==============================] - 0s 128us/step - loss: 28.3897\n",
            "Epoch 166/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 26.5482\n",
            "Epoch 167/200\n",
            "354/354 [==============================] - 0s 137us/step - loss: 25.6844\n",
            "Epoch 168/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 24.8819\n",
            "Epoch 169/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 28.5867\n",
            "Epoch 170/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 26.2133\n",
            "Epoch 171/200\n",
            "354/354 [==============================] - 0s 117us/step - loss: 30.0863\n",
            "Epoch 172/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 26.4651\n",
            "Epoch 173/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 24.5601\n",
            "Epoch 174/200\n",
            "354/354 [==============================] - 0s 126us/step - loss: 24.9575\n",
            "Epoch 175/200\n",
            "354/354 [==============================] - 0s 123us/step - loss: 25.9704\n",
            "Epoch 176/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 25.3646\n",
            "Epoch 177/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 27.8126\n",
            "Epoch 178/200\n",
            "354/354 [==============================] - 0s 124us/step - loss: 26.0052\n",
            "Epoch 179/200\n",
            "354/354 [==============================] - 0s 122us/step - loss: 27.3448\n",
            "Epoch 180/200\n",
            "354/354 [==============================] - 0s 110us/step - loss: 24.0776\n",
            "Epoch 181/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 27.2214\n",
            "Epoch 182/200\n",
            "354/354 [==============================] - 0s 121us/step - loss: 26.3330\n",
            "Epoch 183/200\n",
            "354/354 [==============================] - 0s 134us/step - loss: 26.3403\n",
            "Epoch 184/200\n",
            "354/354 [==============================] - 0s 114us/step - loss: 23.3557\n",
            "Epoch 185/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 24.6095\n",
            "Epoch 186/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 24.8990\n",
            "Epoch 187/200\n",
            "354/354 [==============================] - 0s 111us/step - loss: 24.4862\n",
            "Epoch 188/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 23.8790\n",
            "Epoch 189/200\n",
            "354/354 [==============================] - 0s 115us/step - loss: 23.6779\n",
            "Epoch 190/200\n",
            "354/354 [==============================] - 0s 127us/step - loss: 23.7315\n",
            "Epoch 191/200\n",
            "354/354 [==============================] - 0s 112us/step - loss: 23.0054\n",
            "Epoch 192/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 22.7218\n",
            "Epoch 193/200\n",
            "354/354 [==============================] - 0s 109us/step - loss: 26.6941\n",
            "Epoch 194/200\n",
            "354/354 [==============================] - 0s 118us/step - loss: 23.3222\n",
            "Epoch 195/200\n",
            "354/354 [==============================] - 0s 125us/step - loss: 24.3254\n",
            "Epoch 196/200\n",
            "354/354 [==============================] - 0s 119us/step - loss: 24.3382\n",
            "Epoch 197/200\n",
            "354/354 [==============================] - 0s 118us/step - loss: 25.4537\n",
            "Epoch 198/200\n",
            "354/354 [==============================] - 0s 126us/step - loss: 23.3702\n",
            "Epoch 199/200\n",
            "354/354 [==============================] - 0s 170us/step - loss: 23.4804\n",
            "Epoch 200/200\n",
            "354/354 [==============================] - 0s 103us/step - loss: 24.6306\n",
            "real:22.6 predict:20.311603546142578\n",
            "real:50.0 predict:24.329912185668945\n",
            "real:23.0 predict:28.120046615600586\n",
            "real:8.3 predict:13.431601524353027\n",
            "real:21.2 predict:22.351591110229492\n",
            "real:19.9 predict:23.256540298461914\n",
            "real:20.6 predict:20.132537841796875\n",
            "real:18.7 predict:26.374279022216797\n",
            "real:16.1 predict:18.521041870117188\n",
            "real:18.6 predict:11.229254722595215\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}