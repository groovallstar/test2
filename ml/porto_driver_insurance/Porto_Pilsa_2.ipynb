{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Porto Pilsa 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/groovallstar/test2/blob/master/Porto_Pilsa_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD8zsj8W1l-h",
        "colab_type": "text"
      },
      "source": [
        "- 경진대회: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction\n",
        "- 원본 커널: https://www.kaggle.com/aharless/xgboost-cv-lb-284  \n",
        "- 원본 저자: https://www.kaggle.com/aharless\n",
        "- 참고: https://kaggle-kr.tistory.com/32 (이유한님의 캐글 필사 커리큘럼입니다.)  \n",
        "- 번역: 홍정호(https://blog.naver.com/h0609zxc, KQNG), 번역 오류가 있다면 언제든지 말씀해주세요\n",
        "- 필사 날짜: 2019-07-12\n",
        "\n",
        "훌륭한 커널을 만들어주신 Andy Harless, 이런 커널들을 정리해주신 이유한님께 감사드립니다.  \n",
        "\n",
        "임의로 가독성을 위해 글의 열, 링크 등은 본문과 조금씩 다릅니다!   \n",
        "번역을 하면서 저도 모르는 부분이 존재하기 때문에 명쾌하지 않은 부분은 찾으면서 보시면 더 좋을것 같습니다.  \n",
        "모두 화이팅입니다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZdUBo3r1-Tr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ba6ea49-c483-4c24-fdd9-f22d6f77b8db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJTmRGcK2F4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "69713999-388b-490a-f722-0d253747f826"
      },
      "source": [
        "!ls \"/gdrive/My Drive/COLAB/PortoSafeDriverPrediction/\"\n",
        "DATA_PATH = \"/gdrive/My Drive/COLAB/PortoSafeDriverPrediction/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Porto Pilsa 1.ipynb'   sample_submission.csv   train.csv\n",
            "'Porto Pilsa 2.ipynb'   test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKVrpqsl2Q1J",
        "colab_type": "text"
      },
      "source": [
        "**이 커널은 olivier님의 커널을 기반으로 만들었습니다.**  \n",
        "olivier님의 커널: https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZVzrBgO2qIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_ROUNDS = 400\n",
        "OPTIMIZE_ROUNDS = False\n",
        "LEARNING_RATE = 0.07\n",
        "EARLY_STOPPING_ROUNDS = 50  \n",
        "\n",
        "# 나는 스스로 판단할 수 있는 많은 정보를 얻기 위해 EARLY_STOPPING_ROUNDS를 높게 설정합니다.(OPTIMIZE_ROUNDS가 설정된 경우)\n",
        "# 만약 실제로 조기 종료를 원한다면 EARLY_STOPPING_ROUNDS를 줄여야합니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUxocEWw3qib",
        "colab_type": "text"
      },
      "source": [
        "처음에는 MAX_ROUNDS를 상당히 높게 설정하고 OPTIMIZE_ROUNDS를 사용하여 적당한 라운드 수를 찾는것을 추천합니다.  \n",
        "(제 판단에는,  모든 폴드 사이에서 best_ntree_limit의 최댓값에 가깝게 해야합니다. 모델이 적절히 정규화 되었거나   \n",
        "verbose=True를 설정하고,  모든 폴드에서 잘 동작하는 라운드 수를 찾기 위한 세부 정보를 본다면 더 높을 수도 있습니다.)  \n",
        "그 다음 OPTIMIZE_ROUNDS를 중지하고, MAX_ROUND를 적절한 총 라운드 수로 설정하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjgTKnvrDOft",
        "colab_type": "text"
      },
      "source": [
        "각 폴드마다 최적의 라운드를 선택하는 \"조기 종료\" 방식은 검증 데이터에 과적합하는 문제가 존재합니다.  \n",
        "따라서 테스트 데이터를 예측하기 위한 최적의 모델을 생성하지 못할 수 있고,   \n",
        "다른 모델과 스태킹/앙상블을 위해 검증 데이터를 생성하는 경우 앙상블에 너무 많은 weight를 갖게 할 것입니다.  \n",
        "또 다른 문제점은(XGBoost의 기본 값은) 가장 좋은 라운드보다 조기 종료가 발생한 라운드(개선되지 않고 정체되있는 라운드)를 사용하는 것입니다.    \n",
        "정체되는 구간이 충분히 길다는 가정이 있다면 이것은 과적합 문제를 해결해줍니다. 그러나 지금까지는 도움이 되지 않았습니다.  \n",
        "(모든 폴드에 대해 일정한 라운드로 진행한것보다 폴드 당 20라운드 조기 종료를 한 것이 검증 점수가 안좋았다.  그래서 조기 종료는 실제로는 underfit 처럼 보였다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l46V_wUWxvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numba import jit\n",
        "import time\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqmuvZObePqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## gini 계산\n",
        "## 참고한 링크: https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
        "\n",
        "@jit\n",
        "def eval_gini(y_true, y_prob):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    ntrue = 0\n",
        "    gini = 0\n",
        "    delta = 0\n",
        "    n = len(y_true)\n",
        "    for i in range(n-1, -1, -1):\n",
        "        y_i = y_true[i]\n",
        "        ntrue += y_i\n",
        "        gini += y_i * delta\n",
        "        delta += 1 - y_i\n",
        "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
        "    return gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfoBl_DHlWSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 함수는 olivier 커널에서 가져왔습니다.\n",
        "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
        "\n",
        "def gini_xgb(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    gini_score = -eval_gini(labels, preds)\n",
        "    return [('gini', gini_score)]\n",
        "\n",
        "\n",
        "def add_noise(series, noise_level):\n",
        "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
        "  \n",
        "def target_encode(trn_series=None,  \n",
        "                  val_series=None,\n",
        "                  tst_series=None,\n",
        "                  target=None,\n",
        "                  min_samples_leaf=1,\n",
        "                  smoothing=1,\n",
        "                  noise_level=0):\n",
        "    \"\"\"\n",
        "    Smoothing은 Daniele Micci-Barreca의 논문에서와 같이 계산됩니다.\n",
        "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
        "    trn_series : pd.Series 형태의 학습할 범주형 피처\n",
        "    tst_series : pd.Series 형태의 테스트할 범주형 피처\n",
        "    target : pd.Series 형태의 타겟 데이터\n",
        "    min_samples_leaf (int) : 범주의 평균을 고려할 최소 샘플\n",
        "    smoothing (int) : 범주 평균과 이전의 균형을 맞추기 위한 스무딩 효과 \n",
        "    \"\"\" \n",
        "    assert len(trn_series) == len(target)\n",
        "    assert trn_series.name == tst_series.name\n",
        "    temp = pd.concat([trn_series, target], axis=1)\n",
        "    # Compute target mean\n",
        "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
        "    # Compute smoothing\n",
        "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
        "    # Apply average function to all target data\n",
        "    prior = target.mean()\n",
        "    # The bigger the count the less full_avg is taken into account\n",
        "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
        "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
        "    # Apply averages to trn and tst series\n",
        "    ft_trn_series = pd.merge(\n",
        "        trn_series.to_frame(trn_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=trn_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_trn_series.index = trn_series.index\n",
        "    ft_val_series = pd.merge(\n",
        "        val_series.to_frame(val_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=val_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_val_series.index = val_series.index\n",
        "    ft_tst_series = pd.merge(\n",
        "        tst_series.to_frame(tst_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=tst_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_tst_series.index = tst_series.index\n",
        "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wFAJ29bmVji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 읽기\n",
        "train_df = pd.read_csv(DATA_PATH + \"train.csv\", na_values=\"-1\")\n",
        "test_df = pd.read_csv(DATA_PATH + \"test.csv\", na_values=\"-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ih8kG6o4l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# olivier 커널 참고\n",
        "train_features = [\n",
        "  \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
        "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
        "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
        "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
        "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
        "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
        "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
        "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
        "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
        "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
        "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
        "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
        "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
        "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
        "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
        "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
        "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
        "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
        "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
        "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
        "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
        "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
        "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
        "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
        "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
        "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
        "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
        "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
        "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
        "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
        "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
        "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
        "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
        "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
        "]\n",
        "# 조합 추가\n",
        "combs = [\n",
        "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
        "    ('ps_reg_01', 'ps_car_04_cat'),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMnTfYjprY-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e142a76b-6bd0-4d82-b75e-ee84046a9013"
      },
      "source": [
        "# 데이터 처리\n",
        "id_test = test_df['id'].values\n",
        "id_train = train_df['id'].values\n",
        "y = train_df['target']\n",
        "\n",
        "start = time.time()\n",
        "for n_c, (f1, f2) in enumerate(combs):\n",
        "    name1 = f1 + \"_plus_\" + f2\n",
        "    print('current feature %60s %4d in %5.1f'\n",
        "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
        "    print('\\r' * 75, end='')\n",
        "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
        "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
        "    # Label Encode\n",
        "    lbl = LabelEncoder()\n",
        "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
        "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
        "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
        "\n",
        "    train_features.append(name1)\n",
        "    \n",
        "X = train_df[train_features]\n",
        "test_df = test_df[train_features]\n",
        "\n",
        "f_cats = [f for f in X.columns if \"_cat\" in f]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yo7oLRRs5JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_valid_pred = 0*y\n",
        "y_test_pred = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37KYEgJBtI_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 폴드 설정\n",
        "K = 5\n",
        "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4PT0WK7tKF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 분류기 설정\n",
        "model = XGBClassifier(    \n",
        "                        n_estimators=MAX_ROUNDS,\n",
        "                        max_depth=4,\n",
        "                        objective=\"binary:logistic\",\n",
        "                        learning_rate=LEARNING_RATE, \n",
        "                        subsample=.8,\n",
        "                        min_child_weight=6,\n",
        "                        colsample_bytree=.8,\n",
        "                        scale_pos_weight=1.6,\n",
        "                        gamma=10,\n",
        "                        reg_alpha=8,\n",
        "                        reg_lambda=1.3,\n",
        "                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEwwY0GMtU-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "d599c291-3f12-4e58-9c44-844766d92c8d"
      },
      "source": [
        "# CV 실행\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
        "    \n",
        "    # 폴드에 대한 데이터 생성\n",
        "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
        "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
        "    X_test = test_df.copy()\n",
        "    print( \"\\nFold \", i)\n",
        "    \n",
        "    # 데이터 인코드\n",
        "    for f in f_cats:\n",
        "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
        "                                                        trn_series=X_train[f],\n",
        "                                                        val_series=X_valid[f],\n",
        "                                                        tst_series=X_test[f],\n",
        "                                                        target=y_train,\n",
        "                                                        min_samples_leaf=200,\n",
        "                                                        smoothing=10,\n",
        "                                                        noise_level=0\n",
        "                                                        )\n",
        "    # 폴드에 대한 모델 실행\n",
        "    if OPTIMIZE_ROUNDS:\n",
        "        eval_set=[(X_valid,y_valid)]\n",
        "        fit_model = model.fit( X_train, y_train, \n",
        "                               eval_set=eval_set,\n",
        "                               eval_metric=gini_xgb,\n",
        "                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "                               verbose=False\n",
        "                             )\n",
        "        print( \"  Best N trees = \", model.best_ntree_limit )\n",
        "        print( \"  Best gini = \", model.best_score )\n",
        "    else:\n",
        "        fit_model = model.fit( X_train, y_train )\n",
        "        \n",
        "    # 폴드에 대한 검증 예측 생성\n",
        "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
        "    print( \"  Gini = \", eval_gini(y_valid, pred) )\n",
        "    y_valid_pred.iloc[test_index] = pred\n",
        "    \n",
        "    # 테스트 세트의 예측을 누적\n",
        "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
        "    \n",
        "    del X_test, X_train, X_valid, y_train\n",
        "    \n",
        "y_test_pred /= K  # 테스트 세트 예측의 평균\n",
        "\n",
        "print( \"\\nGini for full training set:\" )\n",
        "eval_gini(y, y_valid_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold  0\n",
            "  Gini =  0.2856959531750338\n",
            "\n",
            "Fold  1\n",
            "  Gini =  0.2825270426290394\n",
            "\n",
            "Fold  2\n",
            "  Gini =  0.2744124272744569\n",
            "\n",
            "Fold  3\n",
            "  Gini =  0.29925913576337726\n",
            "\n",
            "Fold  4\n",
            "  Gini =  0.28468083823013424\n",
            "\n",
            "Gini for full training set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28509183378958614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80jHQ8OtuL7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 스태킹 / 앙상블을위한 검증 예측 저장\n",
        "val = pd.DataFrame()\n",
        "val['id'] = id_train\n",
        "val['target'] = y_valid_pred.values\n",
        "val.to_csv(DATA_PATH + 'xgb_valid.csv', float_format='%.6f', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSjDod2f7l01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 제출 파일 생성\n",
        "sub = pd.DataFrame()\n",
        "sub['id'] = id_test\n",
        "sub['target'] = y_test_pred\n",
        "sub.to_csv(DATA_PATH + 'xgb_submit.csv', float_format='%.6f', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}